{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPY3eqHtogzD5+KEbf1Srf6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moetezwiw/projet-PNEUMONIA/blob/main/ganlast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIkUGrx-YOxU",
        "outputId": "1fe004f3-512b-439d-ea7e-4ec4ffccf88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder votre script\n",
        "%%writefile cyclegan.py\n",
        "\n",
        "\"\"\"\n",
        "CycleGAN pour Navigation C√©leste : Real (Classe A) ‚Üî Stellarium (Classe B)\n",
        "Version optimis√©e pour Colab\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "from itertools import chain\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================================\n",
        "# CBAM: Convolutional Block Attention Module\n",
        "# ============================================================================\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"Attention sur les canaux (QUELS features sont importants)\"\"\"\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        return x * self.sigmoid(avg_out + max_out)\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \"\"\"Attention spatiale (O√ô sont les features - localisation des √©toiles)\"\"\"\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        return x * self.sigmoid(self.conv(out))\n",
        "\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    \"\"\"Module CBAM complet\"\"\"\n",
        "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.channel_att = ChannelAttention(channels, reduction)\n",
        "        self.spatial_att = SpatialAttention(kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_att(x)\n",
        "        x = self.spatial_att(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ResNet Block avec CBAM\n",
        "# ============================================================================\n",
        "\n",
        "class ResnetBlockCBAM(nn.Module):\n",
        "    \"\"\"Bloc r√©siduel avec attention CBAM\"\"\"\n",
        "    def __init__(self, dim, use_cbam=True, use_dropout=False):\n",
        "        super().__init__()\n",
        "        conv_block = [\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, bias=False),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        conv_block += [\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, bias=False),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "        self.use_cbam = use_cbam\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv_block(x)\n",
        "        if self.use_cbam:\n",
        "            out = self.cbam(out)\n",
        "        return residual + out\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# G√©n√©rateur ResNet avec CBAM\n",
        "# ============================================================================\n",
        "\n",
        "class GeneratorResNetCBAM(nn.Module):\n",
        "    \"\"\"\n",
        "    G√©n√©rateur : Encoder -> ResBlocks avec CBAM -> Decoder\n",
        "    Real (Classe A) -> Stellarium (Classe B) et vice-versa\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9, use_cbam=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder initial\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, ngf, kernel_size=7, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "\n",
        "        # Downsampling\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** i\n",
        "            model += [\n",
        "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                         stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ngf * mult * 2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "        # ResNet blocks avec CBAM\n",
        "        mult = 2 ** n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlockCBAM(ngf * mult, use_cbam=use_cbam)]\n",
        "\n",
        "        # Upsampling\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** (n_downsampling - i)\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2,\n",
        "                                  kernel_size=3, stride=2,\n",
        "                                  padding=1, output_padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ngf * mult // 2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "        # Couche finale\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
        "            nn.Tanh()\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Discriminateur PatchGAN\n",
        "# ============================================================================\n",
        "\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminateur PatchGAN (70x70 receptive field)\n",
        "    Classe des patches comme r√©els/faux pour un feedback local\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc=3, ndf=64, n_layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        nf_mult = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            model += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                         kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        model += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                     kernel_size=4, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Dataset pour Classe A (Real) et Classe B (Stellarium)\n",
        "# ============================================================================\n",
        "\n",
        "class CelestialDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset pour navigation c√©leste\n",
        "    Classe A : Images r√©elles du ciel nocturne\n",
        "    Classe B : Images synth√©tiques Stellarium\n",
        "    \"\"\"\n",
        "    def __init__(self, root_classA, root_classB, transform=None, max_images=None):\n",
        "        self.root_classA = Path(root_classA)\n",
        "        self.root_classB = Path(root_classB)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Extensions support√©es\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "\n",
        "        # Lister les fichiers Classe A (Real)\n",
        "        self.classA_images = []\n",
        "        for ext in extensions:\n",
        "            self.classA_images.extend(list(self.root_classA.glob(ext)))\n",
        "        self.classA_images = sorted(self.classA_images)\n",
        "\n",
        "        # Lister les fichiers Classe B (Stellarium)\n",
        "        self.classB_images = []\n",
        "        for ext in extensions:\n",
        "            self.classB_images.extend(list(self.root_classB.glob(ext)))\n",
        "        self.classB_images = sorted(self.classB_images)\n",
        "\n",
        "        # Limiter le nombre d'images si sp√©cifi√©\n",
        "        if max_images:\n",
        "            self.classA_images = self.classA_images[:max_images]\n",
        "            self.classB_images = self.classB_images[:max_images]\n",
        "\n",
        "        print(f\"üìÇ Dataset charg√©:\")\n",
        "        print(f\"   Classe A (Real): {len(self.classA_images)} images\")\n",
        "        print(f\"   Classe B (Stellarium): {len(self.classB_images)} images\")\n",
        "\n",
        "        if len(self.classA_images) == 0 or len(self.classB_images) == 0:\n",
        "            raise ValueError(\"‚ö†Ô∏è  Aucune image trouv√©e! V√©rifiez les chemins des dossiers.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.classA_images), len(self.classB_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lecture cyclique si les tailles sont diff√©rentes\n",
        "        classA_img = Image.open(\n",
        "            self.classA_images[idx % len(self.classA_images)]\n",
        "        ).convert('RGB')\n",
        "\n",
        "        classB_img = Image.open(\n",
        "            self.classB_images[idx % len(self.classB_images)]\n",
        "        ).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            classA_img = self.transform(classA_img)\n",
        "            classB_img = self.transform(classB_img)\n",
        "\n",
        "        return classA_img, classB_img\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Utilitaires\n",
        "# ============================================================================\n",
        "\n",
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    \"\"\"Initialisation des poids\"\"\"\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or\n",
        "                                     classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm') != -1 or classname.find('InstanceNorm') != -1:\n",
        "            if hasattr(m, 'weight') and m.weight is not None:\n",
        "                nn.init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    net.apply(init_func)\n",
        "\n",
        "\n",
        "class ImagePool:\n",
        "    \"\"\"Buffer d'images pour stabiliser l'entra√Ænement du discriminateur\"\"\"\n",
        "    def __init__(self, pool_size=50):\n",
        "        self.pool_size = pool_size\n",
        "        self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            image = image.unsqueeze(0)\n",
        "            if len(self.images) < self.pool_size:\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = np.random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = np.random.randint(0, self.pool_size)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "\n",
        "        return torch.cat(return_images, 0)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Trainer CycleGAN\n",
        "# ============================================================================\n",
        "\n",
        "class CycleGANTrainer:\n",
        "    \"\"\"Entra√Ænement CycleGAN pour navigation c√©leste\"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"üñ•Ô∏è  Device: {self.device}\")\n",
        "\n",
        "        # Cr√©er r√©pertoires\n",
        "        os.makedirs(config['output_dir'], exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/samples\", exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/checkpoints\", exist_ok=True)\n",
        "\n",
        "        # Historique des pertes\n",
        "        self.history = {\n",
        "            'G_loss': [], 'D_loss': [], 'cycle_loss': [],\n",
        "            'identity_loss': [], 'GAN_loss': []\n",
        "        }\n",
        "\n",
        "        # Initialiser mod√®les\n",
        "        self._build_models()\n",
        "        self._setup_optimizers()\n",
        "\n",
        "        # Crit√®res de perte\n",
        "        self.criterion_GAN = nn.MSELoss()  # LSGAN\n",
        "        self.criterion_cycle = nn.L1Loss()\n",
        "        self.criterion_identity = nn.L1Loss()\n",
        "\n",
        "        # Pools d'images\n",
        "        self.fake_real_pool = ImagePool(config['pool_size'])\n",
        "        self.fake_sim_pool = ImagePool(config['pool_size'])\n",
        "\n",
        "    def _build_models(self):\n",
        "        \"\"\"Construire les g√©n√©rateurs et discriminateurs\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        print(\"üî® Construction des mod√®les...\")\n",
        "\n",
        "        # G√©n√©rateurs\n",
        "        self.G_A2B = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=config['ngf'],\n",
        "            n_blocks=config['n_blocks'], use_cbam=config['use_cbam']\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.G_B2A = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=config['ngf'],\n",
        "            n_blocks=config['n_blocks'], use_cbam=config['use_cbam']\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Discriminateurs\n",
        "        self.D_A = PatchGANDiscriminator(\n",
        "            input_nc=3, ndf=config['ndf'], n_layers=3\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.D_B = PatchGANDiscriminator(\n",
        "            input_nc=3, ndf=config['ndf'], n_layers=3\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Initialiser poids\n",
        "        init_weights(self.G_A2B, config['init_type'])\n",
        "        init_weights(self.G_B2A, config['init_type'])\n",
        "        init_weights(self.D_A, config['init_type'])\n",
        "        init_weights(self.D_B, config['init_type'])\n",
        "\n",
        "        # Compter param√®tres\n",
        "        g_params = sum(p.numel() for p in self.G_A2B.parameters())\n",
        "        d_params = sum(p.numel() for p in self.D_A.parameters())\n",
        "        print(f\"   G_A2B: {g_params:,} param√®tres\")\n",
        "        print(f\"   D_A: {d_params:,} param√®tres\")\n",
        "\n",
        "    def _setup_optimizers(self):\n",
        "        \"\"\"Configurer optimiseurs et schedulers\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.optimizer_G = Adam(\n",
        "            chain(self.G_A2B.parameters(), self.G_B2A.parameters()),\n",
        "            lr=config['lr'], betas=(config['beta1'], 0.999)\n",
        "        )\n",
        "\n",
        "        self.optimizer_D = Adam(\n",
        "            chain(self.D_A.parameters(), self.D_B.parameters()),\n",
        "            lr=config['lr'], betas=(config['beta1'], 0.999)\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler (decay lin√©aire)\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch - config['n_epochs_decay']) / (\n",
        "                config['n_epochs'] - config['n_epochs_decay'] + 1\n",
        "            )\n",
        "            return lr_l\n",
        "\n",
        "        self.scheduler_G = lr_scheduler.LambdaLR(\n",
        "            self.optimizer_G, lr_lambda=lambda_rule\n",
        "        )\n",
        "        self.scheduler_D = lr_scheduler.LambdaLR(\n",
        "            self.optimizer_D, lr_lambda=lambda_rule\n",
        "        )\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch):\n",
        "        \"\"\"Entra√Æner une √©poque\"\"\"\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "        self.D_A.train()\n",
        "        self.D_B.train()\n",
        "\n",
        "        losses = {'G': [], 'D': [], 'cycle': [], 'identity': [], 'GAN': []}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}/{self.config['n_epochs']}\")\n",
        "\n",
        "        for i, (real_A, real_B) in enumerate(pbar):\n",
        "            real_A = real_A.to(self.device)\n",
        "            real_B = real_B.to(self.device)\n",
        "            batch_size = real_A.size(0)\n",
        "\n",
        "            # Labels adversariaux\n",
        "            valid = torch.ones((batch_size, 1, 30, 30), device=self.device)\n",
        "            fake = torch.zeros((batch_size, 1, 30, 30), device=self.device)\n",
        "\n",
        "            # ========================================\n",
        "            # Entra√Æner G√©n√©rateurs\n",
        "            # ========================================\n",
        "            self.optimizer_G.zero_grad()\n",
        "\n",
        "            # Identity loss (pr√©server identit√© si m√™me domaine)\n",
        "            loss_id = 0\n",
        "            if self.config['lambda_identity'] > 0:\n",
        "                id_A = self.G_B2A(real_A)  # Devrait retourner real_A\n",
        "                id_B = self.G_A2B(real_B)  # Devrait retourner real_B\n",
        "                loss_id_A = self.criterion_identity(id_A, real_A)\n",
        "                loss_id_B = self.criterion_identity(id_B, real_B)\n",
        "                loss_id = (loss_id_A + loss_id_B) * 0.5\n",
        "\n",
        "            # GAN loss\n",
        "            fake_B = self.G_A2B(real_A)  # Real -> Stellarium\n",
        "            pred_fake_B = self.D_B(fake_B)\n",
        "            loss_GAN_A2B = self.criterion_GAN(pred_fake_B, valid)\n",
        "\n",
        "            fake_A = self.G_B2A(real_B)  # Stellarium -> Real\n",
        "            pred_fake_A = self.D_A(fake_A)\n",
        "            loss_GAN_B2A = self.criterion_GAN(pred_fake_A, valid)\n",
        "\n",
        "            loss_GAN = (loss_GAN_A2B + loss_GAN_B2A) * 0.5\n",
        "\n",
        "            # Cycle consistency loss (A -> B -> A et B -> A -> B)\n",
        "            recovered_A = self.G_B2A(fake_B)\n",
        "            loss_cycle_A = self.criterion_cycle(recovered_A, real_A)\n",
        "\n",
        "            recovered_B = self.G_A2B(fake_A)\n",
        "            loss_cycle_B = self.criterion_cycle(recovered_B, real_B)\n",
        "\n",
        "            loss_cycle = (loss_cycle_A + loss_cycle_B) * 0.5\n",
        "\n",
        "            # Total generator loss\n",
        "            loss_G = (loss_GAN +\n",
        "                     self.config['lambda_cycle'] * loss_cycle +\n",
        "                     self.config['lambda_identity'] * loss_id)\n",
        "\n",
        "            loss_G.backward()\n",
        "            self.optimizer_G.step()\n",
        "\n",
        "            # ========================================\n",
        "            # Entra√Æner Discriminateurs\n",
        "            # ========================================\n",
        "            self.optimizer_D.zero_grad()\n",
        "\n",
        "            # D_A (discrimine classe A)\n",
        "            pred_real_A = self.D_A(real_A)\n",
        "            loss_D_A_real = self.criterion_GAN(pred_real_A, valid)\n",
        "\n",
        "            fake_A_ = self.fake_real_pool.query(fake_A.detach())\n",
        "            pred_fake_A = self.D_A(fake_A_)\n",
        "            loss_D_A_fake = self.criterion_GAN(pred_fake_A, fake)\n",
        "\n",
        "            loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
        "\n",
        "            # D_B (discrimine classe B)\n",
        "            pred_real_B = self.D_B(real_B)\n",
        "            loss_D_B_real = self.criterion_GAN(pred_real_B, valid)\n",
        "\n",
        "            fake_B_ = self.fake_sim_pool.query(fake_B.detach())\n",
        "            pred_fake_B = self.D_B(fake_B_)\n",
        "            loss_D_B_fake = self.criterion_GAN(pred_fake_B, fake)\n",
        "\n",
        "            loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
        "\n",
        "            loss_D = (loss_D_A + loss_D_B) * 0.5\n",
        "\n",
        "            loss_D.backward()\n",
        "            self.optimizer_D.step()\n",
        "\n",
        "            # Sauvegarder pertes\n",
        "            losses['G'].append(loss_G.item())\n",
        "            losses['D'].append(loss_D.item())\n",
        "            losses['cycle'].append(loss_cycle.item())\n",
        "            losses['identity'].append(loss_id.item() if loss_id != 0 else 0)\n",
        "            losses['GAN'].append(loss_GAN.item())\n",
        "\n",
        "            # Mise √† jour barre de progression\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_G.item():.3f}\",\n",
        "                'D': f\"{loss_D.item():.3f}\",\n",
        "                'Cycle': f\"{loss_cycle.item():.3f}\"\n",
        "            })\n",
        "\n",
        "            # Sauvegarder √©chantillons\n",
        "            if i % self.config['sample_interval'] == 0:\n",
        "                self.save_samples(epoch, i, real_A, real_B, fake_B, fake_A)\n",
        "\n",
        "        # Moyennes\n",
        "        avg_losses = {k: np.mean(v) for k, v in losses.items()}\n",
        "\n",
        "        return avg_losses\n",
        "\n",
        "    def save_samples(self, epoch, batch, real_A, real_B, fake_B, fake_A):\n",
        "        \"\"\"Sauvegarder √©chantillons de traduction\"\"\"\n",
        "        samples_dir = f\"{self.config['output_dir']}/samples\"\n",
        "\n",
        "        n_samples = min(4, real_A.size(0))\n",
        "\n",
        "        # Cr√©er grille: Real A | Fake B | Real B | Fake A\n",
        "        comparison = torch.cat([\n",
        "            real_A[:n_samples],\n",
        "            fake_B[:n_samples],\n",
        "            real_B[:n_samples],\n",
        "            fake_A[:n_samples]\n",
        "        ], dim=0)\n",
        "\n",
        "        save_image(comparison,\n",
        "                  f\"{samples_dir}/epoch_{epoch:03d}_batch_{batch:04d}.png\",\n",
        "                  nrow=n_samples, normalize=True, value_range=(-1, 1))\n",
        "\n",
        "    def save_checkpoint(self, epoch, is_best=False):\n",
        "        \"\"\"Sauvegarder checkpoint\"\"\"\n",
        "        checkpoint_dir = f\"{self.config['output_dir']}/checkpoints\"\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'G_A2B': self.G_A2B.state_dict(),\n",
        "            'G_B2A': self.G_B2A.state_dict(),\n",
        "            'D_A': self.D_A.state_dict(),\n",
        "            'D_B': self.D_B.state_dict(),\n",
        "            'optimizer_G': self.optimizer_G.state_dict(),\n",
        "            'optimizer_D': self.optimizer_D.state_dict(),\n",
        "            'history': self.history,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        # Sauvegarder dernier checkpoint\n",
        "        torch.save(checkpoint, f\"{checkpoint_dir}/latest.pth\")\n",
        "\n",
        "        # Sauvegarder checkpoint p√©riodique\n",
        "        if epoch % self.config['checkpoint_interval'] == 0:\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/epoch_{epoch:03d}.pth\")\n",
        "\n",
        "        # Sauvegarder meilleur mod√®le\n",
        "        if is_best:\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/best.pth\")\n",
        "\n",
        "        print(f\"   üíæ Checkpoint sauvegard√© (epoch {epoch})\")\n",
        "\n",
        "    def plot_losses(self):\n",
        "        \"\"\"Tracer courbes de perte\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "        fig.suptitle('Historique d\\'entra√Ænement CycleGAN')\n",
        "\n",
        "        axes[0, 0].plot(self.history['G_loss'])\n",
        "        axes[0, 0].set_title('Generator Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "\n",
        "        axes[0, 1].plot(self.history['D_loss'])\n",
        "        axes[0, 1].set_title('Discriminator Loss')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "\n",
        "        axes[1, 0].plot(self.history['cycle_loss'])\n",
        "        axes[1, 0].set_title('Cycle Consistency Loss')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "\n",
        "        axes[1, 1].plot(self.history['GAN_loss'])\n",
        "        axes[1, 1].set_title('GAN Loss')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.config['output_dir']}/training_curves.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        \"\"\"Boucle d'entra√Ænement principale\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"üöÄ D√©marrage entra√Ænement CycleGAN Navigation C√©leste\")\n",
        "        print(f\"   Epochs: {self.config['n_epochs']}\")\n",
        "        print(f\"   Batch size: {self.config['batch_size']}\")\n",
        "        print(f\"   CBAM: {self.config['use_cbam']}\")\n",
        "        print(f\"   Device: {self.device}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        best_cycle_loss = float('inf')\n",
        "\n",
        "        for epoch in range(1, self.config['n_epochs'] + 1):\n",
        "            avg_losses = self.train_epoch(dataloader, epoch)\n",
        "\n",
        "            # Sauvegarder dans historique\n",
        "            self.history['G_loss'].append(avg_losses['G'])\n",
        "            self.history['D_loss'].append(avg_losses['D'])\n",
        "            self.history['cycle_loss'].append(avg_losses['cycle'])\n",
        "            self.history['identity_loss'].append(avg_losses['identity'])\n",
        "            self.history['GAN_loss'].append(avg_losses['GAN'])\n",
        "\n",
        "            # Afficher r√©sum√©\n",
        "            print(f\"\\nüìä Epoch {epoch} - Pertes moyennes:\")\n",
        "            print(f\"   G: {avg_losses['G']:.4f} | D: {avg_losses['D']:.4f}\")\n",
        "            print(f\"   Cycle: {avg_losses['cycle']:.4f} | GAN: {avg_losses['GAN']:.4f}\")\n",
        "\n",
        "            # Mettre √† jour learning rates\n",
        "            self.scheduler_G.step()\n",
        "            self.scheduler_D.step()\n",
        "\n",
        "            # Sauvegarder checkpoint\n",
        "            is_best = avg_losses['cycle'] < best_cycle_loss\n",
        "            if is_best:\n",
        "                best_cycle_loss = avg_losses['cycle']\n",
        "\n",
        "            self.save_checkpoint(epoch, is_best)\n",
        "\n",
        "            # Tracer courbes\n",
        "            if epoch % 5 == 0:\n",
        "                self.plot_losses()\n",
        "\n",
        "        # Sauvegarder historique\n",
        "        with open(f\"{self.config['output_dir']}/history.json\", 'w') as f:\n",
        "            json.dump(self.history, f, indent=2)\n",
        "\n",
        "        print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
        "        print(f\"üìÅ R√©sultats sauvegard√©s dans: {self.config['output_dir']}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "\n",
        "def get_config(classA_dir='/content/drive/MyDrive/entainement/classeA', classB_dir='/content/drive/MyDrive/entainement/classeB'):\n",
        "    \"\"\"Configuration d'entra√Ænement\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    return {\n",
        "        # Chemins des donn√©es\n",
        "        'classA_dir': classA_dir,  # Images r√©elles\n",
        "        'classB_dir': classB_dir,  # Images Stellarium\n",
        "        'output_dir': f'./outputs/cyclegan_{timestamp}',\n",
        "\n",
        "        # Architecture\n",
        "        'use_cbam': True,\n",
        "        'ngf': 64,  # Filtres g√©n√©rateur\n",
        "        'ndf': 64,  # Filtres discriminateur\n",
        "        'n_blocks': 9,  # Nombre de ResBlocks\n",
        "        'init_type': 'normal',\n",
        "\n",
        "        # Hyperparam√®tres\n",
        "        'n_epochs': 100,\n",
        "        'n_epochs_decay': 50,  # Decay LR apr√®s cette √©poque\n",
        "        'batch_size': 1,\n",
        "        'lr': 0.0002,\n",
        "        'beta1': 0.5,\n",
        "\n",
        "        # Poids des pertes\n",
        "        'lambda_cycle': 10.0,\n",
        "        'lambda_identity': 0.5,\n",
        "\n",
        "        # Entra√Ænement\n",
        "        'pool_size': 50,\n",
        "        'num_workers': 4,\n",
        "        'sample_interval': 100,\n",
        "        'checkpoint_interval': 10,\n",
        "\n",
        "        # Images\n",
        "        'img_size': 256,\n",
        "        'max_images': None,  # None = toutes les images\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Script principal\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Script d'entra√Ænement principal\"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"   CycleGAN - Navigation C√©leste\")\n",
        "    print(\"   Real (Classe A) ‚Üî Stellarium (Classe B)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Configuration\n",
        "    config = get_config(\n",
        "        classA_dir='./classeA',  # üìÅ Dossier images r√©elles\n",
        "        classB_dir='./classeB'   # üìÅ Dossier images Stellarium\n",
        "    )\n",
        "\n",
        "    # V√©rifier dossiers\n",
        "    if not os.path.exists(config['classA_dir']):\n",
        "        print(f\"‚ùå Erreur: Dossier '{config['classA_dir']}' introuvable!\")\n",
        "        print(\"   Cr√©ez le dossier et placez-y vos images r√©elles.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(config['classB_dir']):\n",
        "        print(f\"‚ùå Erreur: Dossier '{config['classB_dir']}' introuvable!\")\n",
        "        print(\"   Cr√©ez le dossier et placez-y vos images Stellarium.\")\n",
        "        return\n",
        "\n",
        "    # Transforms avec augmentation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((config['img_size'], config['img_size'])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Cr√©er dataset\n",
        "    print(\"üìÇ Chargement du dataset...\")\n",
        "    try:\n",
        "        dataset = CelestialDataset(\n",
        "            root_classA=config['classA_dir'],\n",
        "            root_classB=config['classB_dir'],\n",
        "            transform=transform,\n",
        "            max_images=config['max_images']\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ DataLoader cr√©√©: {len(dataloader)} batches\\n\")\n",
        "\n",
        "    # Cr√©er trainer et entra√Æner\n",
        "    trainer = CycleGANTrainer(config)\n",
        "    trainer.train(dataloader)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI1ne_FvYQ1e",
        "outputId": "516ed08e-6fa5-42f3-eb66-5798ef714a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cyclegan.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile script.py\n",
        "\"\"\"\n",
        "CycleGAN pour Navigation C√©leste : Real (Classe A) ‚Üî Stellarium (Classe B)\n",
        "Version optimis√©e et pr√™te √† l'ex√©cution\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "from itertools import chain\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================================\n",
        "# CBAM: Convolutional Block Attention Module\n",
        "# ============================================================================\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"Attention sur les canaux (QUELS features sont importants)\"\"\"\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        return x * self.sigmoid(avg_out + max_out)\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \"\"\"Attention spatiale (O√ô sont les features - localisation des √©toiles)\"\"\"\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        return x * self.sigmoid(self.conv(out))\n",
        "\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    \"\"\"Module CBAM complet\"\"\"\n",
        "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.channel_att = ChannelAttention(channels, reduction)\n",
        "        self.spatial_att = SpatialAttention(kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_att(x)\n",
        "        x = self.spatial_att(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ResNet Block avec CBAM\n",
        "# ============================================================================\n",
        "\n",
        "class ResnetBlockCBAM(nn.Module):\n",
        "    \"\"\"Bloc r√©siduel avec attention CBAM\"\"\"\n",
        "    def __init__(self, dim, use_cbam=True, use_dropout=False):\n",
        "        super().__init__()\n",
        "        conv_block = [\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, bias=False),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        conv_block += [\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, bias=False),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "        self.use_cbam = use_cbam\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv_block(x)\n",
        "        if self.use_cbam:\n",
        "            out = self.cbam(out)\n",
        "        return residual + out\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# G√©n√©rateur ResNet avec CBAM\n",
        "# ============================================================================\n",
        "\n",
        "class GeneratorResNetCBAM(nn.Module):\n",
        "    \"\"\"\n",
        "    G√©n√©rateur : Encoder -> ResBlocks avec CBAM -> Decoder\n",
        "    Real (Classe A) -> Stellarium (Classe B) et vice-versa\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9, use_cbam=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder initial\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, ngf, kernel_size=7, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "\n",
        "        # Downsampling\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** i\n",
        "            model += [\n",
        "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                         stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ngf * mult * 2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "        # ResNet blocks avec CBAM\n",
        "        mult = 2 ** n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlockCBAM(ngf * mult, use_cbam=use_cbam)]\n",
        "\n",
        "        # Upsampling\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** (n_downsampling - i)\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2,\n",
        "                                  kernel_size=3, stride=2,\n",
        "                                  padding=1, output_padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ngf * mult // 2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "\n",
        "        # Couche finale\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
        "            nn.Tanh()\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Discriminateur PatchGAN\n",
        "# ============================================================================\n",
        "\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminateur PatchGAN (70x70 receptive field)\n",
        "    Classe des patches comme r√©els/faux pour un feedback local\n",
        "    \"\"\"\n",
        "    def __init__(self, input_nc=3, ndf=64, n_layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        nf_mult = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            model += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                         kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        model += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                     kernel_size=4, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        model += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Dataset pour Classe A (Real) et Classe B (Stellarium)\n",
        "# ============================================================================\n",
        "\n",
        "class CelestialDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset pour navigation c√©leste\n",
        "    Classe A : Images r√©elles du ciel nocturne\n",
        "    Classe B : Images synth√©tiques Stellarium\n",
        "    \"\"\"\n",
        "    def __init__(self, root_classA, root_classB, transform=None, max_images=None):\n",
        "        self.root_classA = Path(root_classA)\n",
        "        self.root_classB = Path(root_classB)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Extensions support√©es\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "\n",
        "        # Lister les fichiers Classe A (Real)\n",
        "        self.classA_images = []\n",
        "        for ext in extensions:\n",
        "            self.classA_images.extend(list(self.root_classA.glob(ext)))\n",
        "        self.classA_images = sorted(self.classA_images)\n",
        "\n",
        "        # Lister les fichiers Classe B (Stellarium)\n",
        "        self.classB_images = []\n",
        "        for ext in extensions:\n",
        "            self.classB_images.extend(list(self.root_classB.glob(ext)))\n",
        "        self.classB_images = sorted(self.classB_images)\n",
        "\n",
        "        # Limiter le nombre d'images si sp√©cifi√©\n",
        "        if max_images:\n",
        "            self.classA_images = self.classA_images[:max_images]\n",
        "            self.classB_images = self.classB_images[:max_images]\n",
        "\n",
        "        print(f\"üìÇ Dataset charg√©:\")\n",
        "        print(f\"   Classe A (Real): {len(self.classA_images)} images\")\n",
        "        print(f\"   Classe B (Stellarium): {len(self.classB_images)} images\")\n",
        "\n",
        "        if len(self.classA_images) == 0 or len(self.classB_images) == 0:\n",
        "            raise ValueError(\"‚ö†Ô∏è  Aucune image trouv√©e! V√©rifiez les chemins des dossiers.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.classA_images), len(self.classB_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lecture cyclique si les tailles sont diff√©rentes\n",
        "        classA_img = Image.open(\n",
        "            self.classA_images[idx % len(self.classA_images)]\n",
        "        ).convert('RGB')\n",
        "\n",
        "        classB_img = Image.open(\n",
        "            self.classB_images[idx % len(self.classB_images)]\n",
        "        ).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            classA_img = self.transform(classA_img)\n",
        "            classB_img = self.transform(classB_img)\n",
        "\n",
        "        return classA_img, classB_img\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Utilitaires\n",
        "# ============================================================================\n",
        "\n",
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    \"\"\"Initialisation des poids\"\"\"\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or\n",
        "                                     classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm') != -1 or classname.find('InstanceNorm') != -1:\n",
        "            if hasattr(m, 'weight') and m.weight is not None:\n",
        "                nn.init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    net.apply(init_func)\n",
        "\n",
        "\n",
        "class ImagePool:\n",
        "    \"\"\"Buffer d'images pour stabiliser l'entra√Ænement du discriminateur\"\"\"\n",
        "    def __init__(self, pool_size=50):\n",
        "        self.pool_size = pool_size\n",
        "        self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            image = image.unsqueeze(0)\n",
        "            if len(self.images) < self.pool_size:\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = np.random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = np.random.randint(0, self.pool_size)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "\n",
        "        return torch.cat(return_images, 0)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Trainer CycleGAN\n",
        "# ============================================================================\n",
        "\n",
        "class CycleGANTrainer:\n",
        "    \"\"\"Entra√Ænement CycleGAN pour navigation c√©leste\"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"üñ•Ô∏è  Device: {self.device}\")\n",
        "\n",
        "        # Cr√©er r√©pertoires\n",
        "        os.makedirs(config['output_dir'], exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/samples\", exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/checkpoints\", exist_ok=True)\n",
        "\n",
        "        # Historique des pertes\n",
        "        self.history = {\n",
        "            'G_loss': [], 'D_loss': [], 'cycle_loss': [],\n",
        "            'identity_loss': [], 'GAN_loss': []\n",
        "        }\n",
        "\n",
        "        # Initialiser mod√®les\n",
        "        self._build_models()\n",
        "        self._setup_optimizers()\n",
        "\n",
        "        # Crit√®res de perte\n",
        "        self.criterion_GAN = nn.MSELoss()  # LSGAN\n",
        "        self.criterion_cycle = nn.L1Loss()\n",
        "        self.criterion_identity = nn.L1Loss()\n",
        "\n",
        "        # Pools d'images\n",
        "        self.fake_real_pool = ImagePool(config['pool_size'])\n",
        "        self.fake_sim_pool = ImagePool(config['pool_size'])\n",
        "\n",
        "    def _build_models(self):\n",
        "        \"\"\"Construire les g√©n√©rateurs et discriminateurs\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        print(\"üî® Construction des mod√®les...\")\n",
        "\n",
        "        # G√©n√©rateurs\n",
        "        self.G_A2B = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=config['ngf'],\n",
        "            n_blocks=config['n_blocks'], use_cbam=config['use_cbam']\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.G_B2A = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=config['ngf'],\n",
        "            n_blocks=config['n_blocks'], use_cbam=config['use_cbam']\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Discriminateurs\n",
        "        self.D_A = PatchGANDiscriminator(\n",
        "            input_nc=3, ndf=config['ndf'], n_layers=3\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.D_B = PatchGANDiscriminator(\n",
        "            input_nc=3, ndf=config['ndf'], n_layers=3\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Initialiser poids\n",
        "        init_weights(self.G_A2B, config['init_type'])\n",
        "        init_weights(self.G_B2A, config['init_type'])\n",
        "        init_weights(self.D_A, config['init_type'])\n",
        "        init_weights(self.D_B, config['init_type'])\n",
        "\n",
        "        # Compter param√®tres\n",
        "        g_params = sum(p.numel() for p in self.G_A2B.parameters())\n",
        "        d_params = sum(p.numel() for p in self.D_A.parameters())\n",
        "        print(f\"   G_A2B: {g_params:,} param√®tres\")\n",
        "        print(f\"   D_A: {d_params:,} param√®tres\")\n",
        "\n",
        "    def _setup_optimizers(self):\n",
        "        \"\"\"Configurer optimiseurs et schedulers\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.optimizer_G = Adam(\n",
        "            chain(self.G_A2B.parameters(), self.G_B2A.parameters()),\n",
        "            lr=config['lr'], betas=(config['beta1'], 0.999)\n",
        "        )\n",
        "\n",
        "        self.optimizer_D = Adam(\n",
        "            chain(self.D_A.parameters(), self.D_B.parameters()),\n",
        "            lr=config['lr'], betas=(config['beta1'], 0.999)\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler (decay lin√©aire)\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch - config['n_epochs_decay']) / (\n",
        "                config['n_epochs'] - config['n_epochs_decay'] + 1\n",
        "            )\n",
        "            return lr_l\n",
        "\n",
        "        self.scheduler_G = lr_scheduler.LambdaLR(\n",
        "            self.optimizer_G, lr_lambda=lambda_rule\n",
        "        )\n",
        "        self.scheduler_D = lr_scheduler.LambdaLR(\n",
        "            self.optimizer_D, lr_lambda=lambda_rule\n",
        "        )\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch):\n",
        "        \"\"\"Entra√Æner une √©poque\"\"\"\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "        self.D_A.train()\n",
        "        self.D_B.train()\n",
        "\n",
        "        losses = {'G': [], 'D': [], 'cycle': [], 'identity': [], 'GAN': []}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}/{self.config['n_epochs']}\")\n",
        "\n",
        "        for i, (real_A, real_B) in enumerate(pbar):\n",
        "            real_A = real_A.to(self.device)\n",
        "            real_B = real_B.to(self.device)\n",
        "            batch_size = real_A.size(0)\n",
        "\n",
        "            # Labels adversariaux\n",
        "            valid = torch.ones((batch_size, 1, 30, 30), device=self.device)\n",
        "            fake = torch.zeros((batch_size, 1, 30, 30), device=self.device)\n",
        "\n",
        "            # ========================================\n",
        "            # Entra√Æner G√©n√©rateurs\n",
        "            # ========================================\n",
        "            self.optimizer_G.zero_grad()\n",
        "\n",
        "            # Identity loss (pr√©server identit√© si m√™me domaine)\n",
        "            loss_id = 0\n",
        "            if self.config['lambda_identity'] > 0:\n",
        "                id_A = self.G_B2A(real_A)  # Devrait retourner real_A\n",
        "                id_B = self.G_A2B(real_B)  # Devrait retourner real_B\n",
        "                loss_id_A = self.criterion_identity(id_A, real_A)\n",
        "                loss_id_B = self.criterion_identity(id_B, real_B)\n",
        "                loss_id = (loss_id_A + loss_id_B) * 0.5\n",
        "\n",
        "            # GAN loss\n",
        "            fake_B = self.G_A2B(real_A)  # Real -> Stellarium\n",
        "            pred_fake_B = self.D_B(fake_B)\n",
        "            loss_GAN_A2B = self.criterion_GAN(pred_fake_B, valid)\n",
        "\n",
        "            fake_A = self.G_B2A(real_B)  # Stellarium -> Real\n",
        "            pred_fake_A = self.D_A(fake_A)\n",
        "            loss_GAN_B2A = self.criterion_GAN(pred_fake_A, valid)\n",
        "\n",
        "            loss_GAN = (loss_GAN_A2B + loss_GAN_B2A) * 0.5\n",
        "\n",
        "            # Cycle consistency loss (A -> B -> A et B -> A -> B)\n",
        "            recovered_A = self.G_B2A(fake_B)\n",
        "            loss_cycle_A = self.criterion_cycle(recovered_A, real_A)\n",
        "\n",
        "            recovered_B = self.G_A2B(fake_A)\n",
        "            loss_cycle_B = self.criterion_cycle(recovered_B, real_B)\n",
        "\n",
        "            loss_cycle = (loss_cycle_A + loss_cycle_B) * 0.5\n",
        "\n",
        "            # Total generator loss\n",
        "            loss_G = (loss_GAN +\n",
        "                     self.config['lambda_cycle'] * loss_cycle +\n",
        "                     self.config['lambda_identity'] * loss_id)\n",
        "\n",
        "            loss_G.backward()\n",
        "            self.optimizer_G.step()\n",
        "\n",
        "            # ========================================\n",
        "            # Entra√Æner Discriminateurs\n",
        "            # ========================================\n",
        "            self.optimizer_D.zero_grad()\n",
        "\n",
        "            # D_A (discrimine classe A)\n",
        "            pred_real_A = self.D_A(real_A)\n",
        "            loss_D_A_real = self.criterion_GAN(pred_real_A, valid)\n",
        "\n",
        "            fake_A_ = self.fake_real_pool.query(fake_A.detach())\n",
        "            pred_fake_A = self.D_A(fake_A_)\n",
        "            loss_D_A_fake = self.criterion_GAN(pred_fake_A, fake)\n",
        "\n",
        "            loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
        "\n",
        "            # D_B (discrimine classe B)\n",
        "            pred_real_B = self.D_B(real_B)\n",
        "            loss_D_B_real = self.criterion_GAN(pred_real_B, valid)\n",
        "\n",
        "            fake_B_ = self.fake_sim_pool.query(fake_B.detach())\n",
        "            pred_fake_B = self.D_B(fake_B_)\n",
        "            loss_D_B_fake = self.criterion_GAN(pred_fake_B, fake)\n",
        "\n",
        "            loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
        "\n",
        "            loss_D = (loss_D_A + loss_D_B) * 0.5\n",
        "\n",
        "            loss_D.backward()\n",
        "            self.optimizer_D.step()\n",
        "\n",
        "            # Sauvegarder pertes\n",
        "            losses['G'].append(loss_G.item())\n",
        "            losses['D'].append(loss_D.item())\n",
        "            losses['cycle'].append(loss_cycle.item())\n",
        "            losses['identity'].append(loss_id.item() if loss_id != 0 else 0)\n",
        "            losses['GAN'].append(loss_GAN.item())\n",
        "\n",
        "            # Mise √† jour barre de progression\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_G.item():.3f}\",\n",
        "                'D': f\"{loss_D.item():.3f}\",\n",
        "                'Cycle': f\"{loss_cycle.item():.3f}\"\n",
        "            })\n",
        "\n",
        "            # Sauvegarder √©chantillons\n",
        "            if i % self.config['sample_interval'] == 0:\n",
        "                self.save_samples(epoch, i, real_A, real_B, fake_B, fake_A)\n",
        "\n",
        "        # Moyennes\n",
        "        avg_losses = {k: np.mean(v) for k, v in losses.items()}\n",
        "\n",
        "        return avg_losses\n",
        "\n",
        "    def save_samples(self, epoch, batch, real_A, real_B, fake_B, fake_A):\n",
        "        \"\"\"Sauvegarder √©chantillons de traduction\"\"\"\n",
        "        samples_dir = f\"{self.config['output_dir']}/samples\"\n",
        "\n",
        "        n_samples = min(4, real_A.size(0))\n",
        "\n",
        "        # Cr√©er grille: Real A | Fake B | Real B | Fake A\n",
        "        comparison = torch.cat([\n",
        "            real_A[:n_samples],\n",
        "            fake_B[:n_samples],\n",
        "            real_B[:n_samples],\n",
        "            fake_A[:n_samples]\n",
        "        ], dim=0)\n",
        "\n",
        "        save_image(comparison,\n",
        "                  f\"{samples_dir}/epoch_{epoch:03d}_batch_{batch:04d}.png\",\n",
        "                  nrow=n_samples, normalize=True, value_range=(-1, 1))\n",
        "\n",
        "    def save_checkpoint(self, epoch, is_best=False):\n",
        "        \"\"\"Sauvegarder checkpoint\"\"\"\n",
        "        checkpoint_dir = f\"{self.config['output_dir']}/checkpoints\"\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'G_A2B': self.G_A2B.state_dict(),\n",
        "            'G_B2A': self.G_B2A.state_dict(),\n",
        "            'D_A': self.D_A.state_dict(),\n",
        "            'D_B': self.D_B.state_dict(),\n",
        "            'optimizer_G': self.optimizer_G.state_dict(),\n",
        "            'optimizer_D': self.optimizer_D.state_dict(),\n",
        "            'history': self.history,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        # Sauvegarder dernier checkpoint\n",
        "        torch.save(checkpoint, f\"{checkpoint_dir}/latest.pth\")\n",
        "\n",
        "        # Sauvegarder checkpoint p√©riodique\n",
        "        if epoch % self.config['checkpoint_interval'] == 0:\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/epoch_{epoch:03d}.pth\")\n",
        "\n",
        "        # Sauvegarder meilleur mod√®le\n",
        "        if is_best:\n",
        "            torch.save(checkpoint, f\"{checkpoint_dir}/best.pth\")\n",
        "\n",
        "        print(f\"   üíæ Checkpoint sauvegard√© (epoch {epoch})\")\n",
        "\n",
        "    def plot_losses(self):\n",
        "        \"\"\"Tracer courbes de perte\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "        fig.suptitle('Historique d\\'entra√Ænement CycleGAN')\n",
        "\n",
        "        axes[0, 0].plot(self.history['G_loss'])\n",
        "        axes[0, 0].set_title('Generator Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "\n",
        "        axes[0, 1].plot(self.history['D_loss'])\n",
        "        axes[0, 1].set_title('Discriminator Loss')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "\n",
        "        axes[1, 0].plot(self.history['cycle_loss'])\n",
        "        axes[1, 0].set_title('Cycle Consistency Loss')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "\n",
        "        axes[1, 1].plot(self.history['GAN_loss'])\n",
        "        axes[1, 1].set_title('GAN Loss')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.config['output_dir']}/training_curves.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        \"\"\"Boucle d'entra√Ænement principale\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"üöÄ D√©marrage entra√Ænement CycleGAN Navigation C√©leste\")\n",
        "        print(f\"   Epochs: {self.config['n_epochs']}\")\n",
        "        print(f\"   Batch size: {self.config['batch_size']}\")\n",
        "        print(f\"   CBAM: {self.config['use_cbam']}\")\n",
        "        print(f\"   Device: {self.device}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        best_cycle_loss = float('inf')\n",
        "\n",
        "        for epoch in range(1, self.config['n_epochs'] + 1):\n",
        "            avg_losses = self.train_epoch(dataloader, epoch)\n",
        "\n",
        "            # Sauvegarder dans historique\n",
        "            self.history['G_loss'].append(avg_losses['G'])\n",
        "            self.history['D_loss'].append(avg_losses['D'])\n",
        "            self.history['cycle_loss'].append(avg_losses['cycle'])\n",
        "            self.history['identity_loss'].append(avg_losses['identity'])\n",
        "            self.history['GAN_loss'].append(avg_losses['GAN'])\n",
        "\n",
        "            # Afficher r√©sum√©\n",
        "            print(f\"\\nüìä Epoch {epoch} - Pertes moyennes:\")\n",
        "            print(f\"   G: {avg_losses['G']:.4f} | D: {avg_losses['D']:.4f}\")\n",
        "            print(f\"   Cycle: {avg_losses['cycle']:.4f} | GAN: {avg_losses['GAN']:.4f}\")\n",
        "\n",
        "            # Mettre √† jour learning rates\n",
        "            self.scheduler_G.step()\n",
        "            self.scheduler_D.step()\n",
        "\n",
        "            # Sauvegarder checkpoint\n",
        "            is_best = avg_losses['cycle'] < best_cycle_loss\n",
        "            if is_best:\n",
        "                best_cycle_loss = avg_losses['cycle']\n",
        "\n",
        "            self.save_checkpoint(epoch, is_best)\n",
        "\n",
        "            # Tracer courbes\n",
        "            if epoch % 5 == 0:\n",
        "                self.plot_losses()\n",
        "\n",
        "        # Sauvegarder historique\n",
        "        with open(f\"{self.config['output_dir']}/history.json\", 'w') as f:\n",
        "            json.dump(self.history, f, indent=2)\n",
        "\n",
        "        print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
        "        print(f\"üìÅ R√©sultats sauvegard√©s dans: {self.config['output_dir']}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "\n",
        "def get_config(classA_dir='/content/drive/MyDrive/entainement/classeA', classB_dir='/content/drive/MyDrive/entainement/classeB'):\n",
        "    \"\"\"Configuration d'entra√Ænement\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    return {\n",
        "        # Chemins des donn√©es\n",
        "        'classA_dir': classA_dir,  # Images r√©elles\n",
        "        'classB_dir': classB_dir,  # Images Stellarium\n",
        "        'output_dir': f'./outputs/cyclegan_{timestamp}',\n",
        "\n",
        "        # Architecture\n",
        "        'use_cbam': True,\n",
        "        'ngf': 64,  # Filtres g√©n√©rateur\n",
        "        'ndf': 64,  # Filtres discriminateur\n",
        "        'n_blocks': 9,  # Nombre de ResBlocks\n",
        "        'init_type': 'normal',\n",
        "\n",
        "        # Hyperparam√®tres\n",
        "        'n_epochs': 100,\n",
        "        'n_epochs_decay': 50,  # Decay LR apr√®s cette √©poque\n",
        "        'batch_size': 1,\n",
        "        'lr': 0.0002,\n",
        "        'beta1': 0.5,\n",
        "\n",
        "        # Poids des pertes\n",
        "        'lambda_cycle': 10.0,\n",
        "        'lambda_identity': 0.5,\n",
        "\n",
        "        # Entra√Ænement\n",
        "        'pool_size': 50,\n",
        "        'num_workers': 4,\n",
        "        'sample_interval': 100,\n",
        "        'checkpoint_interval': 10,\n",
        "\n",
        "        # Images\n",
        "        'img_size': 256,\n",
        "        'max_images': None,  # None = toutes les images\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Inf√©rence\n",
        "# ============================================================================\n",
        "\n",
        "class CycleGANInference:\n",
        "    \"\"\"Inf√©rence : traduire nouvelles images\"\"\"\n",
        "    def __init__(self, checkpoint_path, device='cuda'):\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"üñ•Ô∏è  Chargement mod√®le sur {self.device}...\")\n",
        "\n",
        "        # Charger checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
        "\n",
        "        # Cr√©er g√©n√©rateurs\n",
        "        self.G_A2B = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=64, n_blocks=9, use_cbam=True\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.G_B2A = GeneratorResNetCBAM(\n",
        "            input_nc=3, output_nc=3, ngf=64, n_blocks=9, use_cbam=True\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Charger poids\n",
        "        self.G_A2B.load_state_dict(checkpoint['G_A2B'])\n",
        "        self.G_B2A.load_state_dict(checkpoint['G_B2A'])\n",
        "\n",
        "        self.G_A2B.eval()\n",
        "        self.G_B2A.eval()\n",
        "\n",
        "        # Transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        print(\"‚úÖ Mod√®le charg√© avec succ√®s!\")\n",
        "\n",
        "    def translate_A2B(self, image_path, output_path):\n",
        "        \"\"\"Traduire Real (A) -> Stellarium (B)\"\"\"\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake_B = self.G_A2B(img_tensor)\n",
        "\n",
        "        save_image(fake_B, output_path, normalize=True, value_range=(-1, 1))\n",
        "        print(f\"‚úÖ Traduit: {output_path}\")\n",
        "\n",
        "    def translate_B2A(self, image_path, output_path):\n",
        "        \"\"\"Traduire Stellarium (B) -> Real (A)\"\"\"\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake_A = self.G_B2A(img_tensor)\n",
        "\n",
        "        save_image(fake_A, output_path, normalize=True, value_range=(-1, 1))\n",
        "        print(f\"‚úÖ Traduit: {output_path}\")\n",
        "\n",
        "    def batch_translate(self, input_dir, output_dir, direction='A2B'):\n",
        "        \"\"\"Traduire un dossier d'images\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "        image_files = []\n",
        "        for ext in extensions:\n",
        "            image_files.extend(list(Path(input_dir).glob(ext)))\n",
        "\n",
        "        print(f\"üîÑ Traduction de {len(image_files)} images ({direction})...\")\n",
        "\n",
        "        for img_path in tqdm(image_files):\n",
        "            output_path = Path(output_dir) / f\"translated_{img_path.name}\"\n",
        "\n",
        "            if direction == 'A2B':\n",
        "                self.translate_A2B(str(img_path), str(output_path))\n",
        "            else:\n",
        "                self.translate_B2A(str(img_path), str(output_path))\n",
        "\n",
        "    def create_comparison(self, image_path, output_path, direction='A2B'):\n",
        "        \"\"\"Cr√©er image de comparaison c√¥te √† c√¥te\"\"\"\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if direction == 'A2B':\n",
        "                fake = self.G_A2B(img_tensor)\n",
        "            else:\n",
        "                fake = self.G_B2A(img_tensor)\n",
        "\n",
        "        # Cr√©er comparaison\n",
        "        comparison = torch.cat([img_tensor, fake], dim=3)\n",
        "        save_image(comparison, output_path, normalize=True, value_range=(-1, 1))\n",
        "        print(f\"‚úÖ Comparaison cr√©√©e: {output_path}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Script principal\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Script d'entra√Ænement principal\"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"   CycleGAN - Navigation C√©leste\")\n",
        "    print(\"   Real (Classe A) ‚Üî Stellarium (Classe B)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Configuration\n",
        "    config = get_config(\n",
        "        classA_dir='./classeA',  # üìÅ Dossier images r√©elles\n",
        "        classB_dir='./classeB'   # üìÅ Dossier images Stellarium\n",
        "    )\n",
        "\n",
        "    # V√©rifier dossiers\n",
        "    if not os.path.exists(config['classA_dir']):\n",
        "        print(f\"‚ùå Erreur: Dossier '{config['classA_dir']}' introuvable!\")\n",
        "        print(\"   Cr√©ez le dossier et placez-y vos images r√©elles.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(config['classB_dir']):\n",
        "        print(f\"‚ùå Erreur: Dossier '{config['classB_dir']}' introuvable!\")\n",
        "        print(\"   Cr√©ez le dossier et placez-y vos images Stellarium.\")\n",
        "        return\n",
        "\n",
        "    # Transforms avec augmentation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((config['img_size'], config['img_size'])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Cr√©er dataset\n",
        "    print(\"üìÇ Chargement du dataset...\")\n",
        "    try:\n",
        "        dataset = CelestialDataset(\n",
        "            root_classA=config['classA_dir'],\n",
        "            root_classB=config['classB_dir'],\n",
        "            transform=transform,\n",
        "            max_images=config['max_images']\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ DataLoader cr√©√©: {len(dataloader)} batches\\n\")\n",
        "\n",
        "    # Cr√©er trainer et entra√Æner\n",
        "    trainer = CycleGANTrainer(config)\n",
        "    trainer.train(dataloader)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Fonctions utilitaires\n",
        "# ============================================================================\n",
        "\n",
        "def test_inference():\n",
        "    \"\"\"Tester l'inf√©rence avec un mod√®le entra√Æn√©\"\"\"\n",
        "    print(\"üß™ Test d'inf√©rence...\")\n",
        "\n",
        "    # Chemin vers checkpoint (√† adapter)\n",
        "    checkpoint = './outputs/cyclegan_XXXXXX/checkpoints/best.pth'\n",
        "\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(f\"‚ùå Checkpoint introuvable: {checkpoint}\")\n",
        "        print(\"   Entra√Ænez d'abord le mod√®le avec main()\")\n",
        "        return\n",
        "\n",
        "    # Cr√©er inf√©renceur\n",
        "    inferencer = CycleGANInference(checkpoint)\n",
        "\n",
        "    # Test sur une image\n",
        "    test_image = './classeA/test_image.jpg'\n",
        "    if os.path.exists(test_image):\n",
        "        inferencer.create_comparison(\n",
        "            test_image,\n",
        "            './test_comparison.png',\n",
        "            direction='A2B'\n",
        "        )\n",
        "\n",
        "    # Traduire un dossier complet\n",
        "    inferencer.batch_translate(\n",
        "        input_dir='./classeA',\n",
        "        output_dir='./translated_to_stellarium',\n",
        "        direction='A2B'\n",
        "    )\n",
        "\n",
        "\n",
        "def quick_test():\n",
        "    \"\"\"Test rapide avec donn√©es synth√©tiques\"\"\"\n",
        "    print(\"üß™ Test rapide avec donn√©es synth√©tiques...\\n\")\n",
        "\n",
        "    config = get_config()\n",
        "    config['n_epochs'] = 2\n",
        "    config['batch_size'] = 2\n",
        "    config['checkpoint_interval'] = 1\n",
        "\n",
        "    # Dataset synth√©tique\n",
        "    class DummyDataset(Dataset):\n",
        "        def __len__(self):\n",
        "            return 20\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return torch.randn(3, 256, 256), torch.randn(3, 256, 256)\n",
        "\n",
        "    dataloader = DataLoader(DummyDataset(), batch_size=2, shuffle=True)\n",
        "\n",
        "    trainer = CycleGANTrainer(config)\n",
        "    trainer.train(dataloader)\n",
        "\n",
        "    print(\"\\n‚úÖ Test rapide r√©ussi!\")\n",
        "\n",
        "\n",
        "def create_sample_structure():\n",
        "    \"\"\"Cr√©er structure de dossiers exemple\"\"\"\n",
        "    print(\"üìÅ Cr√©ation de la structure de dossiers...\\n\")\n",
        "\n",
        "    folders = [\n",
        "        './classeA',  # Images r√©elles\n",
        "        './classeB',  # Images Stellarium\n",
        "        './outputs',\n",
        "    ]\n",
        "\n",
        "    for folder in folders:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        print(f\"   ‚úì {folder}\")\n",
        "\n",
        "    print(\"\\nüìã Instructions:\")\n",
        "    print(\"   1. Placez vos images R√âELLES du ciel dans: ./classeA/\")\n",
        "    print(\"   2. Placez vos images STELLARIUM dans: ./classeB/\")\n",
        "    print(\"   3. Lancez l'entra√Ænement avec: python script.py --mode train\")\n",
        "    print(\"\\n   Formats support√©s: .jpg, .jpeg, .png\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Point d'entr√©e\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='CycleGAN pour Navigation C√©leste (Real ‚Üî Stellarium)'\n",
        "    )\n",
        "    parser.add_argument('--mode', type=str, default='train',\n",
        "                       choices=['train', 'inference', 'test', 'setup'],\n",
        "                       help='Mode d\\'ex√©cution')\n",
        "    parser.add_argument('--classA', type=str, default='./classeA',\n",
        "                       help='Dossier images r√©elles (Classe A)')\n",
        "    parser.add_argument('--classB', type=str, default='./classeB',\n",
        "                       help='Dossier images Stellarium (Classe B)')\n",
        "    parser.add_argument('--checkpoint', type=str, default=None,\n",
        "                       help='Chemin checkpoint pour inf√©rence')\n",
        "    parser.add_argument('--input', type=str, default=None,\n",
        "                       help='Image/dossier d\\'entr√©e pour inf√©rence')\n",
        "    parser.add_argument('--output', type=str, default='./translated',\n",
        "                       help='Dossier de sortie pour inf√©rence')\n",
        "    parser.add_argument('--direction', type=str, default='A2B',\n",
        "                       choices=['A2B', 'B2A'],\n",
        "                       help='Direction traduction: A2B (Real->Stellarium) ou B2A')\n",
        "    parser.add_argument('--epochs', type=int, default=100,\n",
        "                       help='Nombre d\\'√©poques')\n",
        "    parser.add_argument('--batch_size', type=int, default=1,\n",
        "                       help='Taille du batch')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.mode == 'setup':\n",
        "        # Cr√©er structure de dossiers\n",
        "        create_sample_structure()\n",
        "\n",
        "    elif args.mode == 'train':\n",
        "        # Entra√Ænement\n",
        "        config = get_config(args.classA, args.classB)\n",
        "        config['n_epochs'] = args.epochs\n",
        "        config['batch_size'] = args.batch_size\n",
        "\n",
        "        # Transforms\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((config['img_size'], config['img_size'])),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        try:\n",
        "            dataset = CelestialDataset(\n",
        "                root_classA=config['classA_dir'],\n",
        "                root_classB=config['classB_dir'],\n",
        "                transform=transform,\n",
        "                max_images=config['max_images']\n",
        "            )\n",
        "\n",
        "            dataloader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=config['batch_size'],\n",
        "                shuffle=True,\n",
        "                num_workers=config['num_workers'],\n",
        "                pin_memory=True,\n",
        "                drop_last=True\n",
        "            )\n",
        "\n",
        "            trainer = CycleGANTrainer(config)\n",
        "            trainer.train(dataloader)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur: {e}\")\n",
        "\n",
        "    elif args.mode == 'inference':\n",
        "        # Inf√©rence\n",
        "        if not args.checkpoint:\n",
        "            print(\"‚ùå Erreur: --checkpoint requis pour l'inf√©rence\")\n",
        "        elif not args.input:\n",
        "            print(\"‚ùå Erreur: --input requis pour l'inf√©rence\")\n",
        "        else:\n",
        "            inferencer = CycleGANInference(args.checkpoint)\n",
        "\n",
        "            if os.path.isdir(args.input):\n",
        "                # Traduire dossier\n",
        "                inferencer.batch_translate(\n",
        "                    args.input,\n",
        "                    args.output,\n",
        "                    direction=args.direction\n",
        "                )\n",
        "            else:\n",
        "                # Traduire image unique\n",
        "                os.makedirs(args.output, exist_ok=True)\n",
        "                output_path = os.path.join(args.output, 'translated.png')\n",
        "\n",
        "                if args.direction == 'A2B':\n",
        "                    inferencer.translate_A2B(args.input, output_path)\n",
        "                else:\n",
        "                    inferencer.translate_B2A(args.input, output_path)\n",
        "\n",
        "    elif args.mode == 'test':\n",
        "        # Test rapide\n",
        "        quick_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1IHxZAve2GL",
        "outputId": "f3cbd00c-0bd4-47ff-95f1-26635fd65870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source = \"/content/drive/MyDrive/entainement/classeB\"\n",
        "destination = \"/content/classeB\"\n",
        "\n",
        "# Cr√©er le dossier destination s'il n'existe pas\n",
        "os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "# Copier tous les fichiers\n",
        "for filename in os.listdir(source):\n",
        "    source_path = os.path.join(source, filename)\n",
        "    destination_path = os.path.join(destination, filename)\n",
        "\n",
        "    if os.path.isfile(source_path):  # V√©rifier que c'est un fichier\n",
        "        shutil.copy(source_path, destination_path)\n",
        "        print(f\"Copi√©: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZDaXpzEhgK6",
        "outputId": "58afd998-164a-4c72-e7e4-78b29b2f1d68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copi√©: image_00001.jpg\n",
            "Copi√©: image_00002.jpg\n",
            "Copi√©: image_00003.jpg\n",
            "Copi√©: image_00004.jpg\n",
            "Copi√©: image_00005.jpg\n",
            "Copi√©: image_00006.jpg\n",
            "Copi√©: image_00007.jpg\n",
            "Copi√©: image_00008.jpg\n",
            "Copi√©: image_00009.jpg\n",
            "Copi√©: image_00010.jpg\n",
            "Copi√©: image_00011.jpg\n",
            "Copi√©: image_00012.jpg\n",
            "Copi√©: image_00013.jpg\n",
            "Copi√©: image_00014.jpg\n",
            "Copi√©: image_00015.jpg\n",
            "Copi√©: image_00016.jpg\n",
            "Copi√©: image_00017.jpg\n",
            "Copi√©: image_00018.jpg\n",
            "Copi√©: image_00019.jpg\n",
            "Copi√©: image_00020.jpg\n",
            "Copi√©: image_00021.jpg\n",
            "Copi√©: image_00022.jpg\n",
            "Copi√©: image_00023.jpg\n",
            "Copi√©: image_00024.jpg\n",
            "Copi√©: image_00025.jpg\n",
            "Copi√©: image_00026.jpg\n",
            "Copi√©: image_00027.jpg\n",
            "Copi√©: image_00028.jpg\n",
            "Copi√©: image_00029.jpg\n",
            "Copi√©: image_00030.jpg\n",
            "Copi√©: image_00031.jpg\n",
            "Copi√©: image_00032.jpg\n",
            "Copi√©: image_00033.jpg\n",
            "Copi√©: image_00034.jpg\n",
            "Copi√©: image_00035.jpg\n",
            "Copi√©: image_00036.jpg\n",
            "Copi√©: image_00037.jpg\n",
            "Copi√©: image_00038.jpg\n",
            "Copi√©: image_00039.jpg\n",
            "Copi√©: image_00040.jpg\n",
            "Copi√©: image_00041.jpg\n",
            "Copi√©: image_00042.jpg\n",
            "Copi√©: image_00043.jpg\n",
            "Copi√©: image_00044.jpg\n",
            "Copi√©: image_00045.jpg\n",
            "Copi√©: image_00046.jpg\n",
            "Copi√©: image_00047.jpg\n",
            "Copi√©: image_00048.jpg\n",
            "Copi√©: image_00049.jpg\n",
            "Copi√©: image_00050.jpg\n",
            "Copi√©: image_00051.jpg\n",
            "Copi√©: image_00052.jpg\n",
            "Copi√©: image_00053.jpg\n",
            "Copi√©: image_00054.jpg\n",
            "Copi√©: image_00055.jpg\n",
            "Copi√©: image_00056.jpg\n",
            "Copi√©: image_00057.jpg\n",
            "Copi√©: image_00058.jpg\n",
            "Copi√©: image_00059.jpg\n",
            "Copi√©: image_00060.jpg\n",
            "Copi√©: image_00061.jpg\n",
            "Copi√©: image_00062.jpg\n",
            "Copi√©: image_00063.jpg\n",
            "Copi√©: image_00064.jpg\n",
            "Copi√©: image_00065.jpg\n",
            "Copi√©: image_00066.jpg\n",
            "Copi√©: image_00067.jpg\n",
            "Copi√©: image_00068.jpg\n",
            "Copi√©: image_00069.jpg\n",
            "Copi√©: image_00070.jpg\n",
            "Copi√©: image_00071.jpg\n",
            "Copi√©: image_00072.jpg\n",
            "Copi√©: image_00073.jpg\n",
            "Copi√©: image_00074.jpg\n",
            "Copi√©: image_00075.jpg\n",
            "Copi√©: image_00076.jpg\n",
            "Copi√©: image_00077.jpg\n",
            "Copi√©: image_00078.jpg\n",
            "Copi√©: image_00079.jpg\n",
            "Copi√©: image_00080.jpg\n",
            "Copi√©: image_00081.jpg\n",
            "Copi√©: image_00082.jpg\n",
            "Copi√©: image_00083.jpg\n",
            "Copi√©: image_00084.jpg\n",
            "Copi√©: image_00085.jpg\n",
            "Copi√©: image_00086.jpg\n",
            "Copi√©: image_00087.jpg\n",
            "Copi√©: image_00088.jpg\n",
            "Copi√©: image_00089.jpg\n",
            "Copi√©: image_00090.jpg\n",
            "Copi√©: image_00091.jpg\n",
            "Copi√©: image_00092.jpg\n",
            "Copi√©: image_00093.jpg\n",
            "Copi√©: image_00094.jpg\n",
            "Copi√©: image_00095.jpg\n",
            "Copi√©: image_00096.jpg\n",
            "Copi√©: image_00097.jpg\n",
            "Copi√©: image_00098.jpg\n",
            "Copi√©: image_00099.jpg\n",
            "Copi√©: image_00100.jpg\n",
            "Copi√©: image_00101.jpg\n",
            "Copi√©: image_00102.jpg\n",
            "Copi√©: image_00103.jpg\n",
            "Copi√©: image_00104.jpg\n",
            "Copi√©: image_00105.jpg\n",
            "Copi√©: image_00106.jpg\n",
            "Copi√©: image_00107.jpg\n",
            "Copi√©: image_00108.jpg\n",
            "Copi√©: image_00109.jpg\n",
            "Copi√©: image_00110.jpg\n",
            "Copi√©: image_00111.jpg\n",
            "Copi√©: image_00112.jpg\n",
            "Copi√©: image_00113.jpg\n",
            "Copi√©: image_00114.jpg\n",
            "Copi√©: image_00115.jpg\n",
            "Copi√©: image_00116.jpg\n",
            "Copi√©: image_00117.jpg\n",
            "Copi√©: image_00118.jpg\n",
            "Copi√©: image_00119.jpg\n",
            "Copi√©: image_00120.jpg\n",
            "Copi√©: image_00121.jpg\n",
            "Copi√©: image_00122.jpg\n",
            "Copi√©: image_00123.jpg\n",
            "Copi√©: image_00124.jpg\n",
            "Copi√©: image_00125.jpg\n",
            "Copi√©: image_00126.jpg\n",
            "Copi√©: image_00127.jpg\n",
            "Copi√©: image_00128.jpg\n",
            "Copi√©: image_00129.jpg\n",
            "Copi√©: image_00130.jpg\n",
            "Copi√©: image_00131.jpg\n",
            "Copi√©: image_00132.jpg\n",
            "Copi√©: image_00133.jpg\n",
            "Copi√©: image_00134.jpg\n",
            "Copi√©: image_00135.jpg\n",
            "Copi√©: image_00136.jpg\n",
            "Copi√©: image_00137.jpg\n",
            "Copi√©: image_00138.jpg\n",
            "Copi√©: image_00139.jpg\n",
            "Copi√©: image_00140.jpg\n",
            "Copi√©: image_00141.jpg\n",
            "Copi√©: image_00142.jpg\n",
            "Copi√©: image_00143.jpg\n",
            "Copi√©: image_00144.jpg\n",
            "Copi√©: image_00145.jpg\n",
            "Copi√©: image_00146.jpg\n",
            "Copi√©: image_00147.jpg\n",
            "Copi√©: image_00148.jpg\n",
            "Copi√©: image_00149.jpg\n",
            "Copi√©: image_00150.jpg\n",
            "Copi√©: image_00151.jpg\n",
            "Copi√©: image_00152.jpg\n",
            "Copi√©: image_00153.jpg\n",
            "Copi√©: image_00154.jpg\n",
            "Copi√©: image_00155.jpg\n",
            "Copi√©: image_00156.jpg\n",
            "Copi√©: image_00157.jpg\n",
            "Copi√©: image_00158.jpg\n",
            "Copi√©: image_00159.jpg\n",
            "Copi√©: image_00160.jpg\n",
            "Copi√©: image_00161.jpg\n",
            "Copi√©: image_00162.jpg\n",
            "Copi√©: image_00163.jpg\n",
            "Copi√©: image_00164.jpg\n",
            "Copi√©: image_00165.jpg\n",
            "Copi√©: image_00166.jpg\n",
            "Copi√©: image_00167.jpg\n",
            "Copi√©: image_00168.jpg\n",
            "Copi√©: image_00169.jpg\n",
            "Copi√©: image_00170.jpg\n",
            "Copi√©: image_00171.jpg\n",
            "Copi√©: image_00172.jpg\n",
            "Copi√©: image_00173.jpg\n",
            "Copi√©: image_00174.jpg\n",
            "Copi√©: image_00175.jpg\n",
            "Copi√©: image_00176.jpg\n",
            "Copi√©: image_00177.jpg\n",
            "Copi√©: image_00178.jpg\n",
            "Copi√©: image_00179.jpg\n",
            "Copi√©: image_00180.jpg\n",
            "Copi√©: image_00181.jpg\n",
            "Copi√©: image_00182.jpg\n",
            "Copi√©: image_00183.jpg\n",
            "Copi√©: image_00184.jpg\n",
            "Copi√©: image_00185.jpg\n",
            "Copi√©: image_00186.jpg\n",
            "Copi√©: image_00187.jpg\n",
            "Copi√©: image_00188.jpg\n",
            "Copi√©: image_00189.jpg\n",
            "Copi√©: image_00190.jpg\n",
            "Copi√©: image_00191.jpg\n",
            "Copi√©: image_00192.jpg\n",
            "Copi√©: image_00193.jpg\n",
            "Copi√©: image_00194.jpg\n",
            "Copi√©: image_00195.jpg\n",
            "Copi√©: image_00196.jpg\n",
            "Copi√©: image_00197.jpg\n",
            "Copi√©: image_00198.jpg\n",
            "Copi√©: image_00199.jpg\n",
            "Copi√©: image_00200.jpg\n",
            "Copi√©: image_00201.jpg\n",
            "Copi√©: image_00202.jpg\n",
            "Copi√©: image_00203.jpg\n",
            "Copi√©: image_00204.jpg\n",
            "Copi√©: image_00205.jpg\n",
            "Copi√©: image_00206.jpg\n",
            "Copi√©: image_00207.jpg\n",
            "Copi√©: image_00208.jpg\n",
            "Copi√©: image_00209.jpg\n",
            "Copi√©: image_00210.jpg\n",
            "Copi√©: image_00211.jpg\n",
            "Copi√©: image_00212.jpg\n",
            "Copi√©: image_00213.jpg\n",
            "Copi√©: image_00214.jpg\n",
            "Copi√©: image_00215.jpg\n",
            "Copi√©: image_00216.jpg\n",
            "Copi√©: image_00217.jpg\n",
            "Copi√©: image_00218.jpg\n",
            "Copi√©: image_00219.jpg\n",
            "Copi√©: image_00220.jpg\n",
            "Copi√©: image_00221.jpg\n",
            "Copi√©: image_00222.jpg\n",
            "Copi√©: image_00223.jpg\n",
            "Copi√©: image_00224.jpg\n",
            "Copi√©: image_00225.jpg\n",
            "Copi√©: image_00226.jpg\n",
            "Copi√©: image_00227.jpg\n",
            "Copi√©: image_00228.jpg\n",
            "Copi√©: image_00229.jpg\n",
            "Copi√©: image_00230.jpg\n",
            "Copi√©: image_00231.jpg\n",
            "Copi√©: image_00232.jpg\n",
            "Copi√©: image_00233.jpg\n",
            "Copi√©: image_00234.jpg\n",
            "Copi√©: image_00235.jpg\n",
            "Copi√©: image_00236.jpg\n",
            "Copi√©: image_00237.jpg\n",
            "Copi√©: image_00238.jpg\n",
            "Copi√©: image_00239.jpg\n",
            "Copi√©: image_00240.jpg\n",
            "Copi√©: image_00241.jpg\n",
            "Copi√©: image_00242.jpg\n",
            "Copi√©: image_00243.jpg\n",
            "Copi√©: image_00244.jpg\n",
            "Copi√©: image_00245.jpg\n",
            "Copi√©: image_00246.jpg\n",
            "Copi√©: image_00247.jpg\n",
            "Copi√©: image_00248.jpg\n",
            "Copi√©: image_00249.jpg\n",
            "Copi√©: image_00250.jpg\n",
            "Copi√©: image_00251.jpg\n",
            "Copi√©: image_00252.jpg\n",
            "Copi√©: image_00253.jpg\n",
            "Copi√©: image_00254.jpg\n",
            "Copi√©: image_00255.jpg\n",
            "Copi√©: image_00256.jpg\n",
            "Copi√©: image_00257.jpg\n",
            "Copi√©: image_00258.jpg\n",
            "Copi√©: image_00259.jpg\n",
            "Copi√©: image_00260.jpg\n",
            "Copi√©: image_00261.jpg\n",
            "Copi√©: image_00262.jpg\n",
            "Copi√©: image_00263.jpg\n",
            "Copi√©: image_00264.jpg\n",
            "Copi√©: image_00265.jpg\n",
            "Copi√©: image_00266.jpg\n",
            "Copi√©: image_00267.jpg\n",
            "Copi√©: image_00268.jpg\n",
            "Copi√©: image_00269.jpg\n",
            "Copi√©: image_00270.jpg\n",
            "Copi√©: image_00271.jpg\n",
            "Copi√©: image_00272.jpg\n",
            "Copi√©: image_00273.jpg\n",
            "Copi√©: image_00274.jpg\n",
            "Copi√©: image_00275.jpg\n",
            "Copi√©: image_00276.jpg\n",
            "Copi√©: image_00277.jpg\n",
            "Copi√©: image_00278.jpg\n",
            "Copi√©: image_00279.jpg\n",
            "Copi√©: image_00280.jpg\n",
            "Copi√©: image_00281.jpg\n",
            "Copi√©: image_00282.jpg\n",
            "Copi√©: image_00283.jpg\n",
            "Copi√©: image_00284.jpg\n",
            "Copi√©: image_00285.jpg\n",
            "Copi√©: image_00286.jpg\n",
            "Copi√©: image_00287.jpg\n",
            "Copi√©: image_00288.jpg\n",
            "Copi√©: image_00289.jpg\n",
            "Copi√©: image_00290.jpg\n",
            "Copi√©: image_00291.jpg\n",
            "Copi√©: image_00292.jpg\n",
            "Copi√©: image_00293.jpg\n",
            "Copi√©: image_00294.jpg\n",
            "Copi√©: image_00295.jpg\n",
            "Copi√©: image_00296.jpg\n",
            "Copi√©: image_00297.jpg\n",
            "Copi√©: image_00298.jpg\n",
            "Copi√©: image_00299.jpg\n",
            "Copi√©: image_00300.jpg\n",
            "Copi√©: image_00301.jpg\n",
            "Copi√©: image_00302.jpg\n",
            "Copi√©: image_00303.jpg\n",
            "Copi√©: image_00304.jpg\n",
            "Copi√©: image_00305.jpg\n",
            "Copi√©: image_00306.jpg\n",
            "Copi√©: image_00307.jpg\n",
            "Copi√©: image_00308.jpg\n",
            "Copi√©: image_00309.jpg\n",
            "Copi√©: image_00310.jpg\n",
            "Copi√©: image_00311.jpg\n",
            "Copi√©: image_00312.jpg\n",
            "Copi√©: image_00313.jpg\n",
            "Copi√©: image_00314.jpg\n",
            "Copi√©: image_00315.jpg\n",
            "Copi√©: image_00316.jpg\n",
            "Copi√©: image_00317.jpg\n",
            "Copi√©: image_00318.jpg\n",
            "Copi√©: image_00319.jpg\n",
            "Copi√©: image_00320.jpg\n",
            "Copi√©: image_00321.jpg\n",
            "Copi√©: image_00322.jpg\n",
            "Copi√©: image_00323.jpg\n",
            "Copi√©: image_00324.jpg\n",
            "Copi√©: image_00325.jpg\n",
            "Copi√©: image_00326.jpg\n",
            "Copi√©: image_00327.jpg\n",
            "Copi√©: image_00328.jpg\n",
            "Copi√©: image_00329.jpg\n",
            "Copi√©: image_00330.jpg\n",
            "Copi√©: image_00331.jpg\n",
            "Copi√©: image_00332.jpg\n",
            "Copi√©: image_00333.jpg\n",
            "Copi√©: image_00334.jpg\n",
            "Copi√©: image_00335.jpg\n",
            "Copi√©: image_00336.jpg\n",
            "Copi√©: image_00337.jpg\n",
            "Copi√©: image_00338.jpg\n",
            "Copi√©: image_00339.jpg\n",
            "Copi√©: image_00340.jpg\n",
            "Copi√©: image_00341.jpg\n",
            "Copi√©: image_00342.jpg\n",
            "Copi√©: image_00343.jpg\n",
            "Copi√©: image_00344.jpg\n",
            "Copi√©: image_00345.jpg\n",
            "Copi√©: image_00346.jpg\n",
            "Copi√©: image_00347.jpg\n",
            "Copi√©: image_00348.jpg\n",
            "Copi√©: image_00349.jpg\n",
            "Copi√©: image_00350.jpg\n",
            "Copi√©: image_00351.jpg\n",
            "Copi√©: image_00352.jpg\n",
            "Copi√©: image_00353.jpg\n",
            "Copi√©: image_00354.jpg\n",
            "Copi√©: image_00355.jpg\n",
            "Copi√©: image_00356.jpg\n",
            "Copi√©: image_00357.jpg\n",
            "Copi√©: image_00358.jpg\n",
            "Copi√©: image_00359.jpg\n",
            "Copi√©: image_00360.jpg\n",
            "Copi√©: image_00361.jpg\n",
            "Copi√©: image_00362.jpg\n",
            "Copi√©: image_00363.jpg\n",
            "Copi√©: image_00364.jpg\n",
            "Copi√©: image_00365.jpg\n",
            "Copi√©: image_00366.jpg\n",
            "Copi√©: image_00367.jpg\n",
            "Copi√©: image_00368.jpg\n",
            "Copi√©: image_00369.jpg\n",
            "Copi√©: image_00370.jpg\n",
            "Copi√©: image_00371.jpg\n",
            "Copi√©: image_00372.jpg\n",
            "Copi√©: image_00373.jpg\n",
            "Copi√©: image_00374.jpg\n",
            "Copi√©: image_00375.jpg\n",
            "Copi√©: image_00376.jpg\n",
            "Copi√©: image_00377.jpg\n",
            "Copi√©: image_00378.jpg\n",
            "Copi√©: image_00379.jpg\n",
            "Copi√©: image_00380.jpg\n",
            "Copi√©: image_00381.jpg\n",
            "Copi√©: image_00382.jpg\n",
            "Copi√©: image_00383.jpg\n",
            "Copi√©: image_00384.jpg\n",
            "Copi√©: image_00385.jpg\n",
            "Copi√©: image_00386.jpg\n",
            "Copi√©: image_00387.jpg\n",
            "Copi√©: image_00388.jpg\n",
            "Copi√©: image_00389.jpg\n",
            "Copi√©: image_00390.jpg\n",
            "Copi√©: image_00391.jpg\n",
            "Copi√©: image_00392.jpg\n",
            "Copi√©: image_00393.jpg\n",
            "Copi√©: image_00394.jpg\n",
            "Copi√©: image_00395.jpg\n",
            "Copi√©: image_00396.jpg\n",
            "Copi√©: image_00397.jpg\n",
            "Copi√©: image_00398.jpg\n",
            "Copi√©: image_00399.jpg\n",
            "Copi√©: image_00400.jpg\n",
            "Copi√©: image_00401.jpg\n",
            "Copi√©: image_00402.jpg\n",
            "Copi√©: image_00403.jpg\n",
            "Copi√©: image_00404.jpg\n",
            "Copi√©: image_00405.jpg\n",
            "Copi√©: image_00406.jpg\n",
            "Copi√©: image_00407.jpg\n",
            "Copi√©: image_00408.jpg\n",
            "Copi√©: image_00409.jpg\n",
            "Copi√©: image_00410.jpg\n",
            "Copi√©: image_00411.jpg\n",
            "Copi√©: image_00412.jpg\n",
            "Copi√©: image_00413.jpg\n",
            "Copi√©: image_00414.jpg\n",
            "Copi√©: image_00415.jpg\n",
            "Copi√©: image_00416.jpg\n",
            "Copi√©: image_00417.jpg\n",
            "Copi√©: image_00418.jpg\n",
            "Copi√©: image_00419.jpg\n",
            "Copi√©: image_00420.jpg\n",
            "Copi√©: image_00421.jpg\n",
            "Copi√©: image_00422.jpg\n",
            "Copi√©: image_00423.jpg\n",
            "Copi√©: image_00424.jpg\n",
            "Copi√©: image_00425.jpg\n",
            "Copi√©: image_00426.jpg\n",
            "Copi√©: image_00427.jpg\n",
            "Copi√©: image_00428.jpg\n",
            "Copi√©: image_00429.jpg\n",
            "Copi√©: image_00430.jpg\n",
            "Copi√©: image_00431.jpg\n",
            "Copi√©: image_00432.jpg\n",
            "Copi√©: image_00433.jpg\n",
            "Copi√©: image_00434.jpg\n",
            "Copi√©: image_00435.jpg\n",
            "Copi√©: image_00436.jpg\n",
            "Copi√©: image_00437.jpg\n",
            "Copi√©: image_00438.jpg\n",
            "Copi√©: image_00439.jpg\n",
            "Copi√©: image_00440.jpg\n",
            "Copi√©: image_00441.jpg\n",
            "Copi√©: image_00442.jpg\n",
            "Copi√©: image_00443.jpg\n",
            "Copi√©: image_00444.jpg\n",
            "Copi√©: image_00445.jpg\n",
            "Copi√©: image_00446.jpg\n",
            "Copi√©: image_00447.jpg\n",
            "Copi√©: image_00448.jpg\n",
            "Copi√©: image_00449.jpg\n",
            "Copi√©: image_00450.jpg\n",
            "Copi√©: image_00451.jpg\n",
            "Copi√©: image_00452.jpg\n",
            "Copi√©: image_00453.jpg\n",
            "Copi√©: image_00454.jpg\n",
            "Copi√©: image_00455.jpg\n",
            "Copi√©: image_00456.jpg\n",
            "Copi√©: image_00457.jpg\n",
            "Copi√©: image_00458.jpg\n",
            "Copi√©: image_00459.jpg\n",
            "Copi√©: image_00460.jpg\n",
            "Copi√©: image_00461.jpg\n",
            "Copi√©: image_00462.jpg\n",
            "Copi√©: image_00463.jpg\n",
            "Copi√©: image_00464.jpg\n",
            "Copi√©: image_00465.jpg\n",
            "Copi√©: image_00466.jpg\n",
            "Copi√©: image_00467.jpg\n",
            "Copi√©: image_00468.jpg\n",
            "Copi√©: image_00469.jpg\n",
            "Copi√©: image_00470.jpg\n",
            "Copi√©: image_00471.jpg\n",
            "Copi√©: image_00472.jpg\n",
            "Copi√©: image_00473.jpg\n",
            "Copi√©: image_00474.jpg\n",
            "Copi√©: image_00475.jpg\n",
            "Copi√©: image_00476.jpg\n",
            "Copi√©: image_00477.jpg\n",
            "Copi√©: image_00478.jpg\n",
            "Copi√©: image_00479.jpg\n",
            "Copi√©: image_00480.jpg\n",
            "Copi√©: image_00481.jpg\n",
            "Copi√©: image_00482.jpg\n",
            "Copi√©: image_00483.jpg\n",
            "Copi√©: image_00484.jpg\n",
            "Copi√©: image_00485.jpg\n",
            "Copi√©: image_00486.jpg\n",
            "Copi√©: image_00487.jpg\n",
            "Copi√©: image_00488.jpg\n",
            "Copi√©: image_00489.jpg\n",
            "Copi√©: image_00490.jpg\n",
            "Copi√©: image_00491.jpg\n",
            "Copi√©: image_00492.jpg\n",
            "Copi√©: image_00493.jpg\n",
            "Copi√©: image_00494.jpg\n",
            "Copi√©: image_00495.jpg\n",
            "Copi√©: image_00496.jpg\n",
            "Copi√©: image_00497.jpg\n",
            "Copi√©: image_00498.jpg\n",
            "Copi√©: image_00499.jpg\n",
            "Copi√©: image_00500.jpg\n",
            "Copi√©: image_00501.jpg\n",
            "Copi√©: image_00502.jpg\n",
            "Copi√©: image_00503.jpg\n",
            "Copi√©: image_00504.jpg\n",
            "Copi√©: image_00505.jpg\n",
            "Copi√©: image_00506.jpg\n",
            "Copi√©: image_00507.jpg\n",
            "Copi√©: image_00508.jpg\n",
            "Copi√©: image_00509.jpg\n",
            "Copi√©: image_00510.jpg\n",
            "Copi√©: image_00511.jpg\n",
            "Copi√©: image_00512.jpg\n",
            "Copi√©: image_00513.jpg\n",
            "Copi√©: image_00514.jpg\n",
            "Copi√©: image_00515.jpg\n",
            "Copi√©: image_00516.jpg\n",
            "Copi√©: image_00517.jpg\n",
            "Copi√©: image_00518.jpg\n",
            "Copi√©: image_00519.jpg\n",
            "Copi√©: image_00520.jpg\n",
            "Copi√©: image_00521.jpg\n",
            "Copi√©: image_00522.jpg\n",
            "Copi√©: image_00523.jpg\n",
            "Copi√©: image_00524.jpg\n",
            "Copi√©: image_00525.jpg\n",
            "Copi√©: image_00526.jpg\n",
            "Copi√©: image_00527.jpg\n",
            "Copi√©: image_00528.jpg\n",
            "Copi√©: image_00529.jpg\n",
            "Copi√©: image_00530.jpg\n",
            "Copi√©: image_00531.jpg\n",
            "Copi√©: image_00532.jpg\n",
            "Copi√©: image_00533.jpg\n",
            "Copi√©: image_00534.jpg\n",
            "Copi√©: image_00535.jpg\n",
            "Copi√©: image_00536.jpg\n",
            "Copi√©: image_00537.jpg\n",
            "Copi√©: image_00538.jpg\n",
            "Copi√©: image_00539.jpg\n",
            "Copi√©: image_00540.jpg\n",
            "Copi√©: image_00541.jpg\n",
            "Copi√©: image_00542.jpg\n",
            "Copi√©: image_00543.jpg\n",
            "Copi√©: image_00544.jpg\n",
            "Copi√©: image_00545.jpg\n",
            "Copi√©: image_00546.jpg\n",
            "Copi√©: image_00547.jpg\n",
            "Copi√©: image_00548.jpg\n",
            "Copi√©: image_00549.jpg\n",
            "Copi√©: image_00550.jpg\n",
            "Copi√©: image_00551.jpg\n",
            "Copi√©: image_00552.jpg\n",
            "Copi√©: image_00553.jpg\n",
            "Copi√©: image_00554.jpg\n",
            "Copi√©: image_00555.jpg\n",
            "Copi√©: image_00556.jpg\n",
            "Copi√©: image_00557.jpg\n",
            "Copi√©: image_00558.jpg\n",
            "Copi√©: image_00559.jpg\n",
            "Copi√©: image_00560.jpg\n",
            "Copi√©: image_00561.jpg\n",
            "Copi√©: image_00562.jpg\n",
            "Copi√©: image_00563.jpg\n",
            "Copi√©: image_00564.jpg\n",
            "Copi√©: image_00565.jpg\n",
            "Copi√©: image_00566.jpg\n",
            "Copi√©: image_00567.jpg\n",
            "Copi√©: image_00568.jpg\n",
            "Copi√©: image_00569.jpg\n",
            "Copi√©: image_00570.jpg\n",
            "Copi√©: image_00571.jpg\n",
            "Copi√©: image_00572.jpg\n",
            "Copi√©: image_00573.jpg\n",
            "Copi√©: image_00574.jpg\n",
            "Copi√©: image_00575.jpg\n",
            "Copi√©: image_00576.jpg\n",
            "Copi√©: image_00577.jpg\n",
            "Copi√©: image_00578.jpg\n",
            "Copi√©: image_00579.jpg\n",
            "Copi√©: image_00580.jpg\n",
            "Copi√©: image_00581.jpg\n",
            "Copi√©: image_00582.jpg\n",
            "Copi√©: image_00583.jpg\n",
            "Copi√©: image_00584.jpg\n",
            "Copi√©: image_00585.jpg\n",
            "Copi√©: image_00586.jpg\n",
            "Copi√©: image_00587.jpg\n",
            "Copi√©: image_00588.jpg\n",
            "Copi√©: image_00589.jpg\n",
            "Copi√©: image_00590.jpg\n",
            "Copi√©: image_00591.jpg\n",
            "Copi√©: image_00592.jpg\n",
            "Copi√©: image_00593.jpg\n",
            "Copi√©: image_00594.jpg\n",
            "Copi√©: image_00595.jpg\n",
            "Copi√©: image_00596.jpg\n",
            "Copi√©: image_00597.jpg\n",
            "Copi√©: image_00598.jpg\n",
            "Copi√©: image_00599.jpg\n",
            "Copi√©: image_00600.jpg\n",
            "Copi√©: image_00601.jpg\n",
            "Copi√©: image_00602.jpg\n",
            "Copi√©: image_00603.jpg\n",
            "Copi√©: image_00604.jpg\n",
            "Copi√©: image_00605.jpg\n",
            "Copi√©: image_00606.jpg\n",
            "Copi√©: image_00607.jpg\n",
            "Copi√©: image_00608.jpg\n",
            "Copi√©: image_00609.jpg\n",
            "Copi√©: image_00610.jpg\n",
            "Copi√©: image_00611.jpg\n",
            "Copi√©: image_00612.jpg\n",
            "Copi√©: image_00613.jpg\n",
            "Copi√©: image_00614.jpg\n",
            "Copi√©: image_00615.jpg\n",
            "Copi√©: image_00616.jpg\n",
            "Copi√©: image_00617.jpg\n",
            "Copi√©: image_00618.jpg\n",
            "Copi√©: image_00619.jpg\n",
            "Copi√©: image_00620.jpg\n",
            "Copi√©: image_00621.jpg\n",
            "Copi√©: image_00622.jpg\n",
            "Copi√©: image_00623.jpg\n",
            "Copi√©: image_00624.jpg\n",
            "Copi√©: image_00625.jpg\n",
            "Copi√©: image_00626.jpg\n",
            "Copi√©: image_00627.jpg\n",
            "Copi√©: image_00628.jpg\n",
            "Copi√©: image_00629.jpg\n",
            "Copi√©: image_00630.jpg\n",
            "Copi√©: image_00631.jpg\n",
            "Copi√©: image_00632.jpg\n",
            "Copi√©: image_00633.jpg\n",
            "Copi√©: image_00634.jpg\n",
            "Copi√©: image_00635.jpg\n",
            "Copi√©: image_00636.jpg\n",
            "Copi√©: image_00637.jpg\n",
            "Copi√©: image_00638.jpg\n",
            "Copi√©: image_00639.jpg\n",
            "Copi√©: image_00640.jpg\n",
            "Copi√©: image_00641.jpg\n",
            "Copi√©: image_00642.jpg\n",
            "Copi√©: image_00643.jpg\n",
            "Copi√©: image_00644.jpg\n",
            "Copi√©: image_00645.jpg\n",
            "Copi√©: image_00646.jpg\n",
            "Copi√©: image_00647.jpg\n",
            "Copi√©: image_00648.jpg\n",
            "Copi√©: image_00649.jpg\n",
            "Copi√©: image_00650.jpg\n",
            "Copi√©: image_00651.jpg\n",
            "Copi√©: image_00652.jpg\n",
            "Copi√©: image_00653.jpg\n",
            "Copi√©: image_00654.jpg\n",
            "Copi√©: image_00655.jpg\n",
            "Copi√©: image_00656.jpg\n",
            "Copi√©: image_00657.jpg\n",
            "Copi√©: image_00658.jpg\n",
            "Copi√©: image_00659.jpg\n",
            "Copi√©: image_00660.jpg\n",
            "Copi√©: image_00661.jpg\n",
            "Copi√©: image_00662.jpg\n",
            "Copi√©: image_00663.jpg\n",
            "Copi√©: image_00664.jpg\n",
            "Copi√©: image_00665.jpg\n",
            "Copi√©: image_00666.jpg\n",
            "Copi√©: image_00667.jpg\n",
            "Copi√©: image_00668.jpg\n",
            "Copi√©: image_00669.jpg\n",
            "Copi√©: image_00670.jpg\n",
            "Copi√©: image_00671.jpg\n",
            "Copi√©: image_00672.jpg\n",
            "Copi√©: image_00673.jpg\n",
            "Copi√©: image_00674.jpg\n",
            "Copi√©: image_00675.jpg\n",
            "Copi√©: image_00676.jpg\n",
            "Copi√©: image_00677.jpg\n",
            "Copi√©: image_00678.jpg\n",
            "Copi√©: image_00679.jpg\n",
            "Copi√©: image_00680.jpg\n",
            "Copi√©: image_00681.jpg\n",
            "Copi√©: image_00682.jpg\n",
            "Copi√©: image_00683.jpg\n",
            "Copi√©: image_00684.jpg\n",
            "Copi√©: image_00685.jpg\n",
            "Copi√©: image_00686.jpg\n",
            "Copi√©: image_00687.jpg\n",
            "Copi√©: image_00688.jpg\n",
            "Copi√©: image_00689.jpg\n",
            "Copi√©: image_00690.jpg\n",
            "Copi√©: image_00691.jpg\n",
            "Copi√©: image_00692.jpg\n",
            "Copi√©: image_00693.jpg\n",
            "Copi√©: image_00694.jpg\n",
            "Copi√©: image_00695.jpg\n",
            "Copi√©: image_00696.jpg\n",
            "Copi√©: image_00697.jpg\n",
            "Copi√©: image_00698.jpg\n",
            "Copi√©: image_00699.jpg\n",
            "Copi√©: image_00700.jpg\n",
            "Copi√©: image_00701.jpg\n",
            "Copi√©: image_00702.jpg\n",
            "Copi√©: image_00703.jpg\n",
            "Copi√©: image_00704.jpg\n",
            "Copi√©: image_00705.jpg\n",
            "Copi√©: image_00706.jpg\n",
            "Copi√©: image_00707.jpg\n",
            "Copi√©: image_00708.jpg\n",
            "Copi√©: image_00709.jpg\n",
            "Copi√©: image_00710.jpg\n",
            "Copi√©: image_00711.jpg\n",
            "Copi√©: image_00712.jpg\n",
            "Copi√©: image_00713.jpg\n",
            "Copi√©: image_00714.jpg\n",
            "Copi√©: image_00715.jpg\n",
            "Copi√©: image_00716.jpg\n",
            "Copi√©: image_00717.jpg\n",
            "Copi√©: image_00718.jpg\n",
            "Copi√©: image_00719.jpg\n",
            "Copi√©: image_00720.jpg\n",
            "Copi√©: image_00721.jpg\n",
            "Copi√©: image_00722.jpg\n",
            "Copi√©: image_00723.jpg\n",
            "Copi√©: image_00724.jpg\n",
            "Copi√©: image_00725.jpg\n",
            "Copi√©: image_00726.jpg\n",
            "Copi√©: image_00727.jpg\n",
            "Copi√©: image_00728.jpg\n",
            "Copi√©: image_00729.jpg\n",
            "Copi√©: image_00730.jpg\n",
            "Copi√©: image_00731.jpg\n",
            "Copi√©: image_00732.jpg\n",
            "Copi√©: image_00733.jpg\n",
            "Copi√©: image_00734.jpg\n",
            "Copi√©: image_00735.jpg\n",
            "Copi√©: image_00736.jpg\n",
            "Copi√©: image_00737.jpg\n",
            "Copi√©: image_00738.jpg\n",
            "Copi√©: image_00739.jpg\n",
            "Copi√©: image_00740.jpg\n",
            "Copi√©: image_00741.jpg\n",
            "Copi√©: image_00742.jpg\n",
            "Copi√©: image_00743.jpg\n",
            "Copi√©: image_00744.jpg\n",
            "Copi√©: image_00745.jpg\n",
            "Copi√©: image_00746.jpg\n",
            "Copi√©: image_00747.jpg\n",
            "Copi√©: image_00748.jpg\n",
            "Copi√©: image_00749.jpg\n",
            "Copi√©: image_00750.jpg\n",
            "Copi√©: image_00751.jpg\n",
            "Copi√©: image_00752.jpg\n",
            "Copi√©: image_00753.jpg\n",
            "Copi√©: image_00754.jpg\n",
            "Copi√©: image_00755.jpg\n",
            "Copi√©: image_00756.jpg\n",
            "Copi√©: image_00757.jpg\n",
            "Copi√©: image_00758.jpg\n",
            "Copi√©: image_00759.jpg\n",
            "Copi√©: image_00760.jpg\n",
            "Copi√©: image_00761.jpg\n",
            "Copi√©: image_00762.jpg\n",
            "Copi√©: image_00763.jpg\n",
            "Copi√©: image_00764.jpg\n",
            "Copi√©: image_00765.jpg\n",
            "Copi√©: image_00766.jpg\n",
            "Copi√©: image_00767.jpg\n",
            "Copi√©: image_00768.jpg\n",
            "Copi√©: image_00769.jpg\n",
            "Copi√©: image_00770.jpg\n",
            "Copi√©: image_00771.jpg\n",
            "Copi√©: image_00772.jpg\n",
            "Copi√©: image_00773.jpg\n",
            "Copi√©: image_00774.jpg\n",
            "Copi√©: image_00775.jpg\n",
            "Copi√©: image_00776.jpg\n",
            "Copi√©: image_00777.jpg\n",
            "Copi√©: image_00778.jpg\n",
            "Copi√©: image_00779.jpg\n",
            "Copi√©: image_00780.jpg\n",
            "Copi√©: image_00781.jpg\n",
            "Copi√©: image_00782.jpg\n",
            "Copi√©: image_00783.jpg\n",
            "Copi√©: image_00784.jpg\n",
            "Copi√©: image_00785.jpg\n",
            "Copi√©: image_00786.jpg\n",
            "Copi√©: image_00787.jpg\n",
            "Copi√©: image_00788.jpg\n",
            "Copi√©: image_00789.jpg\n",
            "Copi√©: image_00790.jpg\n",
            "Copi√©: image_00791.jpg\n",
            "Copi√©: image_00792.jpg\n",
            "Copi√©: image_00793.jpg\n",
            "Copi√©: image_00794.jpg\n",
            "Copi√©: image_00795.jpg\n",
            "Copi√©: image_00796.jpg\n",
            "Copi√©: image_00797.jpg\n",
            "Copi√©: image_00798.jpg\n",
            "Copi√©: image_00799.jpg\n",
            "Copi√©: image_00800.jpg\n",
            "Copi√©: image_00801.jpg\n",
            "Copi√©: image_00802.jpg\n",
            "Copi√©: image_00803.jpg\n",
            "Copi√©: image_00804.jpg\n",
            "Copi√©: image_00805.jpg\n",
            "Copi√©: image_00806.jpg\n",
            "Copi√©: image_00807.jpg\n",
            "Copi√©: image_00808.jpg\n",
            "Copi√©: image_00809.jpg\n",
            "Copi√©: image_00810.jpg\n",
            "Copi√©: image_00811.jpg\n",
            "Copi√©: image_00812.jpg\n",
            "Copi√©: image_00813.jpg\n",
            "Copi√©: image_00814.jpg\n",
            "Copi√©: image_00815.jpg\n",
            "Copi√©: image_00816.jpg\n",
            "Copi√©: image_00817.jpg\n",
            "Copi√©: image_00818.jpg\n",
            "Copi√©: image_00819.jpg\n",
            "Copi√©: image_00820.jpg\n",
            "Copi√©: image_00821.jpg\n",
            "Copi√©: image_00822.jpg\n",
            "Copi√©: image_00823.jpg\n",
            "Copi√©: image_00824.jpg\n",
            "Copi√©: image_00825.jpg\n",
            "Copi√©: image_00826.jpg\n",
            "Copi√©: image_00827.jpg\n",
            "Copi√©: image_00828.jpg\n",
            "Copi√©: image_00829.jpg\n",
            "Copi√©: image_00830.jpg\n",
            "Copi√©: image_00831.jpg\n",
            "Copi√©: image_00832.jpg\n",
            "Copi√©: image_00833.jpg\n",
            "Copi√©: image_00834.jpg\n",
            "Copi√©: image_00835.jpg\n",
            "Copi√©: image_00836.jpg\n",
            "Copi√©: image_00837.jpg\n",
            "Copi√©: image_00838.jpg\n",
            "Copi√©: image_00839.jpg\n",
            "Copi√©: image_00840.jpg\n",
            "Copi√©: image_00841.jpg\n",
            "Copi√©: image_00842.jpg\n",
            "Copi√©: image_00843.jpg\n",
            "Copi√©: image_00844.jpg\n",
            "Copi√©: image_00845.jpg\n",
            "Copi√©: image_00846.jpg\n",
            "Copi√©: image_00847.jpg\n",
            "Copi√©: image_00848.jpg\n",
            "Copi√©: image_00849.jpg\n",
            "Copi√©: image_00850.jpg\n",
            "Copi√©: image_00851.jpg\n",
            "Copi√©: image_00852.jpg\n",
            "Copi√©: image_00853.jpg\n",
            "Copi√©: image_00854.jpg\n",
            "Copi√©: image_00855.jpg\n",
            "Copi√©: image_00856.jpg\n",
            "Copi√©: image_00857.jpg\n",
            "Copi√©: image_00858.jpg\n",
            "Copi√©: image_00859.jpg\n",
            "Copi√©: image_00860.jpg\n",
            "Copi√©: image_00861.jpg\n",
            "Copi√©: image_00862.jpg\n",
            "Copi√©: image_00863.jpg\n",
            "Copi√©: image_00864.jpg\n",
            "Copi√©: image_00865.jpg\n",
            "Copi√©: image_00866.jpg\n",
            "Copi√©: image_00867.jpg\n",
            "Copi√©: image_00868.jpg\n",
            "Copi√©: image_00869.jpg\n",
            "Copi√©: image_00870.jpg\n",
            "Copi√©: image_00871.jpg\n",
            "Copi√©: image_00872.jpg\n",
            "Copi√©: image_00873.jpg\n",
            "Copi√©: image_00874.jpg\n",
            "Copi√©: image_00875.jpg\n",
            "Copi√©: image_00876.jpg\n",
            "Copi√©: image_00877.jpg\n",
            "Copi√©: image_00878.jpg\n",
            "Copi√©: image_00879.jpg\n",
            "Copi√©: image_00880.jpg\n",
            "Copi√©: image_00881.jpg\n",
            "Copi√©: image_00882.jpg\n",
            "Copi√©: image_00883.jpg\n",
            "Copi√©: image_00884.jpg\n",
            "Copi√©: image_00885.jpg\n",
            "Copi√©: image_00886.jpg\n",
            "Copi√©: image_00887.jpg\n",
            "Copi√©: image_00888.jpg\n",
            "Copi√©: image_00889.jpg\n",
            "Copi√©: image_00890.jpg\n",
            "Copi√©: image_00891.jpg\n",
            "Copi√©: image_00892.jpg\n",
            "Copi√©: image_00893.jpg\n",
            "Copi√©: image_00894.jpg\n",
            "Copi√©: image_00895.jpg\n",
            "Copi√©: image_00896.jpg\n",
            "Copi√©: image_00897.jpg\n",
            "Copi√©: image_00898.jpg\n",
            "Copi√©: image_00899.jpg\n",
            "Copi√©: image_00900.jpg\n",
            "Copi√©: image_00901.jpg\n",
            "Copi√©: image_00902.jpg\n",
            "Copi√©: image_00903.jpg\n",
            "Copi√©: image_00904.jpg\n",
            "Copi√©: image_00905.jpg\n",
            "Copi√©: image_00906.jpg\n",
            "Copi√©: image_00907.jpg\n",
            "Copi√©: image_00908.jpg\n",
            "Copi√©: image_00909.jpg\n",
            "Copi√©: image_00910.jpg\n",
            "Copi√©: image_00911.jpg\n",
            "Copi√©: image_00912.jpg\n",
            "Copi√©: image_00913.jpg\n",
            "Copi√©: image_00914.jpg\n",
            "Copi√©: image_00915.jpg\n",
            "Copi√©: image_00916.jpg\n",
            "Copi√©: image_00917.jpg\n",
            "Copi√©: image_00918.jpg\n",
            "Copi√©: image_00919.jpg\n",
            "Copi√©: image_00920.jpg\n",
            "Copi√©: image_00921.jpg\n",
            "Copi√©: image_00922.jpg\n",
            "Copi√©: image_00923.jpg\n",
            "Copi√©: image_00924.jpg\n",
            "Copi√©: image_00925.jpg\n",
            "Copi√©: image_00926.jpg\n",
            "Copi√©: image_00927.jpg\n",
            "Copi√©: image_00928.jpg\n",
            "Copi√©: image_00929.jpg\n",
            "Copi√©: image_00930.jpg\n",
            "Copi√©: image_00931.jpg\n",
            "Copi√©: image_00932.jpg\n",
            "Copi√©: image_00933.jpg\n",
            "Copi√©: image_00934.jpg\n",
            "Copi√©: image_00935.jpg\n",
            "Copi√©: image_00936.jpg\n",
            "Copi√©: image_00937.jpg\n",
            "Copi√©: image_00938.jpg\n",
            "Copi√©: image_00939.jpg\n",
            "Copi√©: image_00940.jpg\n",
            "Copi√©: image_00941.jpg\n",
            "Copi√©: image_00942.jpg\n",
            "Copi√©: image_00943.jpg\n",
            "Copi√©: image_00944.jpg\n",
            "Copi√©: image_00945.jpg\n",
            "Copi√©: image_00946.jpg\n",
            "Copi√©: image_00947.jpg\n",
            "Copi√©: image_00948.jpg\n",
            "Copi√©: image_00949.jpg\n",
            "Copi√©: image_00950.jpg\n",
            "Copi√©: image_00951.jpg\n",
            "Copi√©: image_00952.jpg\n",
            "Copi√©: image_00953.jpg\n",
            "Copi√©: image_00954.jpg\n",
            "Copi√©: image_00955.jpg\n",
            "Copi√©: image_00956.jpg\n",
            "Copi√©: image_00957.jpg\n",
            "Copi√©: image_00958.jpg\n",
            "Copi√©: image_00959.jpg\n",
            "Copi√©: image_00960.jpg\n",
            "Copi√©: image_00961.jpg\n",
            "Copi√©: image_00962.jpg\n",
            "Copi√©: image_00963.jpg\n",
            "Copi√©: image_00964.jpg\n",
            "Copi√©: image_00965.jpg\n",
            "Copi√©: image_00966.jpg\n",
            "Copi√©: image_00967.jpg\n",
            "Copi√©: image_00968.jpg\n",
            "Copi√©: image_00969.jpg\n",
            "Copi√©: image_00970.jpg\n",
            "Copi√©: image_00971.jpg\n",
            "Copi√©: image_00972.jpg\n",
            "Copi√©: image_00973.jpg\n",
            "Copi√©: image_00974.jpg\n",
            "Copi√©: image_00975.jpg\n",
            "Copi√©: image_00976.jpg\n",
            "Copi√©: image_00977.jpg\n",
            "Copi√©: image_00978.jpg\n",
            "Copi√©: image_00979.jpg\n",
            "Copi√©: image_00980.jpg\n",
            "Copi√©: image_00981.jpg\n",
            "Copi√©: image_00982.jpg\n",
            "Copi√©: image_00983.jpg\n",
            "Copi√©: image_00984.jpg\n",
            "Copi√©: image_00985.jpg\n",
            "Copi√©: image_00986.jpg\n",
            "Copi√©: image_00987.jpg\n",
            "Copi√©: image_00988.jpg\n",
            "Copi√©: image_00989.jpg\n",
            "Copi√©: image_00990.jpg\n",
            "Copi√©: image_00991.jpg\n",
            "Copi√©: image_00992.jpg\n",
            "Copi√©: image_00993.jpg\n",
            "Copi√©: image_00994.jpg\n",
            "Copi√©: image_00995.jpg\n",
            "Copi√©: image_00996.jpg\n",
            "Copi√©: image_00997.jpg\n",
            "Copi√©: image_00998.jpg\n",
            "Copi√©: image_00999.jpg\n",
            "Copi√©: image_01000.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile script.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================================\n",
        "# ARCHITECTURE L√âG√àRE - MobileNet Style (CORRIG√âE)\n",
        "# ============================================================================\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    \"\"\"Convolution s√©parable en profondeur (9x moins de param√®tres)\"\"\"\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_ch, in_ch, 3, stride, 1, groups=in_ch, bias=False)\n",
        "        self.pointwise = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
        "        self.norm = nn.InstanceNorm2d(out_ch)\n",
        "        # ‚úÖ CORRECTION: Retirer inplace=True\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.norm(x)\n",
        "        return self.relu(x)\n",
        "\n",
        "\n",
        "class LightweightResBlock(nn.Module):\n",
        "    \"\"\"Bloc r√©siduel ultra-l√©ger avec Squeeze-Excitation\"\"\"\n",
        "    def __init__(self, channels, reduction=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = DepthwiseSeparableConv(channels, channels)\n",
        "        self.conv2 = DepthwiseSeparableConv(channels, channels)\n",
        "\n",
        "        # Squeeze-Excitation (attention canal simple)\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // reduction, 1),\n",
        "            nn.ReLU(inplace=False),  # ‚úÖ CORRECTION\n",
        "            nn.Conv2d(channels // reduction, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = out * self.se(out)  # Attention\n",
        "        return residual + out * 0.1  # Scaled residual\n",
        "\n",
        "\n",
        "class FastGenerator(nn.Module):\n",
        "    \"\"\"G√©n√©rateur ultra-rapide pour drone\"\"\"\n",
        "    def __init__(self, ngf=32, n_blocks=6):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder (downsampling)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, ngf, 7, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # Down 1: 128x128\n",
        "            DepthwiseSeparableConv(ngf, ngf * 2, stride=2),\n",
        "            # Down 2: 64x64\n",
        "            DepthwiseSeparableConv(ngf * 2, ngf * 4, stride=2),\n",
        "        )\n",
        "\n",
        "        # Transformation (ResBlocks l√©gers)\n",
        "        transform = []\n",
        "        for _ in range(n_blocks):\n",
        "            transform.append(LightweightResBlock(ngf * 4))\n",
        "        self.transform = nn.Sequential(*transform)\n",
        "\n",
        "        # Decoder (upsampling)\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Up 1: 128x128\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, 1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf * 2),\n",
        "            nn.ReLU(inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # Up 2: 256x256\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 3, 2, 1, 1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # Output\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.transform(x)\n",
        "        return self.decoder(x)\n",
        "\n",
        "\n",
        "class FastDiscriminator(nn.Module):\n",
        "    \"\"\"Discriminateur l√©ger (70x70 PatchGAN)\"\"\"\n",
        "    def __init__(self, ndf=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # 128x128\n",
        "            nn.Conv2d(3, ndf, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # 64x64\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # 32x32\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=False),  # ‚úÖ CORRECTION\n",
        "\n",
        "            # 31x31\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET OPTIMIS√â\n",
        "# ============================================================================\n",
        "\n",
        "class FastCelestialDataset(Dataset):\n",
        "    \"\"\"Dataset avec cache en m√©moire et augmentation rapide\"\"\"\n",
        "    def __init__(self, root_A, root_B, img_size=128, cache_size=500):\n",
        "        self.img_size = img_size\n",
        "        self.cache = {}\n",
        "        self.cache_size = cache_size\n",
        "\n",
        "        # Charger chemins\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "        self.files_A = []\n",
        "        self.files_B = []\n",
        "\n",
        "        for ext in extensions:\n",
        "            self.files_A.extend(list(Path(root_A).glob(ext)))\n",
        "            self.files_B.extend(list(Path(root_B).glob(ext)))\n",
        "\n",
        "        self.files_A = sorted(self.files_A)\n",
        "        self.files_B = sorted(self.files_B)\n",
        "\n",
        "        print(f\"üìÇ Dataset: {len(self.files_A)} Real | {len(self.files_B)} Stellarium\")\n",
        "\n",
        "        if not self.files_A or not self.files_B:\n",
        "            raise ValueError(\"‚ùå Aucune image trouv√©e!\")\n",
        "\n",
        "        # Transforms optimis√©s\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size), transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "    def _load_image(self, path, cache_key):\n",
        "        \"\"\"Chargement avec cache\"\"\"\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        # Cache si pas trop grand\n",
        "        if len(self.cache) < self.cache_size:\n",
        "            self.cache[cache_key] = img\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_A = self.files_A[idx % len(self.files_A)]\n",
        "        file_B = self.files_B[idx % len(self.files_B)]\n",
        "\n",
        "        img_A = self._load_image(file_A, f\"A_{idx % len(self.files_A)}\")\n",
        "        img_B = self._load_image(file_B, f\"B_{idx % len(self.files_B)}\")\n",
        "\n",
        "        return img_A, img_B\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINER OPTIMIS√â (CORRIG√â)\n",
        "# ============================================================================\n",
        "\n",
        "class FastCycleGANTrainer:\n",
        "    \"\"\"Entra√Ænement rapide avec mixed precision et optimisations\"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        print(f\"üöÄ Device: {self.device}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "        os.makedirs(config['output_dir'], exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/samples\", exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/checkpoints\", exist_ok=True)\n",
        "\n",
        "        self.history = {'G': [], 'D': [], 'cycle': []}\n",
        "        self._build_models()\n",
        "        self._setup_optimizers()\n",
        "\n",
        "        # Mixed precision scaler\n",
        "        self.scaler = GradScaler() if config['use_amp'] else None\n",
        "\n",
        "        # Crit√®res\n",
        "        self.criterion_GAN = nn.MSELoss()\n",
        "        self.criterion_cycle = nn.L1Loss()\n",
        "\n",
        "    def _build_models(self):\n",
        "        \"\"\"Construire mod√®les l√©gers\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.G_A2B = FastGenerator(config['ngf'], config['n_blocks']).to(self.device)\n",
        "        self.G_B2A = FastGenerator(config['ngf'], config['n_blocks']).to(self.device)\n",
        "        self.D_A = FastDiscriminator(config['ndf']).to(self.device)\n",
        "        self.D_B = FastDiscriminator(config['ndf']).to(self.device)\n",
        "\n",
        "        # Compter param√®tres\n",
        "        g_params = sum(p.numel() for p in self.G_A2B.parameters()) / 1e6\n",
        "        d_params = sum(p.numel() for p in self.D_A.parameters()) / 1e6\n",
        "        print(f\"üìä G√©n√©rateur: {g_params:.2f}M params\")\n",
        "        print(f\"üìä Discriminateur: {d_params:.2f}M params\")\n",
        "\n",
        "    def _setup_optimizers(self):\n",
        "        \"\"\"AdamW avec cosine annealing\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.opt_G = AdamW(\n",
        "            list(self.G_A2B.parameters()) + list(self.G_B2A.parameters()),\n",
        "            lr=config['lr'],\n",
        "            betas=(0.5, 0.999),\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        self.opt_D = AdamW(\n",
        "            list(self.D_A.parameters()) + list(self.D_B.parameters()),\n",
        "            lr=config['lr'],\n",
        "            betas=(0.5, 0.999),\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # Cosine annealing pour convergence rapide\n",
        "        self.sched_G = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.opt_G, T_max=config['n_epochs']\n",
        "        )\n",
        "        self.sched_D = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.opt_D, T_max=config['n_epochs']\n",
        "        )\n",
        "\n",
        "    def train_step(self, real_A, real_B):\n",
        "        \"\"\"Un pas d'entra√Ænement optimis√© - CORRIG√â\"\"\"\n",
        "        batch_size = real_A.size(0)\n",
        "\n",
        "        # ‚úÖ CORRECTION: Cr√©er les labels AVANT l'autocast\n",
        "        # Obtenir la taille de sortie du discriminateur\n",
        "        with torch.no_grad():\n",
        "            sample_output = self.D_A(real_A[:1])\n",
        "            patch_size = sample_output.shape[-2:]  # (H, W)\n",
        "\n",
        "        # Cr√©er les labels avec la bonne taille\n",
        "        valid = torch.ones(batch_size, 1, *patch_size, device=self.device, dtype=torch.float32)\n",
        "        fake_label = torch.zeros(batch_size, 1, *patch_size, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        # ==================== G√âN√âRATEURS ====================\n",
        "        self.opt_G.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=self.config['use_amp']):\n",
        "            # G√©n√©ration\n",
        "            fake_B = self.G_A2B(real_A)\n",
        "            fake_A = self.G_B2A(real_B)\n",
        "\n",
        "            # GAN loss\n",
        "            pred_fake_B = self.D_B(fake_B)\n",
        "            loss_GAN_A2B = self.criterion_GAN(pred_fake_B, valid)\n",
        "\n",
        "            pred_fake_A = self.D_A(fake_A)\n",
        "            loss_GAN_B2A = self.criterion_GAN(pred_fake_A, valid)\n",
        "\n",
        "            # Cycle consistency\n",
        "            recovered_A = self.G_B2A(fake_B)\n",
        "            recovered_B = self.G_A2B(fake_A)\n",
        "            loss_cycle = (\n",
        "                self.criterion_cycle(recovered_A, real_A) +\n",
        "                self.criterion_cycle(recovered_B, real_B)\n",
        "            ) * self.config['lambda_cycle']\n",
        "\n",
        "            # Total G loss\n",
        "            loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle\n",
        "\n",
        "        if self.scaler:\n",
        "            self.scaler.scale(loss_G).backward()\n",
        "            self.scaler.step(self.opt_G)\n",
        "        else:\n",
        "            loss_G.backward()\n",
        "            self.opt_G.step()\n",
        "\n",
        "        # ==================== DISCRIMINATEURS ====================\n",
        "        self.opt_D.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=self.config['use_amp']):\n",
        "            # D_A\n",
        "            pred_real_A = self.D_A(real_A)\n",
        "            loss_D_real_A = self.criterion_GAN(pred_real_A, valid)\n",
        "\n",
        "            pred_fake_A = self.D_A(fake_A.detach())\n",
        "            loss_D_fake_A = self.criterion_GAN(pred_fake_A, fake_label)\n",
        "\n",
        "            # D_B\n",
        "            pred_real_B = self.D_B(real_B)\n",
        "            loss_D_real_B = self.criterion_GAN(pred_real_B, valid)\n",
        "\n",
        "            pred_fake_B = self.D_B(fake_B.detach())\n",
        "            loss_D_fake_B = self.criterion_GAN(pred_fake_B, fake_label)\n",
        "\n",
        "            loss_D = (loss_D_real_A + loss_D_fake_A +\n",
        "                     loss_D_real_B + loss_D_fake_B) * 0.5\n",
        "\n",
        "        if self.scaler:\n",
        "            self.scaler.scale(loss_D).backward()\n",
        "            self.scaler.step(self.opt_D)\n",
        "            self.scaler.update()\n",
        "        else:\n",
        "            loss_D.backward()\n",
        "            self.opt_D.step()\n",
        "\n",
        "        return {\n",
        "            'G': loss_G.item(),\n",
        "            'D': loss_D.item(),\n",
        "            'cycle': loss_cycle.item()\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch):\n",
        "        \"\"\"Entra√Æner une √©poque\"\"\"\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "        self.D_A.train()\n",
        "        self.D_B.train()\n",
        "\n",
        "        losses = {'G': [], 'D': [], 'cycle': []}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}/{self.config['n_epochs']}\")\n",
        "\n",
        "        for i, (real_A, real_B) in enumerate(pbar):\n",
        "            real_A = real_A.to(self.device, non_blocking=True)\n",
        "            real_B = real_B.to(self.device, non_blocking=True)\n",
        "\n",
        "            loss_dict = self.train_step(real_A, real_B)\n",
        "\n",
        "            for k, v in loss_dict.items():\n",
        "                losses[k].append(v)\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_dict['G']:.3f}\",\n",
        "                'D': f\"{loss_dict['D']:.3f}\",\n",
        "                'Cyc': f\"{loss_dict['cycle']:.3f}\"\n",
        "            })\n",
        "\n",
        "            # √âchantillons\n",
        "            if i == 0:\n",
        "                self.save_samples(epoch, real_A, real_B)\n",
        "\n",
        "        return {k: np.mean(v) for k, v in losses.items()}\n",
        "\n",
        "    def save_samples(self, epoch, real_A, real_B):\n",
        "        \"\"\"Sauvegarder √©chantillons\"\"\"\n",
        "        self.G_A2B.eval()\n",
        "        self.G_B2A.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake_B = self.G_A2B(real_A[:4])\n",
        "            fake_A = self.G_B2A(real_B[:4])\n",
        "\n",
        "        comparison = torch.cat([\n",
        "            real_A[:4], fake_B, real_B[:4], fake_A\n",
        "        ], dim=0)\n",
        "\n",
        "        save_image(\n",
        "            comparison,\n",
        "            f\"{self.config['output_dir']}/samples/epoch_{epoch:03d}.png\",\n",
        "            nrow=4,\n",
        "            normalize=True,\n",
        "            value_range=(-1, 1)\n",
        "        )\n",
        "\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "\n",
        "    def save_checkpoint(self, epoch):\n",
        "        \"\"\"Sauvegarder checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'G_A2B': self.G_A2B.state_dict(),\n",
        "            'G_B2A': self.G_B2A.state_dict(),\n",
        "            'D_A': self.D_A.state_dict(),\n",
        "            'D_B': self.D_B.state_dict(),\n",
        "            'opt_G': self.opt_G.state_dict(),\n",
        "            'opt_D': self.opt_D.state_dict(),\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        path = f\"{self.config['output_dir']}/checkpoints/checkpoint_{epoch:03d}.pth\"\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "        # Garder seulement les 3 derniers\n",
        "        checkpoints = sorted(Path(f\"{self.config['output_dir']}/checkpoints\").glob(\"checkpoint_*.pth\"))\n",
        "        if len(checkpoints) > 3:\n",
        "            checkpoints[0].unlink()\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        \"\"\"Boucle principale\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üöÄ ENTRA√éNEMENT CYCLEGAN RAPIDE\")\n",
        "        print(f\"   Epochs: {self.config['n_epochs']}\")\n",
        "        print(f\"   Batch: {self.config['batch_size']}\")\n",
        "        print(f\"   Mixed Precision: {self.config['use_amp']}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        for epoch in range(1, self.config['n_epochs'] + 1):\n",
        "            avg_losses = self.train_epoch(dataloader, epoch)\n",
        "\n",
        "            for k, v in avg_losses.items():\n",
        "                self.history[k].append(v)\n",
        "\n",
        "            print(f\"\\nüìä Epoch {epoch}: G={avg_losses['G']:.4f} | \"\n",
        "                  f\"D={avg_losses['D']:.4f} | Cycle={avg_losses['cycle']:.4f}\")\n",
        "\n",
        "            self.sched_G.step()\n",
        "            self.sched_D.step()\n",
        "\n",
        "            if epoch % self.config['save_interval'] == 0:\n",
        "                self.save_checkpoint(epoch)\n",
        "\n",
        "        # Sauvegarder final\n",
        "        torch.save(\n",
        "            self.G_A2B.state_dict(),\n",
        "            f\"{self.config['output_dir']}/G_A2B_final.pth\"\n",
        "        )\n",
        "        torch.save(\n",
        "            self.G_B2A.state_dict(),\n",
        "            f\"{self.config['output_dir']}/G_B2A_final.pth\"\n",
        "        )\n",
        "\n",
        "        print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
        "        print(f\"üìÅ Mod√®les sauvegard√©s dans: {self.config['output_dir']}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "def get_fast_config():\n",
        "    \"\"\"Configuration optimis√©e pour entra√Ænement rapide\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    return {\n",
        "        # Donn√©es\n",
        "        'classA_dir': './classeA',\n",
        "        'classB_dir': './classeB',\n",
        "        'output_dir': f'./outputs/fast_cyclegan_{timestamp}',\n",
        "\n",
        "        # Architecture l√©g√®re\n",
        "        'ngf': 32,\n",
        "        'ndf': 32,\n",
        "        'n_blocks': 6,\n",
        "\n",
        "        # Entra√Ænement rapide\n",
        "        'n_epochs': 50,\n",
        "        'batch_size': 8,\n",
        "        'lr': 0.0002,\n",
        "\n",
        "        # Optimisations\n",
        "        'use_amp': True,\n",
        "        'img_size': 128,\n",
        "        'num_workers': 4,\n",
        "\n",
        "        # Poids\n",
        "        'lambda_cycle': 10.0,\n",
        "\n",
        "        # Sauvegarde\n",
        "        'save_interval': 10,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Script principal optimis√©\"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"   CYCLEGAN RAPIDE - Navigation C√©leste pour Drone\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    config = get_fast_config()\n",
        "\n",
        "    # V√©rifications\n",
        "    if not os.path.exists(config['classA_dir']):\n",
        "        print(f\"‚ùå Dossier '{config['classA_dir']}' introuvable!\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(config['classB_dir']):\n",
        "        print(f\"‚ùå Dossier '{config['classB_dir']}' introuvable!\")\n",
        "        return\n",
        "\n",
        "    # Dataset\n",
        "    try:\n",
        "        dataset = FastCelestialDataset(\n",
        "            config['classA_dir'],\n",
        "            config['classB_dir'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader optimis√©\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ {len(dataloader)} batches charg√©s\\n\")\n",
        "\n",
        "    # Entra√Ænement\n",
        "    trainer = FastCycleGANTrainer(config)\n",
        "    trainer.train(dataloader)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyy-5v9sgRkX",
        "outputId": "20f9af62-4291-4e57-9aea-4aa86fdd685d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python script.py train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuZoMKzGhx2w",
        "outputId": "392ef257-7585-4d60-8bf0-ccf73a103724"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "   CYCLEGAN RAPIDE - Navigation C√©leste pour Drone\n",
            "======================================================================\n",
            "\n",
            "üìÇ Dataset: 1000 Real | 1000 Stellarium\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "‚úÖ 125 batches charg√©s\n",
            "\n",
            "üöÄ Device: cuda\n",
            "   GPU: Tesla T4\n",
            "üìä G√©n√©rateur: 0.37M params\n",
            "üìä Discriminateur: 0.17M params\n",
            "/content/script.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler() if config['use_amp'] else None\n",
            "\n",
            "======================================================================\n",
            "üöÄ ENTRA√éNEMENT CYCLEGAN RAPIDE\n",
            "   Epochs: 50\n",
            "   Batch: 8\n",
            "   Mixed Precision: True\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/50:   0% 0/125 [00:00<?, ?it/s]/content/script.py:288: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "/content/script.py:321: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "Epoch 1/50: 100% 125/125 [00:22<00:00,  5.63it/s, G=0.747, D=0.475, Cyc=0.127]\n",
            "\n",
            "üìä Epoch 1: G=2.3827 | D=0.4302 | Cycle=1.6073\n",
            "Epoch 2/50: 100% 125/125 [00:15<00:00,  7.99it/s, G=0.583, D=0.581, Cyc=0.141]\n",
            "\n",
            "üìä Epoch 2: G=0.9757 | D=0.3545 | Cycle=0.1171\n",
            "Epoch 3/50: 100% 125/125 [00:15<00:00,  7.93it/s, G=0.752, D=0.404, Cyc=0.066]\n",
            "\n",
            "üìä Epoch 3: G=0.8814 | D=0.3740 | Cycle=0.0914\n",
            "Epoch 4/50: 100% 125/125 [00:16<00:00,  7.64it/s, G=1.105, D=0.253, Cyc=0.078]\n",
            "\n",
            "üìä Epoch 4: G=0.9109 | D=0.3658 | Cycle=0.0818\n",
            "Epoch 5/50: 100% 125/125 [00:15<00:00,  7.89it/s, G=0.652, D=0.427, Cyc=0.081]\n",
            "\n",
            "üìä Epoch 5: G=0.9641 | D=0.3396 | Cycle=0.0723\n",
            "Epoch 6/50: 100% 125/125 [00:16<00:00,  7.70it/s, G=1.071, D=0.340, Cyc=0.064]\n",
            "\n",
            "üìä Epoch 6: G=0.8651 | D=0.3870 | Cycle=0.0682\n",
            "Epoch 7/50: 100% 125/125 [00:15<00:00,  7.99it/s, G=0.839, D=0.385, Cyc=0.056]\n",
            "\n",
            "üìä Epoch 7: G=0.9460 | D=0.3517 | Cycle=0.0663\n",
            "Epoch 8/50: 100% 125/125 [00:16<00:00,  7.74it/s, G=0.583, D=0.496, Cyc=0.088]\n",
            "\n",
            "üìä Epoch 8: G=0.8288 | D=0.3942 | Cycle=0.0674\n",
            "Epoch 9/50: 100% 125/125 [00:15<00:00,  8.04it/s, G=1.337, D=0.290, Cyc=0.043]\n",
            "\n",
            "üìä Epoch 9: G=0.8788 | D=0.3796 | Cycle=0.0688\n",
            "Epoch 10/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=0.411, D=0.568, Cyc=0.069]\n",
            "\n",
            "üìä Epoch 10: G=0.9862 | D=0.3460 | Cycle=0.0650\n",
            "Epoch 11/50: 100% 125/125 [00:15<00:00,  7.98it/s, G=1.194, D=0.255, Cyc=0.041]\n",
            "\n",
            "üìä Epoch 11: G=0.8877 | D=0.3667 | Cycle=0.0607\n",
            "Epoch 12/50: 100% 125/125 [00:15<00:00,  7.98it/s, G=0.972, D=0.363, Cyc=0.061]\n",
            "\n",
            "üìä Epoch 12: G=1.0670 | D=0.3036 | Cycle=0.0598\n",
            "Epoch 13/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=1.286, D=0.210, Cyc=0.065]\n",
            "\n",
            "üìä Epoch 13: G=1.0386 | D=0.3274 | Cycle=0.0639\n",
            "Epoch 14/50: 100% 125/125 [00:15<00:00,  7.81it/s, G=0.800, D=0.351, Cyc=0.045]\n",
            "\n",
            "üìä Epoch 14: G=1.0078 | D=0.3228 | Cycle=0.0607\n",
            "Epoch 15/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=1.074, D=0.241, Cyc=0.048]\n",
            "\n",
            "üìä Epoch 15: G=0.9464 | D=0.3588 | Cycle=0.0587\n",
            "Epoch 16/50: 100% 125/125 [00:15<00:00,  8.01it/s, G=0.697, D=0.384, Cyc=0.059]\n",
            "\n",
            "üìä Epoch 16: G=0.9578 | D=0.3410 | Cycle=0.0608\n",
            "Epoch 17/50: 100% 125/125 [00:15<00:00,  8.03it/s, G=0.894, D=0.362, Cyc=0.048]\n",
            "\n",
            "üìä Epoch 17: G=0.9415 | D=0.3468 | Cycle=0.0591\n",
            "Epoch 18/50: 100% 125/125 [00:15<00:00,  8.33it/s, G=0.826, D=0.382, Cyc=0.058]\n",
            "\n",
            "üìä Epoch 18: G=0.9612 | D=0.3412 | Cycle=0.0560\n",
            "Epoch 19/50: 100% 125/125 [00:15<00:00,  8.19it/s, G=0.863, D=0.425, Cyc=0.063]\n",
            "\n",
            "üìä Epoch 19: G=0.8109 | D=0.3973 | Cycle=0.0615\n",
            "Epoch 20/50: 100% 125/125 [00:15<00:00,  7.90it/s, G=0.856, D=0.419, Cyc=0.070]\n",
            "\n",
            "üìä Epoch 20: G=0.7665 | D=0.4179 | Cycle=0.0633\n",
            "Epoch 21/50: 100% 125/125 [00:15<00:00,  8.19it/s, G=0.766, D=0.391, Cyc=0.073]\n",
            "\n",
            "üìä Epoch 21: G=0.7640 | D=0.4196 | Cycle=0.0673\n",
            "Epoch 22/50: 100% 125/125 [00:15<00:00,  7.96it/s, G=1.142, D=0.438, Cyc=0.060]\n",
            "\n",
            "üìä Epoch 22: G=0.7534 | D=0.4273 | Cycle=0.0662\n",
            "Epoch 23/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=0.724, D=0.438, Cyc=0.060]\n",
            "\n",
            "üìä Epoch 23: G=0.7347 | D=0.4330 | Cycle=0.0690\n",
            "Epoch 24/50: 100% 125/125 [00:15<00:00,  8.10it/s, G=0.722, D=0.426, Cyc=0.067]\n",
            "\n",
            "üìä Epoch 24: G=0.7255 | D=0.4352 | Cycle=0.0685\n",
            "Epoch 25/50: 100% 125/125 [00:15<00:00,  7.86it/s, G=0.619, D=0.465, Cyc=0.080]\n",
            "\n",
            "üìä Epoch 25: G=0.7017 | D=0.4485 | Cycle=0.0688\n",
            "Epoch 26/50: 100% 125/125 [00:15<00:00,  7.84it/s, G=0.635, D=0.434, Cyc=0.055]\n",
            "\n",
            "üìä Epoch 26: G=0.7049 | D=0.4432 | Cycle=0.0699\n",
            "Epoch 27/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=0.682, D=0.460, Cyc=0.075]\n",
            "\n",
            "üìä Epoch 27: G=0.6992 | D=0.4464 | Cycle=0.0693\n",
            "Epoch 28/50: 100% 125/125 [00:16<00:00,  7.61it/s, G=0.711, D=0.450, Cyc=0.067]\n",
            "\n",
            "üìä Epoch 28: G=0.6991 | D=0.4424 | Cycle=0.0689\n",
            "Epoch 29/50: 100% 125/125 [00:15<00:00,  7.95it/s, G=0.674, D=0.433, Cyc=0.066]\n",
            "\n",
            "üìä Epoch 29: G=0.6946 | D=0.4446 | Cycle=0.0684\n",
            "Epoch 30/50: 100% 125/125 [00:15<00:00,  8.07it/s, G=0.613, D=0.490, Cyc=0.070]\n",
            "\n",
            "üìä Epoch 30: G=0.6956 | D=0.4461 | Cycle=0.0684\n",
            "Epoch 31/50: 100% 125/125 [00:15<00:00,  8.19it/s, G=0.690, D=0.438, Cyc=0.072]\n",
            "\n",
            "üìä Epoch 31: G=0.6984 | D=0.4424 | Cycle=0.0678\n",
            "Epoch 32/50: 100% 125/125 [00:15<00:00,  8.00it/s, G=0.746, D=0.444, Cyc=0.078]\n",
            "\n",
            "üìä Epoch 32: G=0.7033 | D=0.4418 | Cycle=0.0684\n",
            "Epoch 33/50: 100% 125/125 [00:15<00:00,  8.06it/s, G=0.649, D=0.454, Cyc=0.060]\n",
            "\n",
            "üìä Epoch 33: G=0.6985 | D=0.4416 | Cycle=0.0669\n",
            "Epoch 34/50: 100% 125/125 [00:15<00:00,  8.10it/s, G=0.766, D=0.433, Cyc=0.061]\n",
            "\n",
            "üìä Epoch 34: G=0.6944 | D=0.4437 | Cycle=0.0659\n",
            "Epoch 35/50: 100% 125/125 [00:15<00:00,  7.84it/s, G=0.728, D=0.449, Cyc=0.060]\n",
            "\n",
            "üìä Epoch 35: G=0.6908 | D=0.4458 | Cycle=0.0658\n",
            "Epoch 36/50: 100% 125/125 [00:15<00:00,  7.83it/s, G=0.642, D=0.426, Cyc=0.078]\n",
            "\n",
            "üìä Epoch 36: G=0.6927 | D=0.4444 | Cycle=0.0666\n",
            "Epoch 37/50: 100% 125/125 [00:16<00:00,  7.75it/s, G=0.635, D=0.449, Cyc=0.070]\n",
            "\n",
            "üìä Epoch 37: G=0.6948 | D=0.4418 | Cycle=0.0665\n",
            "Epoch 38/50: 100% 125/125 [00:15<00:00,  7.95it/s, G=0.755, D=0.411, Cyc=0.060]\n",
            "\n",
            "üìä Epoch 38: G=0.6892 | D=0.4442 | Cycle=0.0656\n",
            "Epoch 39/50: 100% 125/125 [00:15<00:00,  8.00it/s, G=0.727, D=0.425, Cyc=0.067]\n",
            "\n",
            "üìä Epoch 39: G=0.6919 | D=0.4423 | Cycle=0.0649\n",
            "Epoch 40/50: 100% 125/125 [00:15<00:00,  8.04it/s, G=0.736, D=0.453, Cyc=0.064]\n",
            "\n",
            "üìä Epoch 40: G=0.6938 | D=0.4419 | Cycle=0.0655\n",
            "Epoch 41/50: 100% 125/125 [00:15<00:00,  7.89it/s, G=0.664, D=0.435, Cyc=0.064]\n",
            "\n",
            "üìä Epoch 41: G=0.6924 | D=0.4405 | Cycle=0.0646\n",
            "Epoch 42/50: 100% 125/125 [00:15<00:00,  7.86it/s, G=0.744, D=0.424, Cyc=0.055]\n",
            "\n",
            "üìä Epoch 42: G=0.6921 | D=0.4413 | Cycle=0.0651\n",
            "Epoch 43/50: 100% 125/125 [00:15<00:00,  8.15it/s, G=0.703, D=0.457, Cyc=0.066]\n",
            "\n",
            "üìä Epoch 43: G=0.6914 | D=0.4415 | Cycle=0.0646\n",
            "Epoch 44/50: 100% 125/125 [00:15<00:00,  8.05it/s, G=0.674, D=0.450, Cyc=0.065]\n",
            "\n",
            "üìä Epoch 44: G=0.6929 | D=0.4399 | Cycle=0.0652\n",
            "Epoch 45/50: 100% 125/125 [00:15<00:00,  7.92it/s, G=0.660, D=0.471, Cyc=0.064]\n",
            "\n",
            "üìä Epoch 45: G=0.6914 | D=0.4405 | Cycle=0.0652\n",
            "Epoch 46/50: 100% 125/125 [00:15<00:00,  7.83it/s, G=0.687, D=0.439, Cyc=0.066]\n",
            "\n",
            "üìä Epoch 46: G=0.6941 | D=0.4392 | Cycle=0.0651\n",
            "Epoch 47/50: 100% 125/125 [00:16<00:00,  7.66it/s, G=0.688, D=0.458, Cyc=0.066]\n",
            "\n",
            "üìä Epoch 47: G=0.6908 | D=0.4402 | Cycle=0.0649\n",
            "Epoch 48/50: 100% 125/125 [00:15<00:00,  8.03it/s, G=0.710, D=0.426, Cyc=0.065]\n",
            "\n",
            "üìä Epoch 48: G=0.6913 | D=0.4395 | Cycle=0.0650\n",
            "Epoch 49/50: 100% 125/125 [00:15<00:00,  8.19it/s, G=0.741, D=0.422, Cyc=0.058]\n",
            "\n",
            "üìä Epoch 49: G=0.6917 | D=0.4389 | Cycle=0.0638\n",
            "Epoch 50/50: 100% 125/125 [00:15<00:00,  8.03it/s, G=0.699, D=0.437, Cyc=0.083]\n",
            "\n",
            "üìä Epoch 50: G=0.6940 | D=0.4391 | Cycle=0.0655\n",
            "\n",
            "‚úÖ Entra√Ænement termin√©!\n",
            "üìÅ Mod√®les sauvegard√©s dans: ./outputs/fast_cyclegan_20251117_162325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile improved_cyclegan.py\n",
        "\"\"\"\n",
        "CycleGAN AM√âLIOR√â pour Navigation C√©leste\n",
        "Optimisations : √âtoiles brillantes + Meilleure qualit√© visuelle + Visualisation\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# ============================================================================\n",
        "# ARCHITECTURE AM√âLIOR√âE avec Attention sur les √âtoiles\n",
        "# ============================================================================\n",
        "\n",
        "class StarAttentionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention module sp√©cialis√© pour les √©toiles\n",
        "    Renforce les points lumineux (√©toiles) dans l'image\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # D√©tection des points lumineux (√©toiles)\n",
        "        self.star_detector = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // 4, 1),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(channels // 4, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Amplification s√©lective\n",
        "        self.amplifier = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 1),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # D√©tecter les √©toiles (points lumineux)\n",
        "        star_mask = self.star_detector(x)\n",
        "\n",
        "        # Amplifier les features aux positions des √©toiles\n",
        "        amplified = self.amplifier(x)\n",
        "\n",
        "        # Combiner : zone √©toile = amplifi√©, reste = original\n",
        "        return x + star_mask * amplified * 0.5\n",
        "\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"Attention sur les canaux\"\"\"\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        return x * self.sigmoid(avg_out + max_out)\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \"\"\"Attention spatiale pour localiser les √©toiles\"\"\"\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        return x * self.sigmoid(self.conv(out))\n",
        "\n",
        "\n",
        "class EnhancedResBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Bloc r√©siduel am√©lior√© avec attention multi-niveaux\n",
        "    Sp√©cialement con√ßu pour pr√©server et am√©liorer les √©toiles\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(channels, channels, 3, bias=False),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(channels, channels, 3, bias=False),\n",
        "            nn.InstanceNorm2d(channels)\n",
        "        )\n",
        "\n",
        "        # Triple attention\n",
        "        self.star_attention = StarAttentionModule(channels)\n",
        "        self.channel_attention = ChannelAttention(channels)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        # Convolutions\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        # Attention sur les √©toiles\n",
        "        out = self.star_attention(out)\n",
        "\n",
        "        # Attention canal et spatiale\n",
        "        out = self.channel_attention(out)\n",
        "        out = self.spatial_attention(out)\n",
        "\n",
        "        return residual + out * 0.2  # Scaled residual connection\n",
        "\n",
        "\n",
        "class ImprovedGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    G√©n√©rateur am√©lior√© pour conversion R√©el‚ÜíStellarium\n",
        "    Focus : Rendre les √©toiles brillantes et claires\n",
        "    \"\"\"\n",
        "    def __init__(self, ngf=64, n_blocks=9):\n",
        "        super().__init__()\n",
        "\n",
        "        # === ENCODER ===\n",
        "        self.encoder_init = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, ngf, 7, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        # Downsampling\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(ngf, ngf * 2, 3, stride=2, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf * 2),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(ngf * 2, ngf * 4, 3, stride=2, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf * 4),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        # === TRANSFORMATION avec attention √©toiles ===\n",
        "        transform_blocks = []\n",
        "        for _ in range(n_blocks):\n",
        "            transform_blocks.append(EnhancedResBlock(ngf * 4))\n",
        "        self.transform = nn.Sequential(*transform_blocks)\n",
        "\n",
        "        # === DECODER ===\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, stride=2, padding=1,\n",
        "                              output_padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf * 2),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 3, stride=2, padding=1,\n",
        "                              output_padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "        # Couche finale\n",
        "        self.output = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.encoder_init(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "\n",
        "        # Transformation avec attention\n",
        "        x = self.transform(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "\n",
        "        return self.output(x)\n",
        "\n",
        "\n",
        "class ImprovedDiscriminator(nn.Module):\n",
        "    \"\"\"Discriminateur am√©lior√© (PatchGAN)\"\"\"\n",
        "    def __init__(self, ndf=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # 128x128 ‚Üí 64x64\n",
        "            nn.Conv2d(3, ndf, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "\n",
        "            # 64x64 ‚Üí 32x32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "\n",
        "            # 32x32 ‚Üí 16x16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "\n",
        "            # 16x16 ‚Üí 15x15\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "\n",
        "            # Output\n",
        "            nn.Conv2d(ndf * 8, 1, 4, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PERCEPTUAL LOSS pour am√©liorer la qualit√© visuelle\n",
        "# ============================================================================\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Perte perceptuelle bas√©e sur VGG\n",
        "    Am√©liore la qualit√© visuelle des √©toiles\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Utiliser les premi√®res couches de VGG pour extraire features\n",
        "        try:\n",
        "            from torchvision.models import vgg19, VGG19_Weights\n",
        "            vgg = vgg19(weights=VGG19_Weights.DEFAULT).features\n",
        "        except:\n",
        "            from torchvision.models import vgg19\n",
        "            vgg = vgg19(pretrained=True).features\n",
        "\n",
        "        # Extraire jusqu'√† relu3_4 (indices 0-17)\n",
        "        self.feature_extractor = nn.Sequential(*list(vgg.children())[:18]).eval()\n",
        "\n",
        "        # Geler les poids\n",
        "        for param in self.feature_extractor.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.criterion = nn.L1Loss()\n",
        "\n",
        "    def forward(self, fake, real):\n",
        "        # Normalisation ImageNet\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(fake.device)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(fake.device)\n",
        "\n",
        "        fake_normalized = (fake * 0.5 + 0.5 - mean) / std\n",
        "        real_normalized = (real * 0.5 + 0.5 - mean) / std\n",
        "\n",
        "        # Extraire features\n",
        "        fake_features = self.feature_extractor(fake_normalized)\n",
        "        real_features = self.feature_extractor(real_normalized)\n",
        "\n",
        "        return self.criterion(fake_features, real_features)\n",
        "\n",
        "\n",
        "class StarBrightnessLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Perte personnalis√©e pour encourager les √©toiles brillantes\n",
        "    P√©nalise si les √©toiles sont trop sombres\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, fake_stellarium, real_stellarium):\n",
        "        # Calculer la luminosit√© moyenne des pixels brillants\n",
        "        # (on consid√®re les 10% de pixels les plus lumineux comme des √©toiles)\n",
        "\n",
        "        fake_flat = fake_stellarium.view(fake_stellarium.size(0), -1)\n",
        "        real_flat = real_stellarium.view(real_stellarium.size(0), -1)\n",
        "\n",
        "        # Top 10% pixels\n",
        "        k = int(fake_flat.size(1) * 0.1)\n",
        "\n",
        "        fake_bright = torch.topk(fake_flat, k, dim=1)[0].mean()\n",
        "        real_bright = torch.topk(real_flat, k, dim=1)[0].mean()\n",
        "\n",
        "        # Encourager fake √† avoir des √©toiles aussi brillantes que real\n",
        "        return F.l1_loss(fake_bright, real_bright)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class CelestialDataset(Dataset):\n",
        "    \"\"\"Dataset avec augmentation pour navigation c√©leste\"\"\"\n",
        "    def __init__(self, root_A, root_B, img_size=128):\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Charger chemins\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "        self.files_A = []\n",
        "        self.files_B = []\n",
        "\n",
        "        for ext in extensions:\n",
        "            self.files_A.extend(list(Path(root_A).glob(ext)))\n",
        "            self.files_B.extend(list(Path(root_B).glob(ext)))\n",
        "\n",
        "        self.files_A = sorted(self.files_A)\n",
        "        self.files_B = sorted(self.files_B)\n",
        "\n",
        "        print(f\"üìÇ Dataset: {len(self.files_A)} R√©el | {len(self.files_B)} Stellarium\")\n",
        "\n",
        "        if not self.files_A or not self.files_B:\n",
        "            raise ValueError(\"‚ùå Aucune image trouv√©e!\")\n",
        "\n",
        "        # Transforms avec augmentation\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size), transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            # Augmentation sp√©cifique pour le ciel nocturne\n",
        "            transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_A = self.files_A[idx % len(self.files_A)]\n",
        "        file_B = self.files_B[idx % len(self.files_B)]\n",
        "\n",
        "        img_A = Image.open(file_A).convert('RGB')\n",
        "        img_B = Image.open(file_B).convert('RGB')\n",
        "\n",
        "        img_A = self.transform(img_A)\n",
        "        img_B = self.transform(img_B)\n",
        "\n",
        "        return img_A, img_B\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINER AM√âLIOR√â\n",
        "# ============================================================================\n",
        "\n",
        "class ImprovedCycleGANTrainer:\n",
        "    \"\"\"Entra√Ænement am√©lior√© avec pertes suppl√©mentaires\"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        print(f\"üöÄ Device: {self.device}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "        os.makedirs(config['output_dir'], exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/samples\", exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/checkpoints\", exist_ok=True)\n",
        "        os.makedirs(f\"{config['output_dir']}/comparisons\", exist_ok=True)\n",
        "\n",
        "        self.history = {\n",
        "            'G': [], 'D': [], 'cycle': [], 'perceptual': [],\n",
        "            'star_brightness': [], 'total': []\n",
        "        }\n",
        "\n",
        "        self._build_models()\n",
        "        self._setup_optimizers()\n",
        "\n",
        "        # Scaler pour mixed precision\n",
        "        self.scaler = GradScaler() if config['use_amp'] else None\n",
        "\n",
        "        # Crit√®res\n",
        "        self.criterion_GAN = nn.MSELoss()\n",
        "        self.criterion_cycle = nn.L1Loss()\n",
        "        self.criterion_identity = nn.L1Loss()\n",
        "\n",
        "        # Pertes am√©lior√©es\n",
        "        if config['use_perceptual']:\n",
        "            self.criterion_perceptual = PerceptualLoss().to(self.device)\n",
        "\n",
        "        if config['use_star_loss']:\n",
        "            self.criterion_star = StarBrightnessLoss().to(self.device)\n",
        "\n",
        "    def _build_models(self):\n",
        "        \"\"\"Construire mod√®les\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.G_A2B = ImprovedGenerator(config['ngf'], config['n_blocks']).to(self.device)\n",
        "        self.G_B2A = ImprovedGenerator(config['ngf'], config['n_blocks']).to(self.device)\n",
        "        self.D_A = ImprovedDiscriminator(config['ndf']).to(self.device)\n",
        "        self.D_B = ImprovedDiscriminator(config['ndf']).to(self.device)\n",
        "\n",
        "        # Initialisation\n",
        "        for net in [self.G_A2B, self.G_B2A, self.D_A, self.D_B]:\n",
        "            self._init_weights(net)\n",
        "\n",
        "        # Stats\n",
        "        g_params = sum(p.numel() for p in self.G_A2B.parameters()) / 1e6\n",
        "        d_params = sum(p.numel() for p in self.D_A.parameters()) / 1e6\n",
        "        print(f\"üìä G√©n√©rateur: {g_params:.2f}M params\")\n",
        "        print(f\"üìä Discriminateur: {d_params:.2f}M params\")\n",
        "\n",
        "    def _init_weights(self, net, init_gain=0.02):\n",
        "        \"\"\"Initialisation des poids\"\"\"\n",
        "        def init_func(m):\n",
        "            classname = m.__class__.__name__\n",
        "            if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "                nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
        "                if hasattr(m, 'bias') and m.bias is not None:\n",
        "                    nn.init.constant_(m.bias.data, 0.0)\n",
        "            elif 'Norm' in classname:\n",
        "                if hasattr(m, 'weight') and m.weight is not None:\n",
        "                    nn.init.normal_(m.weight.data, 1.0, init_gain)\n",
        "                if hasattr(m, 'bias') and m.bias is not None:\n",
        "                    nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "        net.apply(init_func)\n",
        "\n",
        "    def _setup_optimizers(self):\n",
        "        \"\"\"Optimiseurs\"\"\"\n",
        "        config = self.config\n",
        "\n",
        "        self.opt_G = AdamW(\n",
        "            list(self.G_A2B.parameters()) + list(self.G_B2A.parameters()),\n",
        "            lr=config['lr'],\n",
        "            betas=(0.5, 0.999),\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        self.opt_D = AdamW(\n",
        "            list(self.D_A.parameters()) + list(self.D_B.parameters()),\n",
        "            lr=config['lr'],\n",
        "            betas=(0.5, 0.999),\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # Schedulers\n",
        "        self.sched_G = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.opt_G, T_max=config['n_epochs']\n",
        "        )\n",
        "        self.sched_D = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.opt_D, T_max=config['n_epochs']\n",
        "        )\n",
        "\n",
        "    def train_step(self, real_A, real_B):\n",
        "        \"\"\"Un pas d'entra√Ænement avec toutes les pertes\"\"\"\n",
        "        batch_size = real_A.size(0)\n",
        "\n",
        "        # Labels\n",
        "        with torch.no_grad():\n",
        "            sample_out = self.D_A(real_A[:1])\n",
        "            patch_size = sample_out.shape[-2:]\n",
        "\n",
        "        valid = torch.ones(batch_size, 1, *patch_size, device=self.device)\n",
        "        fake_label = torch.zeros(batch_size, 1, *patch_size, device=self.device)\n",
        "\n",
        "        # ==================== G√âN√âRATEURS ====================\n",
        "        self.opt_G.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=self.config['use_amp']):\n",
        "            # G√©n√©ration\n",
        "            fake_B = self.G_A2B(real_A)  # R√©el ‚Üí Stellarium\n",
        "            fake_A = self.G_B2A(real_B)\n",
        "\n",
        "            # GAN loss\n",
        "            pred_fake_B = self.D_B(fake_B)\n",
        "            loss_GAN_A2B = self.criterion_GAN(pred_fake_B, valid)\n",
        "\n",
        "            pred_fake_A = self.D_A(fake_A)\n",
        "            loss_GAN_B2A = self.criterion_GAN(pred_fake_A, valid)\n",
        "\n",
        "            loss_GAN = (loss_GAN_A2B + loss_GAN_B2A) * 0.5\n",
        "\n",
        "            # Cycle consistency\n",
        "            recovered_A = self.G_B2A(fake_B)\n",
        "            recovered_B = self.G_A2B(fake_A)\n",
        "            loss_cycle = (\n",
        "                self.criterion_cycle(recovered_A, real_A) +\n",
        "                self.criterion_cycle(recovered_B, real_B)\n",
        "            ) * self.config['lambda_cycle']\n",
        "\n",
        "            # Identity loss (optionnel)\n",
        "            loss_identity = 0\n",
        "            if self.config['lambda_identity'] > 0:\n",
        "                id_B = self.G_A2B(real_B)\n",
        "                id_A = self.G_B2A(real_A)\n",
        "                loss_identity = (\n",
        "                    self.criterion_identity(id_B, real_B) +\n",
        "                    self.criterion_identity(id_A, real_A)\n",
        "                ) * self.config['lambda_identity']\n",
        "\n",
        "            # Perceptual loss (am√©liore qualit√© visuelle)\n",
        "            loss_perceptual = 0\n",
        "            if self.config['use_perceptual']:\n",
        "                loss_perceptual = (\n",
        "                    self.criterion_perceptual(fake_B, real_B) +\n",
        "                    self.criterion_perceptual(fake_A, real_A)\n",
        "                ) * self.config['lambda_perceptual']\n",
        "\n",
        "            # Star brightness loss (√©toiles brillantes!)\n",
        "            loss_star = 0\n",
        "            if self.config['use_star_loss']:\n",
        "                loss_star = self.criterion_star(fake_B, real_B) * self.config['lambda_star']\n",
        "\n",
        "            # Total G loss\n",
        "            loss_G = loss_GAN + loss_cycle + loss_identity + loss_perceptual + loss_star\n",
        "\n",
        "        if self.scaler:\n",
        "            self.scaler.scale(loss_G).backward()\n",
        "            self.scaler.step(self.opt_G)\n",
        "        else:\n",
        "            loss_G.backward()\n",
        "            self.opt_G.step()\n",
        "\n",
        "        # ==================== DISCRIMINATEURS ====================\n",
        "        self.opt_D.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=self.config['use_amp']):\n",
        "            # D_A\n",
        "            pred_real_A = self.D_A(real_A)\n",
        "            loss_D_real_A = self.criterion_GAN(pred_real_A, valid)\n",
        "\n",
        "            pred_fake_A = self.D_A(fake_A.detach())\n",
        "            loss_D_fake_A = self.criterion_GAN(pred_fake_A, fake_label)\n",
        "\n",
        "            # D_B\n",
        "            pred_real_B = self.D_B(real_B)\n",
        "            loss_D_real_B = self.criterion_GAN(pred_real_B, valid)\n",
        "\n",
        "            pred_fake_B = self.D_B(fake_B.detach())\n",
        "            loss_D_fake_B = self.criterion_GAN(pred_fake_B, fake_label)\n",
        "\n",
        "            loss_D = (loss_D_real_A + loss_D_fake_A +\n",
        "                     loss_D_real_B + loss_D_fake_B) * 0.5\n",
        "\n",
        "        if self.scaler:\n",
        "            self.scaler.scale(loss_D).backward()\n",
        "            self.scaler.step(self.opt_D)\n",
        "            self.scaler.update()\n",
        "        else:\n",
        "            loss_D.backward()\n",
        "            self.opt_D.step()\n",
        "\n",
        "        return {\n",
        "            'G': loss_G.item(),\n",
        "            'D': loss_D.item(),\n",
        "            'cycle': loss_cycle.item(),\n",
        "            'perceptual': loss_perceptual.item() if loss_perceptual != 0 else 0,\n",
        "            'star': loss_star.item() if loss_star != 0 else 0\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch):\n",
        "        \"\"\"Entra√Æner une √©poque\"\"\"\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "        self.D_A.train()\n",
        "        self.D_B.train()\n",
        "\n",
        "        losses = {'G': [], 'D': [], 'cycle': [], 'perceptual': [], 'star': []}\n",
        "\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch}/{self.config['n_epochs']}\")\n",
        "\n",
        "        for i, (real_A, real_B) in enumerate(pbar):\n",
        "            real_A = real_A.to(self.device, non_blocking=True)\n",
        "            real_B = real_B.to(self.device, non_blocking=True)\n",
        "\n",
        "            loss_dict = self.train_step(real_A, real_B)\n",
        "\n",
        "            for k, v in loss_dict.items():\n",
        "                losses[k].append(v)\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'G': f\"{loss_dict['G']:.3f}\",\n",
        "                'D': f\"{loss_dict['D']:.3f}\",\n",
        "                'Cyc': f\"{loss_dict['cycle']:.3f}\",\n",
        "                'Star': f\"{loss_dict['star']:.3f}\"\n",
        "            })\n",
        "\n",
        "            # Sauvegarder √©chantillons\n",
        "            if i == 0:\n",
        "                self.save_comparison(epoch, real_A, real_B)\n",
        "\n",
        "        return {k: np.mean(v) for k, v in losses.items()}\n",
        "\n",
        "    def save_comparison(self, epoch, real_A, real_B):\n",
        "        \"\"\"Cr√©er image de comparaison d√©taill√©e\"\"\"\n",
        "        self.G_A2B.eval()\n",
        "        self.G_B2A.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake_B = self.G_A2B(real_A[:4])\n",
        "            fake_A = self.G_B2A(real_B[:4])\n",
        "            recovered_A = self.G_B2A(fake_B)\n",
        "            recovered_B = self.G_A2B(fake_A)\n",
        "\n",
        "        # Grille de comparaison\n",
        "        comparison = torch.cat([\n",
        "            real_A[:4],        # Images r√©elles\n",
        "            fake_B,            # Converti en Stellarium\n",
        "            real_B[:4],        # Stellarium r√©el\n",
        "            fake_A,            # Converti en R√©el\n",
        "            recovered_A,       # Cycle A‚ÜíB‚ÜíA\n",
        "            recovered_B        # Cycle B‚ÜíA‚ÜíB\n",
        "        ], dim=0)\n",
        "\n",
        "        save_image(\n",
        "            comparison,\n",
        "            f\"{self.config['output_dir']}/comparisons/epoch_{epoch:03d}_full.png\",\n",
        "            nrow=4,\n",
        "            normalize=True,\n",
        "            value_range=(-1, 1)\n",
        "        )\n",
        "\n",
        "        # Comparaison c√¥te √† c√¥te (R√©el vs Stellarium)\n",
        "        side_by_side = torch.cat([real_A[:4], fake_B], dim=3)\n",
        "        save_image(\n",
        "            side_by_side,\n",
        "            f\"{self.config['output_dir']}/comparisons/epoch_{epoch:03d}_sidebyside.png\",\n",
        "            nrow=1,\n",
        "            normalize=True,\n",
        "            value_range=(-1, 1)\n",
        "        )\n",
        "\n",
        "        self.G_A2B.train()\n",
        "        self.G_B2A.train()\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        \"\"\"Graphiques d'entra√Ænement\"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "        fig.suptitle('Entra√Ænement CycleGAN - Navigation C√©leste', fontsize=14)\n",
        "\n",
        "        # G loss\n",
        "        axes[0, 0].plot(self.history['G'], color='blue', alpha=0.7)\n",
        "        axes[0, 0].set_title('Generator Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # D loss\n",
        "        axes[0, 1].plot(self.history['D'], color='red', alpha=0.7)\n",
        "        axes[0, 1].set_title('Discriminator Loss')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Cycle loss\n",
        "        axes[0, 2].plot(self.history['cycle'], color='green', alpha=0.7)\n",
        "        axes[0, 2].set_title('Cycle Consistency Loss')\n",
        "        axes[0, 2].set_xlabel('Epoch')\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Perceptual loss\n",
        "        if len(self.history['perceptual']) > 0 and max(self.history['perceptual']) > 0:\n",
        "            axes[1, 0].plot(self.history['perceptual'], color='purple', alpha=0.7)\n",
        "            axes[1, 0].set_title('Perceptual Loss')\n",
        "            axes[1, 0].set_xlabel('Epoch')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "        else:\n",
        "            axes[1, 0].text(0.5, 0.5, 'Perceptual Loss\\nDisabled',\n",
        "                          ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "\n",
        "        # Star brightness loss\n",
        "        if len(self.history['star_brightness']) > 0 and max(self.history['star_brightness']) > 0:\n",
        "            axes[1, 1].plot(self.history['star_brightness'], color='orange', alpha=0.7)\n",
        "            axes[1, 1].set_title('Star Brightness Loss')\n",
        "            axes[1, 1].set_xlabel('Epoch')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'Star Brightness\\nLoss Disabled',\n",
        "                          ha='center', va='center', transform=axes[1, 1].transAxes)\n",
        "\n",
        "        # Total loss\n",
        "        axes[1, 2].plot(self.history['total'], color='black', alpha=0.7)\n",
        "        axes[1, 2].set_title('Total Loss')\n",
        "        axes[1, 2].set_xlabel('Epoch')\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.config['output_dir']}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"   üìà Graphiques sauvegard√©s\")\n",
        "\n",
        "    def save_checkpoint(self, epoch):\n",
        "        \"\"\"Sauvegarder checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'G_A2B': self.G_A2B.state_dict(),\n",
        "            'G_B2A': self.G_B2A.state_dict(),\n",
        "            'D_A': self.D_A.state_dict(),\n",
        "            'D_B': self.D_B.state_dict(),\n",
        "            'opt_G': self.opt_G.state_dict(),\n",
        "            'opt_D': self.opt_D.state_dict(),\n",
        "            'config': self.config,\n",
        "            'history': self.history\n",
        "        }\n",
        "\n",
        "        path = f\"{self.config['output_dir']}/checkpoints/checkpoint_{epoch:03d}.pth\"\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "        # Garder seulement les 3 derniers + best\n",
        "        checkpoints = sorted(Path(f\"{self.config['output_dir']}/checkpoints\").glob(\"checkpoint_*.pth\"))\n",
        "        if len(checkpoints) > 3:\n",
        "            for ckpt in checkpoints[:-3]:\n",
        "                if 'best' not in str(ckpt):\n",
        "                    ckpt.unlink()\n",
        "\n",
        "    def train(self, dataloader):\n",
        "        \"\"\"Boucle principale d'entra√Ænement\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üöÄ ENTRA√éNEMENT CYCLEGAN AM√âLIOR√â\")\n",
        "        print(f\"   Epochs: {self.config['n_epochs']}\")\n",
        "        print(f\"   Batch: {self.config['batch_size']}\")\n",
        "        print(f\"   Perceptual Loss: {self.config['use_perceptual']}\")\n",
        "        print(f\"   Star Brightness Loss: {self.config['use_star_loss']}\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        best_cycle_loss = float('inf')\n",
        "\n",
        "        for epoch in range(1, self.config['n_epochs'] + 1):\n",
        "            avg_losses = self.train_epoch(dataloader, epoch)\n",
        "\n",
        "            # Historique\n",
        "            self.history['G'].append(avg_losses['G'])\n",
        "            self.history['D'].append(avg_losses['D'])\n",
        "            self.history['cycle'].append(avg_losses['cycle'])\n",
        "            self.history['perceptual'].append(avg_losses['perceptual'])\n",
        "            self.history['star_brightness'].append(avg_losses['star'])\n",
        "            self.history['total'].append(avg_losses['G'] + avg_losses['D'])\n",
        "\n",
        "            print(f\"\\nüìä Epoch {epoch}: G={avg_losses['G']:.4f} | \"\n",
        "                  f\"D={avg_losses['D']:.4f} | Cycle={avg_losses['cycle']:.4f} | \"\n",
        "                  f\"Star={avg_losses['star']:.4f}\")\n",
        "\n",
        "            # Update schedulers\n",
        "            self.sched_G.step()\n",
        "            self.sched_D.step()\n",
        "\n",
        "            # Sauvegarder\n",
        "            if epoch % self.config['save_interval'] == 0:\n",
        "                self.save_checkpoint(epoch)\n",
        "\n",
        "            # Sauvegarder meilleur\n",
        "            if avg_losses['cycle'] < best_cycle_loss:\n",
        "                best_cycle_loss = avg_losses['cycle']\n",
        "                torch.save(\n",
        "                    self.G_A2B.state_dict(),\n",
        "                    f\"{self.config['output_dir']}/checkpoints/best_G_A2B.pth\"\n",
        "                )\n",
        "                print(f\"   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: {best_cycle_loss:.4f}\")\n",
        "\n",
        "            # Graphiques\n",
        "            if epoch % 5 == 0:\n",
        "                self.plot_training_curves()\n",
        "\n",
        "        # Final\n",
        "        torch.save(\n",
        "            self.G_A2B.state_dict(),\n",
        "            f\"{self.config['output_dir']}/G_A2B_final.pth\"\n",
        "        )\n",
        "        torch.save(\n",
        "            self.G_B2A.state_dict(),\n",
        "            f\"{self.config['output_dir']}/G_B2A_final.pth\"\n",
        "        )\n",
        "\n",
        "        # Sauvegarder historique\n",
        "        with open(f\"{self.config['output_dir']}/history.json\", 'w') as f:\n",
        "            json.dump(self.history, f, indent=2)\n",
        "\n",
        "        # Graphiques finaux\n",
        "        self.plot_training_curves()\n",
        "\n",
        "        print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
        "        print(f\"üìÅ Mod√®les sauvegard√©s dans: {self.config['output_dir']}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALISATION ET ANALYSE\n",
        "# ============================================================================\n",
        "\n",
        "class ResultAnalyzer:\n",
        "    \"\"\"Analyser et visualiser les r√©sultats\"\"\"\n",
        "    def __init__(self, model_path, device='cuda'):\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Charger mod√®le\n",
        "        self.G_A2B = ImprovedGenerator(ngf=64, n_blocks=9).to(self.device)\n",
        "        self.G_A2B.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "        self.G_A2B.eval()\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "\n",
        "        print(f\"‚úÖ Mod√®le charg√© sur {self.device}\")\n",
        "\n",
        "    def create_detailed_comparison(self, image_path, output_path):\n",
        "        \"\"\"\n",
        "        Cr√©er une comparaison d√©taill√©e avec:\n",
        "        - Image originale (r√©elle)\n",
        "        - Image convertie (Stellarium)\n",
        "        - Zoom sur les √©toiles\n",
        "        - Histogrammes de luminosit√©\n",
        "        \"\"\"\n",
        "        # Charger image\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # G√©n√©rer version Stellarium\n",
        "        with torch.no_grad():\n",
        "            fake_stellarium = self.G_A2B(img_tensor)\n",
        "\n",
        "        # Convertir en numpy pour matplotlib\n",
        "        real_np = img_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "        real_np = (real_np * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "        fake_np = fake_stellarium.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "        fake_np = (fake_np * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "        # Cr√©er figure\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "        # Image r√©elle compl√®te\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        ax1.imshow(real_np)\n",
        "        ax1.set_title('Image R√©elle', fontsize=14, fontweight='bold')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # Image Stellarium g√©n√©r√©e\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.imshow(fake_np)\n",
        "        ax2.set_title('G√©n√©r√© (Style Stellarium)', fontsize=14, fontweight='bold')\n",
        "        ax2.axis('off')\n",
        "\n",
        "        # Diff√©rence\n",
        "        ax3 = fig.add_subplot(gs[0, 2])\n",
        "        diff = np.abs(fake_np - real_np)\n",
        "        ax3.imshow(diff)\n",
        "        ax3.set_title('Diff√©rence (Changements)', fontsize=14, fontweight='bold')\n",
        "        ax3.axis('off')\n",
        "\n",
        "        # Zoom sur une r√©gion (d√©tails √©toiles)\n",
        "        h, w = real_np.shape[:2]\n",
        "        crop_h, crop_w = h//3, w//3\n",
        "        start_h, start_w = h//3, w//3\n",
        "\n",
        "        real_zoom = real_np[start_h:start_h+crop_h, start_w:start_w+crop_w]\n",
        "        fake_zoom = fake_np[start_h:start_h+crop_h, start_w:start_w+crop_w]\n",
        "\n",
        "        ax4 = fig.add_subplot(gs[1, 0])\n",
        "        ax4.imshow(real_zoom)\n",
        "        ax4.set_title('Zoom - R√©el', fontsize=12)\n",
        "        ax4.axis('off')\n",
        "\n",
        "        ax5 = fig.add_subplot(gs[1, 1])\n",
        "        ax5.imshow(fake_zoom)\n",
        "        ax5.set_title('Zoom - Stellarium', fontsize=12)\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Histogramme luminosit√©\n",
        "        ax6 = fig.add_subplot(gs[1, 2])\n",
        "        real_gray = np.mean(real_np, axis=2)\n",
        "        fake_gray = np.mean(fake_np, axis=2)\n",
        "\n",
        "        ax6.hist(real_gray.flatten(), bins=50, alpha=0.6, label='R√©el', color='blue')\n",
        "        ax6.hist(fake_gray.flatten(), bins=50, alpha=0.6, label='Stellarium', color='orange')\n",
        "        ax6.set_title('Distribution Luminosit√©', fontsize=12)\n",
        "        ax6.set_xlabel('Intensit√©')\n",
        "        ax6.set_ylabel('Fr√©quence')\n",
        "        ax6.legend()\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "\n",
        "        # Statistiques sur les √©toiles (pixels brillants)\n",
        "        ax7 = fig.add_subplot(gs[2, :])\n",
        "\n",
        "        # Top 10% pixels les plus brillants\n",
        "        real_bright = np.sort(real_gray.flatten())[-int(len(real_gray.flatten())*0.1):]\n",
        "        fake_bright = np.sort(fake_gray.flatten())[-int(len(fake_gray.flatten())*0.1):]\n",
        "\n",
        "        stats_text = f\"\"\"\n",
        "        üìä STATISTIQUES DES √âTOILES (Top 10% pixels brillants)\n",
        "\n",
        "        R√©el:\n",
        "        - Luminosit√© moyenne: {real_bright.mean():.3f}\n",
        "        - Luminosit√© max: {real_gray.max():.3f}\n",
        "        - √âcart-type: {real_bright.std():.3f}\n",
        "\n",
        "        Stellarium (G√©n√©r√©):\n",
        "        - Luminosit√© moyenne: {fake_bright.mean():.3f}\n",
        "        - Luminosit√© max: {fake_gray.max():.3f}\n",
        "        - √âcart-type: {fake_bright.std():.3f}\n",
        "\n",
        "        Am√©lioration:\n",
        "        - Gain luminosit√©: {(fake_bright.mean() / real_bright.mean() - 1) * 100:+.1f}%\n",
        "        - Nombre pixels tr√®s brillants (>0.8): {(fake_gray > 0.8).sum()} vs {(real_gray > 0.8).sum()}\n",
        "        \"\"\"\n",
        "\n",
        "        ax7.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
        "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        ax7.axis('off')\n",
        "\n",
        "        plt.suptitle('Analyse D√©taill√©e - Conversion R√©el ‚Üí Stellarium',\n",
        "                    fontsize=16, fontweight='bold', y=0.98)\n",
        "\n",
        "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Analyse d√©taill√©e sauvegard√©e: {output_path}\")\n",
        "\n",
        "    def batch_analyze(self, input_dir, output_dir):\n",
        "        \"\"\"Analyser un dossier d'images\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        extensions = ['*.jpg', '*.jpeg', '*.png']\n",
        "        image_files = []\n",
        "        for ext in extensions:\n",
        "            image_files.extend(list(Path(input_dir).glob(ext)))\n",
        "\n",
        "        print(f\"üîç Analyse de {len(image_files)} images...\")\n",
        "\n",
        "        for img_path in tqdm(image_files[:10]):  # Limiter √† 10 pour l'exemple\n",
        "            output_path = Path(output_dir) / f\"analysis_{img_path.stem}.png\"\n",
        "            self.create_detailed_comparison(str(img_path), str(output_path))\n",
        "\n",
        "    def create_grid_comparison(self, image_paths, output_path, max_images=16):\n",
        "        \"\"\"Cr√©er grille de comparaisons multiples\"\"\"\n",
        "        n_images = min(len(image_paths), max_images)\n",
        "\n",
        "        fig, axes = plt.subplots(n_images, 2, figsize=(10, 5*n_images))\n",
        "        if n_images == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for idx, img_path in enumerate(image_paths[:n_images]):\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = self.G_A2B(img_tensor)\n",
        "\n",
        "            real_np = img_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "            real_np = (real_np * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "            fake_np = fake.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "            fake_np = (fake_np * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "            axes[idx][0].imshow(real_np)\n",
        "            axes[idx][0].set_title(f'R√©el - {Path(img_path).name}', fontsize=10)\n",
        "            axes[idx][0].axis('off')\n",
        "\n",
        "            axes[idx][1].imshow(fake_np)\n",
        "            axes[idx][1].set_title(f'Stellarium G√©n√©r√©', fontsize=10)\n",
        "            axes[idx][1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Grille de comparaison sauvegard√©e: {output_path}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "def get_improved_config():\n",
        "    \"\"\"Configuration am√©lior√©e\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    return {\n",
        "        # Donn√©es\n",
        "        'classA_dir': './classeA',\n",
        "        'classB_dir': './classeB',\n",
        "        'output_dir': f'./outputs/improved_cyclegan_{timestamp}',\n",
        "\n",
        "        # Architecture\n",
        "        'ngf': 64,  # Augment√© pour meilleure qualit√©\n",
        "        'ndf': 64,\n",
        "        'n_blocks': 9,  # Plus de ResBlocks pour transformer\n",
        "\n",
        "        # Entra√Ænement\n",
        "        'n_epochs': 100,\n",
        "        'batch_size': 4,  # Augment√© si GPU le permet\n",
        "        'lr': 0.0002,\n",
        "\n",
        "        # Optimisations\n",
        "        'use_amp': True,\n",
        "        'img_size': 128,\n",
        "        'num_workers': 4,\n",
        "\n",
        "        # Poids des pertes\n",
        "        'lambda_cycle': 10.0,\n",
        "        'lambda_identity': 0.5,\n",
        "        'lambda_perceptual': 1.0,  # Nouvelle: qualit√© visuelle\n",
        "        'lambda_star': 2.0,  # Nouvelle: √©toiles brillantes\n",
        "\n",
        "        # Nouvelles pertes\n",
        "        'use_perceptual': True,  # ‚úÖ Am√©liore qualit√©\n",
        "        'use_star_loss': True,   # ‚úÖ √âtoiles brillantes\n",
        "\n",
        "        # Sauvegarde\n",
        "        'save_interval': 10,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Script principal am√©lior√©\"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"   CYCLEGAN AM√âLIOR√â - Navigation C√©leste\")\n",
        "    print(\"   Conversion: R√©el ‚Üí Stellarium (√âtoiles Brillantes)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    config = get_improved_config()\n",
        "\n",
        "    # V√©rifications\n",
        "    if not os.path.exists(config['classA_dir']):\n",
        "        print(f\"‚ùå Dossier '{config['classA_dir']}' introuvable!\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(config['classB_dir']):\n",
        "        print(f\"‚ùå Dossier '{config['classB_dir']}' introuvable!\")\n",
        "        return\n",
        "\n",
        "    # Dataset\n",
        "    try:\n",
        "        dataset = CelestialDataset(\n",
        "            config['classA_dir'],\n",
        "            config['classB_dir'],\n",
        "            img_size=config['img_size']\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"‚ùå {e}\")\n",
        "        return\n",
        "\n",
        "    # DataLoader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ {len(dataloader)} batches charg√©s\\n\")\n",
        "\n",
        "    # Entra√Ænement\n",
        "    trainer = ImprovedCycleGANTrainer(config)\n",
        "    trainer.train(dataloader)\n",
        "\n",
        "\n",
        "def analyze_results(model_path, test_dir, output_dir):\n",
        "    \"\"\"Analyser les r√©sultats apr√®s entra√Ænement\"\"\"\n",
        "    print(\"üîç Analyse des r√©sultats...\\n\")\n",
        "\n",
        "    analyzer = ResultAnalyzer(model_path)\n",
        "\n",
        "    # Cr√©er analyses d√©taill√©es\n",
        "    analyzer.batch_analyze(test_dir, f\"{output_dir}/detailed_analysis\")\n",
        "\n",
        "    # Cr√©er grille de comparaison\n",
        "    test_images = list(Path(test_dir).glob(\"*.jpg\"))[:16]\n",
        "    if test_images:\n",
        "        analyzer.create_grid_comparison(\n",
        "            test_images,\n",
        "            f\"{output_dir}/comparison_grid.png\"\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "        if sys.argv[1] == 'train':\n",
        "            main()\n",
        "        elif sys.argv[1] == 'analyze':\n",
        "            if len(sys.argv) < 4:\n",
        "                print(\"Usage: python script.py analyze <model_path> <test_dir>\")\n",
        "            else:\n",
        "                analyze_results(sys.argv[2], sys.argv[3], './analysis_output')\n",
        "    else:\n",
        "        main()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "============================================================================\n",
        "AM√âLIORATIONS PRINCIPALES PAR RAPPORT AU MOD√àLE RAPIDE\n",
        "============================================================================\n",
        "\n",
        "1. ‚ú® ARCHITECTURE AM√âLIOR√âE\n",
        "   - StarAttentionModule: Focus sp√©cial sur les √©toiles\n",
        "   - Triple attention (Star + Channel + Spatial)\n",
        "   - ResBlocks plus profonds avec attention\n",
        "   ‚ûú √âtoiles plus brillantes et mieux d√©finies\n",
        "\n",
        "2. üé® PERCEPTUAL LOSS\n",
        "   - Utilise VGG19 pour comparer features\n",
        "   - Am√©liore la qualit√© visuelle globale\n",
        "   - Pr√©serve mieux les d√©tails\n",
        "   ‚ûú Images plus r√©alistes et naturelles\n",
        "\n",
        "3. ‚≠ê STAR BRIGHTNESS LOSS\n",
        "   - Perte personnalis√©e pour √©toiles brillantes\n",
        "   - Force le g√©n√©rateur √† rendre les √©toiles lumineuses\n",
        "   - Compare top 10% pixels (√©toiles)\n",
        "   ‚ûú √âtoiles √©clatantes comme dans Stellarium!\n",
        "\n",
        "4. üìä VISUALISATION AVANC√âE\n",
        "   - Comparaisons d√©taill√©es avec zoom\n",
        "   - Histogrammes de luminosit√©\n",
        "   - Statistiques sur les √©toiles\n",
        "   - Grilles de comparaison multiple\n",
        "   ‚ûú Analyse compl√®te des r√©sultats\n",
        "\n",
        "5. üéØ MEILLEURE STABILIT√â\n",
        "   - Initialisation des poids optimis√©e\n",
        "   - Schedulers cosine annealing\n",
        "   - Sauvegarde du meilleur mod√®le\n",
        "   ‚ûú Convergence plus stable\n",
        "\n",
        "============================================================================\n",
        "UTILISATION\n",
        "============================================================================\n",
        "\n",
        "# Entra√Ænement am√©lior√©\n",
        "python script.py train\n",
        "\n",
        "# Analyse des r√©sultats\n",
        "python script.py analyze ./outputs/*/checkpoints/best_G_A2B.pth ./classeA\n",
        "\n",
        "# R√©sultats g√©n√©r√©s:\n",
        "# - /comparisons/: Comparaisons c√¥te-√†-c√¥te\n",
        "# - /samples/: √âchantillons par √©poque\n",
        "# - /training_curves.png: Graphiques d'entra√Ænement\n",
        "# - /detailed_analysis/: Analyses d√©taill√©es avec stats\n",
        "\n",
        "============================================================================\n",
        "DIFF√âRENCES VS MOD√àLE LOURD\n",
        "============================================================================\n",
        "\n",
        "CONSERV√â:\n",
        "‚úì Architecture ResNet avec attention\n",
        "‚úì PatchGAN discriminateur\n",
        "‚úì Cycle consistency\n",
        "‚úì Mixed precision training\n",
        "\n",
        "AJOUT√â/AM√âLIOR√â:\n",
        "‚úì Star attention module (nouveau)\n",
        "‚úì Perceptual loss VGG (qualit√©++)\n",
        "‚úì Star brightness loss (√©toiles brillantes++)\n",
        "‚úì Visualisations compl√®tes (analyse++)\n",
        "‚úì Taille optimis√©e (128px pour vitesse)\n",
        "\n",
        "ALL√âG√â:\n",
        "‚úì 64 filtres au lieu de plus\n",
        "‚úì Images 128x128 (4x plus rapide que 256)\n",
        "‚úì Pas de pools d'images (simplification)\n",
        "\n",
        "R√âSULTAT: 10x plus rapide, qualit√© comparable, √©toiles BRILLANTES! ‚≠ê\n",
        "============================================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4saEVdvkcUB",
        "outputId": "34a550b8-17b6-4472-9999-da33fe6f9a2f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing improved_cyclegan.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python improved_cyclegan.py train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjA54SV9vIij",
        "outputId": "3cd09467-fe13-4ef6-c774-447d1edbee86"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "   CYCLEGAN AM√âLIOR√â - Navigation C√©leste\n",
            "   Conversion: R√©el ‚Üí Stellarium (√âtoiles Brillantes)\n",
            "======================================================================\n",
            "\n",
            "üìÇ Dataset: 1000 R√©el | 1000 Stellarium\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "‚úÖ 250 batches charg√©s\n",
            "\n",
            "üöÄ Device: cuda\n",
            "   GPU: Tesla T4\n",
            "üìä G√©n√©rateur: 12.26M params\n",
            "üìä Discriminateur: 2.76M params\n",
            "/content/improved_cyclegan.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler() if config['use_amp'] else None\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:05<00:00, 100MB/s] \n",
            "\n",
            "======================================================================\n",
            "üöÄ ENTRA√éNEMENT CYCLEGAN AM√âLIOR√â\n",
            "   Epochs: 100\n",
            "   Batch: 4\n",
            "   Perceptual Loss: True\n",
            "   Star Brightness Loss: True\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/100:   0% 0/250 [00:00<?, ?it/s]/content/improved_cyclegan.py:481: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "/content/improved_cyclegan.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "Epoch 1/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.445, D=0.517, Cyc=0.064, Star=0.015]\n",
            "\n",
            "üìä Epoch 1: G=2.1083 | D=0.6378 | Cycle=0.5207 | Star=0.1304\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.5207\n",
            "Epoch 2/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.449, D=0.471, Cyc=0.052, Star=0.027]\n",
            "\n",
            "üìä Epoch 2: G=1.4264 | D=0.4656 | Cycle=0.0530 | Star=0.0179\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0530\n",
            "Epoch 3/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.596, D=0.372, Cyc=0.074, Star=0.058]\n",
            "\n",
            "üìä Epoch 3: G=1.3188 | D=0.4610 | Cycle=0.0475 | Star=0.0201\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0475\n",
            "Epoch 4/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.264, D=0.382, Cyc=0.052, Star=0.047]\n",
            "\n",
            "üìä Epoch 4: G=1.3353 | D=0.4662 | Cycle=0.0505 | Star=0.0210\n",
            "Epoch 5/100: 100% 250/250 [01:26<00:00,  2.89it/s, G=1.281, D=0.492, Cyc=0.049, Star=0.006]\n",
            "\n",
            "üìä Epoch 5: G=1.3687 | D=0.4394 | Cycle=0.0518 | Star=0.0229\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 6/100:   0% 0/250 [00:00<?, ?it/s]/content/improved_cyclegan.py:481: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "/content/improved_cyclegan.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.config['use_amp']):\n",
            "Epoch 6/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.317, D=0.564, Cyc=0.056, Star=0.021]\n",
            "\n",
            "üìä Epoch 6: G=1.3375 | D=0.4580 | Cycle=0.0468 | Star=0.0202\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0468\n",
            "Epoch 7/100: 100% 250/250 [01:26<00:00,  2.90it/s, G=1.449, D=0.468, Cyc=0.045, Star=0.013]\n",
            "\n",
            "üìä Epoch 7: G=1.3347 | D=0.4643 | Cycle=0.0436 | Star=0.0199\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0436\n",
            "Epoch 8/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.452, D=0.416, Cyc=0.067, Star=0.058]\n",
            "\n",
            "üìä Epoch 8: G=1.3356 | D=0.4652 | Cycle=0.0431 | Star=0.0184\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0431\n",
            "Epoch 9/100: 100% 250/250 [01:27<00:00,  2.86it/s, G=1.273, D=0.432, Cyc=0.053, Star=0.042]\n",
            "\n",
            "üìä Epoch 9: G=1.3349 | D=0.4656 | Cycle=0.0418 | Star=0.0177\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0418\n",
            "Epoch 10/100: 100% 250/250 [01:26<00:00,  2.88it/s, G=1.200, D=0.515, Cyc=0.047, Star=0.018]\n",
            "\n",
            "üìä Epoch 10: G=1.3396 | D=0.4684 | Cycle=0.0401 | Star=0.0170\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0401\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 11/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.301, D=0.356, Cyc=0.048, Star=0.024]\n",
            "\n",
            "üìä Epoch 11: G=1.3465 | D=0.4695 | Cycle=0.0382 | Star=0.0146\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0382\n",
            "Epoch 12/100: 100% 250/250 [01:26<00:00,  2.90it/s, G=1.240, D=0.507, Cyc=0.042, Star=0.009]\n",
            "\n",
            "üìä Epoch 12: G=1.3435 | D=0.4655 | Cycle=0.0379 | Star=0.0161\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0379\n",
            "Epoch 13/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.334, D=0.429, Cyc=0.039, Star=0.006]\n",
            "\n",
            "üìä Epoch 13: G=1.3617 | D=0.4533 | Cycle=0.0382 | Star=0.0152\n",
            "Epoch 14/100: 100% 250/250 [01:27<00:00,  2.86it/s, G=1.375, D=0.409, Cyc=0.047, Star=0.025]\n",
            "\n",
            "üìä Epoch 14: G=1.3604 | D=0.4573 | Cycle=0.0383 | Star=0.0147\n",
            "Epoch 15/100: 100% 250/250 [01:26<00:00,  2.90it/s, G=1.185, D=0.566, Cyc=0.030, Star=0.010]\n",
            "\n",
            "üìä Epoch 15: G=1.3484 | D=0.4584 | Cycle=0.0388 | Star=0.0151\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 16/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.304, D=0.461, Cyc=0.034, Star=0.017]\n",
            "\n",
            "üìä Epoch 16: G=1.3400 | D=0.4581 | Cycle=0.0384 | Star=0.0153\n",
            "Epoch 17/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.247, D=0.439, Cyc=0.035, Star=0.009]\n",
            "\n",
            "üìä Epoch 17: G=1.3335 | D=0.4591 | Cycle=0.0381 | Star=0.0144\n",
            "Epoch 18/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.362, D=0.393, Cyc=0.045, Star=0.014]\n",
            "\n",
            "üìä Epoch 18: G=1.3513 | D=0.4554 | Cycle=0.0382 | Star=0.0162\n",
            "Epoch 19/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.174, D=0.342, Cyc=0.035, Star=0.001]\n",
            "\n",
            "üìä Epoch 19: G=1.3825 | D=0.5059 | Cycle=0.0383 | Star=0.0182\n",
            "Epoch 20/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.175, D=0.435, Cyc=0.031, Star=0.012]\n",
            "\n",
            "üìä Epoch 20: G=1.3210 | D=0.4470 | Cycle=0.0369 | Star=0.0169\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0369\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 21/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.272, D=0.535, Cyc=0.046, Star=0.007]\n",
            "\n",
            "üìä Epoch 21: G=1.3270 | D=0.4560 | Cycle=0.0398 | Star=0.0163\n",
            "Epoch 22/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.209, D=0.495, Cyc=0.032, Star=0.006]\n",
            "\n",
            "üìä Epoch 22: G=1.3296 | D=0.4601 | Cycle=0.0410 | Star=0.0166\n",
            "Epoch 23/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.346, D=0.416, Cyc=0.038, Star=0.011]\n",
            "\n",
            "üìä Epoch 23: G=1.3389 | D=0.4520 | Cycle=0.0379 | Star=0.0153\n",
            "Epoch 24/100: 100% 250/250 [01:24<00:00,  2.94it/s, G=1.326, D=0.526, Cyc=0.038, Star=0.015]\n",
            "\n",
            "üìä Epoch 24: G=1.3352 | D=0.4534 | Cycle=0.0380 | Star=0.0155\n",
            "Epoch 25/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.341, D=0.438, Cyc=0.035, Star=0.012]\n",
            "\n",
            "üìä Epoch 25: G=1.3432 | D=0.4497 | Cycle=0.0379 | Star=0.0159\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 26/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.518, D=0.393, Cyc=0.044, Star=0.016]\n",
            "\n",
            "üìä Epoch 26: G=1.3555 | D=0.4428 | Cycle=0.0383 | Star=0.0157\n",
            "Epoch 27/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.306, D=0.491, Cyc=0.022, Star=0.037]\n",
            "\n",
            "üìä Epoch 27: G=1.3690 | D=0.4385 | Cycle=0.0375 | Star=0.0154\n",
            "Epoch 28/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.439, D=0.468, Cyc=0.033, Star=0.043]\n",
            "\n",
            "üìä Epoch 28: G=1.3517 | D=0.4514 | Cycle=0.0375 | Star=0.0177\n",
            "Epoch 29/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.301, D=0.431, Cyc=0.025, Star=0.029]\n",
            "\n",
            "üìä Epoch 29: G=1.3658 | D=0.4371 | Cycle=0.0375 | Star=0.0150\n",
            "Epoch 30/100: 100% 250/250 [01:26<00:00,  2.89it/s, G=1.418, D=0.394, Cyc=0.035, Star=0.006]\n",
            "\n",
            "üìä Epoch 30: G=1.3759 | D=0.4305 | Cycle=0.0377 | Star=0.0157\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 31/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.487, D=0.479, Cyc=0.037, Star=0.018]\n",
            "\n",
            "üìä Epoch 31: G=1.3714 | D=0.4364 | Cycle=0.0375 | Star=0.0170\n",
            "Epoch 32/100: 100% 250/250 [01:26<00:00,  2.91it/s, G=1.393, D=0.354, Cyc=0.044, Star=0.030]\n",
            "\n",
            "üìä Epoch 32: G=1.3791 | D=0.4272 | Cycle=0.0373 | Star=0.0158\n",
            "Epoch 33/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.416, D=0.395, Cyc=0.048, Star=0.019]\n",
            "\n",
            "üìä Epoch 33: G=1.3875 | D=0.4212 | Cycle=0.0375 | Star=0.0161\n",
            "Epoch 34/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.367, D=0.433, Cyc=0.042, Star=0.013]\n",
            "\n",
            "üìä Epoch 34: G=1.3909 | D=0.4191 | Cycle=0.0370 | Star=0.0148\n",
            "Epoch 35/100: 100% 250/250 [01:26<00:00,  2.90it/s, G=1.374, D=0.376, Cyc=0.034, Star=0.008]\n",
            "\n",
            "üìä Epoch 35: G=1.3892 | D=0.4215 | Cycle=0.0369 | Star=0.0167\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 36/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.482, D=0.462, Cyc=0.037, Star=0.002]\n",
            "\n",
            "üìä Epoch 36: G=1.4009 | D=0.4143 | Cycle=0.0367 | Star=0.0161\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0367\n",
            "Epoch 37/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.417, D=0.385, Cyc=0.031, Star=0.013]\n",
            "\n",
            "üìä Epoch 37: G=1.3974 | D=0.4125 | Cycle=0.0366 | Star=0.0146\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0366\n",
            "Epoch 38/100: 100% 250/250 [01:26<00:00,  2.90it/s, G=1.543, D=0.432, Cyc=0.051, Star=0.021]\n",
            "\n",
            "üìä Epoch 38: G=1.4436 | D=0.3796 | Cycle=0.0398 | Star=0.0168\n",
            "Epoch 39/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.367, D=0.418, Cyc=0.036, Star=0.009]\n",
            "\n",
            "üìä Epoch 39: G=1.4177 | D=0.4017 | Cycle=0.0376 | Star=0.0151\n",
            "Epoch 40/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.284, D=0.464, Cyc=0.026, Star=0.031]\n",
            "\n",
            "üìä Epoch 40: G=1.4290 | D=0.3996 | Cycle=0.0372 | Star=0.0160\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 41/100: 100% 250/250 [01:26<00:00,  2.91it/s, G=1.580, D=0.365, Cyc=0.058, Star=0.007]\n",
            "\n",
            "üìä Epoch 41: G=1.4297 | D=0.3929 | Cycle=0.0370 | Star=0.0145\n",
            "Epoch 42/100: 100% 250/250 [01:26<00:00,  2.89it/s, G=1.370, D=0.331, Cyc=0.039, Star=0.006]\n",
            "\n",
            "üìä Epoch 42: G=1.4418 | D=0.3835 | Cycle=0.0372 | Star=0.0158\n",
            "Epoch 43/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.369, D=0.414, Cyc=0.031, Star=0.003]\n",
            "\n",
            "üìä Epoch 43: G=1.4478 | D=0.3781 | Cycle=0.0370 | Star=0.0134\n",
            "Epoch 44/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.419, D=0.422, Cyc=0.030, Star=0.032]\n",
            "\n",
            "üìä Epoch 44: G=1.4556 | D=0.3748 | Cycle=0.0372 | Star=0.0140\n",
            "Epoch 45/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.665, D=0.363, Cyc=0.033, Star=0.032]\n",
            "\n",
            "üìä Epoch 45: G=1.4570 | D=0.3699 | Cycle=0.0368 | Star=0.0137\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 46/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.349, D=0.398, Cyc=0.024, Star=0.020]\n",
            "\n",
            "üìä Epoch 46: G=1.4649 | D=0.3632 | Cycle=0.0370 | Star=0.0178\n",
            "Epoch 47/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.390, D=0.335, Cyc=0.038, Star=0.017]\n",
            "\n",
            "üìä Epoch 47: G=1.4738 | D=0.3587 | Cycle=0.0368 | Star=0.0148\n",
            "Epoch 48/100: 100% 250/250 [01:26<00:00,  2.89it/s, G=1.328, D=0.448, Cyc=0.047, Star=0.018]\n",
            "\n",
            "üìä Epoch 48: G=1.4758 | D=0.3551 | Cycle=0.0369 | Star=0.0159\n",
            "Epoch 49/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.467, D=0.357, Cyc=0.041, Star=0.004]\n",
            "\n",
            "üìä Epoch 49: G=1.4795 | D=0.3526 | Cycle=0.0369 | Star=0.0162\n",
            "Epoch 50/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.338, D=0.302, Cyc=0.029, Star=0.004]\n",
            "\n",
            "üìä Epoch 50: G=1.4947 | D=0.3386 | Cycle=0.0368 | Star=0.0132\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 51/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.543, D=0.367, Cyc=0.043, Star=0.026]\n",
            "\n",
            "üìä Epoch 51: G=1.4988 | D=0.3415 | Cycle=0.0370 | Star=0.0160\n",
            "Epoch 52/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.632, D=0.361, Cyc=0.027, Star=0.035]\n",
            "\n",
            "üìä Epoch 52: G=1.5026 | D=0.3334 | Cycle=0.0364 | Star=0.0163\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0364\n",
            "Epoch 53/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.652, D=0.309, Cyc=0.030, Star=0.037]\n",
            "\n",
            "üìä Epoch 53: G=1.5174 | D=0.3263 | Cycle=0.0366 | Star=0.0149\n",
            "Epoch 54/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.592, D=0.301, Cyc=0.049, Star=0.021]\n",
            "\n",
            "üìä Epoch 54: G=1.5200 | D=0.3176 | Cycle=0.0365 | Star=0.0141\n",
            "Epoch 55/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.342, D=0.300, Cyc=0.027, Star=0.008]\n",
            "\n",
            "üìä Epoch 55: G=1.5356 | D=0.3145 | Cycle=0.0367 | Star=0.0141\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 56/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.386, D=0.323, Cyc=0.036, Star=0.018]\n",
            "\n",
            "üìä Epoch 56: G=1.5466 | D=0.3050 | Cycle=0.0367 | Star=0.0144\n",
            "Epoch 57/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.557, D=0.328, Cyc=0.045, Star=0.002]\n",
            "\n",
            "üìä Epoch 57: G=1.5441 | D=0.3023 | Cycle=0.0368 | Star=0.0147\n",
            "Epoch 58/100: 100% 250/250 [01:24<00:00,  2.94it/s, G=1.495, D=0.331, Cyc=0.038, Star=0.014]\n",
            "\n",
            "üìä Epoch 58: G=1.5434 | D=0.3007 | Cycle=0.0366 | Star=0.0144\n",
            "Epoch 59/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.544, D=0.350, Cyc=0.037, Star=0.003]\n",
            "\n",
            "üìä Epoch 59: G=1.5530 | D=0.2951 | Cycle=0.0367 | Star=0.0137\n",
            "Epoch 60/100: 100% 250/250 [01:24<00:00,  2.94it/s, G=1.557, D=0.322, Cyc=0.047, Star=0.025]\n",
            "\n",
            "üìä Epoch 60: G=1.5623 | D=0.2855 | Cycle=0.0366 | Star=0.0130\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 61/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.610, D=0.312, Cyc=0.032, Star=0.022]\n",
            "\n",
            "üìä Epoch 61: G=1.5594 | D=0.2901 | Cycle=0.0362 | Star=0.0148\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0362\n",
            "Epoch 62/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.504, D=0.320, Cyc=0.042, Star=0.008]\n",
            "\n",
            "üìä Epoch 62: G=1.5766 | D=0.2796 | Cycle=0.0364 | Star=0.0141\n",
            "Epoch 63/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.451, D=0.300, Cyc=0.025, Star=0.022]\n",
            "\n",
            "üìä Epoch 63: G=1.5870 | D=0.2698 | Cycle=0.0364 | Star=0.0129\n",
            "Epoch 64/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.742, D=0.239, Cyc=0.056, Star=0.006]\n",
            "\n",
            "üìä Epoch 64: G=1.5921 | D=0.2668 | Cycle=0.0368 | Star=0.0137\n",
            "Epoch 65/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.486, D=0.222, Cyc=0.038, Star=0.008]\n",
            "\n",
            "üìä Epoch 65: G=1.5865 | D=0.2689 | Cycle=0.0373 | Star=0.0143\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 66/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.535, D=0.240, Cyc=0.032, Star=0.003]\n",
            "\n",
            "üìä Epoch 66: G=1.5936 | D=0.2659 | Cycle=0.0373 | Star=0.0138\n",
            "Epoch 67/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.574, D=0.296, Cyc=0.054, Star=0.010]\n",
            "\n",
            "üìä Epoch 67: G=1.5932 | D=0.2645 | Cycle=0.0365 | Star=0.0144\n",
            "Epoch 68/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.733, D=0.224, Cyc=0.037, Star=0.005]\n",
            "\n",
            "üìä Epoch 68: G=1.6048 | D=0.2537 | Cycle=0.0366 | Star=0.0140\n",
            "Epoch 69/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.710, D=0.259, Cyc=0.044, Star=0.017]\n",
            "\n",
            "üìä Epoch 69: G=1.6095 | D=0.2548 | Cycle=0.0366 | Star=0.0148\n",
            "Epoch 70/100: 100% 250/250 [01:24<00:00,  2.94it/s, G=1.578, D=0.225, Cyc=0.036, Star=0.009]\n",
            "\n",
            "üìä Epoch 70: G=1.6034 | D=0.2563 | Cycle=0.0365 | Star=0.0144\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 71/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.690, D=0.253, Cyc=0.035, Star=0.035]\n",
            "\n",
            "üìä Epoch 71: G=1.6108 | D=0.2519 | Cycle=0.0366 | Star=0.0155\n",
            "Epoch 72/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.684, D=0.239, Cyc=0.029, Star=0.006]\n",
            "\n",
            "üìä Epoch 72: G=1.6118 | D=0.2485 | Cycle=0.0364 | Star=0.0142\n",
            "Epoch 73/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.664, D=0.231, Cyc=0.044, Star=0.012]\n",
            "\n",
            "üìä Epoch 73: G=1.6103 | D=0.2494 | Cycle=0.0362 | Star=0.0145\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0362\n",
            "Epoch 74/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.620, D=0.264, Cyc=0.034, Star=0.014]\n",
            "\n",
            "üìä Epoch 74: G=1.6166 | D=0.2424 | Cycle=0.0362 | Star=0.0137\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0362\n",
            "Epoch 75/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.537, D=0.200, Cyc=0.032, Star=0.005]\n",
            "\n",
            "üìä Epoch 75: G=1.6181 | D=0.2438 | Cycle=0.0362 | Star=0.0143\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0362\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 76/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.499, D=0.250, Cyc=0.025, Star=0.018]\n",
            "\n",
            "üìä Epoch 76: G=1.6181 | D=0.2413 | Cycle=0.0362 | Star=0.0141\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0362\n",
            "Epoch 77/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.559, D=0.252, Cyc=0.036, Star=0.001]\n",
            "\n",
            "üìä Epoch 77: G=1.6189 | D=0.2412 | Cycle=0.0362 | Star=0.0145\n",
            "Epoch 78/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.583, D=0.252, Cyc=0.041, Star=0.000]\n",
            "\n",
            "üìä Epoch 78: G=1.6231 | D=0.2405 | Cycle=0.0365 | Star=0.0154\n",
            "Epoch 79/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.575, D=0.245, Cyc=0.035, Star=0.008]\n",
            "\n",
            "üìä Epoch 79: G=1.6280 | D=0.2377 | Cycle=0.0367 | Star=0.0158\n",
            "Epoch 80/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.628, D=0.227, Cyc=0.041, Star=0.020]\n",
            "\n",
            "üìä Epoch 80: G=1.6261 | D=0.2371 | Cycle=0.0366 | Star=0.0155\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 81/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.515, D=0.210, Cyc=0.028, Star=0.004]\n",
            "\n",
            "üìä Epoch 81: G=1.6217 | D=0.2385 | Cycle=0.0365 | Star=0.0146\n",
            "Epoch 82/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.623, D=0.266, Cyc=0.034, Star=0.019]\n",
            "\n",
            "üìä Epoch 82: G=1.6271 | D=0.2342 | Cycle=0.0363 | Star=0.0135\n",
            "Epoch 83/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.587, D=0.231, Cyc=0.026, Star=0.009]\n",
            "\n",
            "üìä Epoch 83: G=1.6298 | D=0.2336 | Cycle=0.0368 | Star=0.0145\n",
            "Epoch 84/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.694, D=0.234, Cyc=0.046, Star=0.008]\n",
            "\n",
            "üìä Epoch 84: G=1.6264 | D=0.2309 | Cycle=0.0363 | Star=0.0143\n",
            "Epoch 85/100: 100% 250/250 [01:24<00:00,  2.94it/s, G=1.696, D=0.212, Cyc=0.046, Star=0.019]\n",
            "\n",
            "üìä Epoch 85: G=1.6284 | D=0.2289 | Cycle=0.0361 | Star=0.0146\n",
            "   ‚≠ê Nouveau meilleur mod√®le! Cycle loss: 0.0361\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 86/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.641, D=0.220, Cyc=0.030, Star=0.001]\n",
            "\n",
            "üìä Epoch 86: G=1.6329 | D=0.2277 | Cycle=0.0365 | Star=0.0155\n",
            "Epoch 87/100: 100% 250/250 [01:25<00:00,  2.91it/s, G=1.560, D=0.234, Cyc=0.032, Star=0.006]\n",
            "\n",
            "üìä Epoch 87: G=1.6332 | D=0.2266 | Cycle=0.0369 | Star=0.0145\n",
            "Epoch 88/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.555, D=0.288, Cyc=0.036, Star=0.026]\n",
            "\n",
            "üìä Epoch 88: G=1.6258 | D=0.2280 | Cycle=0.0364 | Star=0.0133\n",
            "Epoch 89/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.553, D=0.222, Cyc=0.036, Star=0.014]\n",
            "\n",
            "üìä Epoch 89: G=1.6254 | D=0.2284 | Cycle=0.0365 | Star=0.0138\n",
            "Epoch 90/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.674, D=0.232, Cyc=0.040, Star=0.009]\n",
            "\n",
            "üìä Epoch 90: G=1.6280 | D=0.2263 | Cycle=0.0363 | Star=0.0136\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 91/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.560, D=0.240, Cyc=0.028, Star=0.037]\n",
            "\n",
            "üìä Epoch 91: G=1.6280 | D=0.2259 | Cycle=0.0364 | Star=0.0151\n",
            "Epoch 92/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.516, D=0.204, Cyc=0.024, Star=0.018]\n",
            "\n",
            "üìä Epoch 92: G=1.6293 | D=0.2263 | Cycle=0.0363 | Star=0.0145\n",
            "Epoch 93/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.748, D=0.217, Cyc=0.046, Star=0.012]\n",
            "\n",
            "üìä Epoch 93: G=1.6265 | D=0.2274 | Cycle=0.0364 | Star=0.0141\n",
            "Epoch 94/100: 100% 250/250 [01:25<00:00,  2.93it/s, G=1.513, D=0.253, Cyc=0.023, Star=0.031]\n",
            "\n",
            "üìä Epoch 94: G=1.6292 | D=0.2264 | Cycle=0.0363 | Star=0.0165\n",
            "Epoch 95/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.746, D=0.221, Cyc=0.041, Star=0.014]\n",
            "\n",
            "üìä Epoch 95: G=1.6263 | D=0.2253 | Cycle=0.0364 | Star=0.0137\n",
            "   üìà Graphiques sauvegard√©s\n",
            "Epoch 96/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.601, D=0.244, Cyc=0.039, Star=0.006]\n",
            "\n",
            "üìä Epoch 96: G=1.6314 | D=0.2243 | Cycle=0.0364 | Star=0.0153\n",
            "Epoch 97/100: 100% 250/250 [01:25<00:00,  2.94it/s, G=1.639, D=0.226, Cyc=0.028, Star=0.020]\n",
            "\n",
            "üìä Epoch 97: G=1.6280 | D=0.2259 | Cycle=0.0363 | Star=0.0142\n",
            "Epoch 98/100: 100% 250/250 [01:25<00:00,  2.92it/s, G=1.664, D=0.224, Cyc=0.036, Star=0.003]\n",
            "\n",
            "üìä Epoch 98: G=1.6299 | D=0.2223 | Cycle=0.0363 | Star=0.0145\n",
            "Epoch 99/100: 100% 250/250 [01:24<00:00,  2.95it/s, G=1.596, D=0.201, Cyc=0.027, Star=0.014]\n",
            "\n",
            "üìä Epoch 99: G=1.6278 | D=0.2234 | Cycle=0.0366 | Star=0.0136\n",
            "Epoch 100/100: 100% 250/250 [01:24<00:00,  2.96it/s, G=1.615, D=0.234, Cyc=0.044, Star=0.015]\n",
            "\n",
            "üìä Epoch 100: G=1.6301 | D=0.2235 | Cycle=0.0364 | Star=0.0150\n",
            "   üìà Graphiques sauvegard√©s\n",
            "   üìà Graphiques sauvegard√©s\n",
            "\n",
            "‚úÖ Entra√Ænement termin√©!\n",
            "üìÅ Mod√®les sauvegard√©s dans: ./outputs/improved_cyclegan_20251117_165354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M√©thode 3: Commande shell directe\n",
        "!cd /content && zip -r mon_modele_cyclegan.zip outputs/ -i \"*\"\n",
        "\n",
        "# Puis t√©l√©charger\n",
        "from google.colab import files\n",
        "files.download('/content/mon_modele_cyclegan.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xoSSctdGQKFD",
        "outputId": "e4df996b-b784-4b2d-c630-5b974603801b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161346/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161346/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161346/checkpoints/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160740/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160740/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160740/checkpoints/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/samples/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/history.json (deflated 61%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/G_A2B_final.pth (deflated 7%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/G_B2A_final.pth (deflated 7%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/training_curves.png (deflated 13%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_032_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_080_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_093_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_015_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_100_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_049_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_098_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_029_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_057_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_002_full.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_094_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_066_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_019_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_049_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_058_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_020_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_082_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_065_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_028_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_035_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_021_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_097_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_091_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_075_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_090_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_030_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_035_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_047_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_089_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_044_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_064_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_042_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_091_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_092_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_022_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_053_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_009_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_015_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_037_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_088_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_060_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_059_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_043_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_053_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_023_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_079_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_026_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_097_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_100_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_071_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_041_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_055_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_045_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_012_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_061_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_029_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_071_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_039_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_033_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_054_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_030_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_062_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_063_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_084_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_095_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_043_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_050_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_018_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_056_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_039_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_095_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_068_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_094_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_001_full.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_052_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_033_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_067_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_002_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_022_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_054_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_026_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_072_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_024_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_021_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_034_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_016_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_024_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_005_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_059_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_079_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_010_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_087_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_099_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_099_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_060_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_006_full.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_005_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_013_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_048_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_031_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_008_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_096_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_001_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_048_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_007_full.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_092_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_011_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_004_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_078_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_036_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_011_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_020_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_032_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_063_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_040_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_007_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_067_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_055_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_038_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_074_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_027_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_042_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_025_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_045_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_085_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_057_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_064_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_009_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_014_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_013_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_037_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_036_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_087_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_066_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_047_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_008_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_069_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_012_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_070_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_051_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_068_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_056_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_010_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_041_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_016_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_052_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_086_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_017_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_074_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_072_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_083_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_098_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_058_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_076_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_073_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_004_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_023_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_018_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_061_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_017_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_086_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_046_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_014_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_040_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_034_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_085_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_028_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_025_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_050_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_051_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_065_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_075_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_003_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_084_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_003_full.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_076_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_089_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_081_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_046_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_073_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_019_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_083_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_078_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_031_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_062_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_038_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_069_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_077_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_096_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_027_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_088_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_006_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_081_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_070_full.png (deflated 1%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_077_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_090_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_080_full.png (deflated 3%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_082_sidebyside.png (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_093_sidebyside.png (deflated 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/comparisons/epoch_044_full.png (deflated 2%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/checkpoints/ (stored 0%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/checkpoints/checkpoint_090.pth (deflated 8%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/checkpoints/checkpoint_100.pth (deflated 8%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/checkpoints/best_G_A2B.pth (deflated 7%)\n",
            "  adding: outputs/improved_cyclegan_20251117_165354/checkpoints/checkpoint_080.pth (deflated 8%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_009.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_025.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_045.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_008.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_047.png (deflated 1%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_046.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_039.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_020.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_042.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_043.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_012.png (deflated 1%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_016.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_023.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_021.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_036.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_037.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_035.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_003.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_038.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_027.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_041.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_022.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_006.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_001.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_024.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_011.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_004.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_030.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_028.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_034.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_026.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_049.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_018.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_010.png (deflated 1%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_044.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_050.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_014.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_032.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_031.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_017.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_033.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_040.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_013.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_048.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_019.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_015.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_002.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_005.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_007.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/samples/epoch_029.png (deflated 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/G_A2B_final.pth (deflated 9%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/G_B2A_final.pth (deflated 9%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/checkpoints/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/checkpoints/checkpoint_050.pth (deflated 11%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/checkpoints/checkpoint_040.pth (deflated 11%)\n",
            "  adding: outputs/fast_cyclegan_20251117_162325/checkpoints/checkpoint_030.pth (deflated 11%)\n",
            "  adding: outputs/fast_cyclegan_20251117_155545/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_155545/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_155545/checkpoints/ (stored 0%)\n",
            "  adding: outputs/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161428/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161428/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_161428/checkpoints/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160038/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160038/samples/ (stored 0%)\n",
            "  adding: outputs/fast_cyclegan_20251117_160038/checkpoints/ (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4eb94a81-ebb1-4cef-90d4-4b7f893e7438\", \"mon_modele_cyclegan.zip\", 1176145570)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def copy_to_drive_simple():\n",
        "    \"\"\"Copier un fichier sp√©cifique vers Drive\"\"\"\n",
        "\n",
        "    # Chemin du fichier dans Colab\n",
        "    source_file = \"/content/outputs.zip\"  # Remplacez par votre fichier\n",
        "\n",
        "    if not os.path.exists(source_file):\n",
        "        print(f\"‚ùå Fichier non trouv√©: {source_file}\")\n",
        "        print(\"üìÅ Fichiers disponibles dans /content:\")\n",
        "        !ls -la /content/\n",
        "        return\n",
        "\n",
        "    # Chemin de destination dans Drive\n",
        "    drive_destination = \"/content/drive/MyDrive/outouts.zip\"\n",
        "\n",
        "    # Copier le fichier\n",
        "    shutil.copy2(source_file, drive_destination)\n",
        "\n",
        "    print(f\"‚úÖ Fichier copi√©: {source_file} ‚Üí {drive_destination}\")\n",
        "\n",
        "copy_to_drive_simple()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up7G0CfnRt78",
        "outputId": "ced10968-591b-4946-ded2-7d9266a0b3f4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fichier copi√©: /content/outputs.zip ‚Üí /content/drive/MyDrive/outouts.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1 - Batch size 1 (actuel)\n",
        "!python script.py --mode train --batch_size 1 --epochs 5\n",
        "\n",
        "# Test 2 - Batch size 2\n",
        "!python script.py --mode train --batch_size 2 --epochs 5\n",
        "\n",
        "# Comparez les courbes de loss !"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSOfEVLvnPAH",
        "outputId": "072c2a32-7d46-4642-c085-54e4608e0b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Dataset charg√©:\n",
            "   Classe A (Real): 1000 images\n",
            "   Classe B (Stellarium): 1000 images\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "üñ•Ô∏è  Device: cuda\n",
            "üî® Construction des mod√®les...\n",
            "   G_A2B: 11,447,541 param√®tres\n",
            "   D_A: 2,763,841 param√®tres\n",
            "\n",
            "======================================================================\n",
            "üöÄ D√©marrage entra√Ænement CycleGAN Navigation C√©leste\n",
            "   Epochs: 5\n",
            "   Batch size: 1\n",
            "   CBAM: True\n",
            "   Device: cuda\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/5: 100% 1000/1000 [09:15<00:00,  1.80it/s, G=0.392, D=0.190, Cycle=0.001]\n",
            "\n",
            "üìä Epoch 1 - Pertes moyennes:\n",
            "   G: 0.4070 | D: 0.2924\n",
            "   Cycle: 0.0071 | GAN: 0.3308\n",
            "   üíæ Checkpoint sauvegard√© (epoch 1)\n",
            "Epoch 2/5: 100% 1000/1000 [09:16<00:00,  1.80it/s, G=0.253, D=0.274, Cycle=0.003]\n",
            "\n",
            "üìä Epoch 2 - Pertes moyennes:\n",
            "   G: 0.4104 | D: 0.2200\n",
            "   Cycle: 0.0023 | GAN: 0.3853\n",
            "   üíæ Checkpoint sauvegard√© (epoch 2)\n",
            "Epoch 3/5: 100% 1000/1000 [09:16<00:00,  1.80it/s, G=0.210, D=0.227, Cycle=0.001]\n",
            "\n",
            "üìä Epoch 3 - Pertes moyennes:\n",
            "   G: 0.2720 | D: 0.2469\n",
            "   Cycle: 0.0020 | GAN: 0.2503\n",
            "   üíæ Checkpoint sauvegard√© (epoch 3)\n",
            "Epoch 4/5: 100% 1000/1000 [09:16<00:00,  1.80it/s, G=0.327, D=0.267, Cycle=0.003]\n",
            "\n",
            "üìä Epoch 4 - Pertes moyennes:\n",
            "   G: 0.3028 | D: 0.2452\n",
            "   Cycle: 0.0020 | GAN: 0.2810\n",
            "   üíæ Checkpoint sauvegard√© (epoch 4)\n",
            "Epoch 5/5: 100% 1000/1000 [09:16<00:00,  1.80it/s, G=0.297, D=0.227, Cycle=0.003]\n",
            "\n",
            "üìä Epoch 5 - Pertes moyennes:\n",
            "   G: 0.3469 | D: 0.2416\n",
            "   Cycle: 0.0022 | GAN: 0.3236\n",
            "   üíæ Checkpoint sauvegard√© (epoch 5)\n",
            "\n",
            "‚úÖ Entra√Ænement termin√©!\n",
            "üìÅ R√©sultats sauvegard√©s dans: ./outputs/cyclegan_20251114_194131\n",
            "üìÇ Dataset charg√©:\n",
            "   Classe A (Real): 1000 images\n",
            "   Classe B (Stellarium): 1000 images\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "üñ•Ô∏è  Device: cuda\n",
            "üî® Construction des mod√®les...\n",
            "   G_A2B: 11,447,541 param√®tres\n",
            "   D_A: 2,763,841 param√®tres\n",
            "\n",
            "======================================================================\n",
            "üöÄ D√©marrage entra√Ænement CycleGAN Navigation C√©leste\n",
            "   Epochs: 5\n",
            "   Batch size: 2\n",
            "   CBAM: True\n",
            "   Device: cuda\n",
            "======================================================================\n",
            "\n",
            "Epoch 1/5:  73% 364/500 [06:25<02:23,  1.06s/it, G=0.302, D=0.200, Cycle=0.003]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour utiliser le mod√®le entra√Æn√©\n",
        "# Remplacez le chemin par votre checkpoint r√©el\n",
        "checkpoint_path = \"./outputs/cyclegan_YYYYMMDD_HHMMSS/checkpoints/best.pth\"\n",
        "\n",
        "# Inf√©rence sur une image\n",
        "!python script.py --mode inference \\\n",
        "    --checkpoint {checkpoint_path} \\\n",
        "    --input ./classeA/test_image.jpg \\\n",
        "    --output ./results \\\n",
        "    --direction A2B"
      ],
      "metadata": {
        "id": "uZoe9yVs5yu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er la structure de dossiers\n",
        "!python script.py --mode setup"
      ],
      "metadata": {
        "id": "JS-1wPlagvmw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/improved_modele_cyclegan.zip\", \"/content/drive/MyDrive/improved_cyclegan.zip\")\n",
        "\n",
        "print(\"‚úÖ ZIP copi√© vers Drive: /content/drive/MyDrive/mon_modele_cyclegan.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Oqj5roW1e63-",
        "outputId": "da0384b7-ae98-404d-e918-e9c3e4c36bac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ZIP copi√© vers Drive: /content/drive/MyDrive/mon_modele_cyclegan.zip\n"
          ]
        }
      ]
    }
  ]
}